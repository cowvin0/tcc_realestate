<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.555">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Cleaning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="modeling_files/libs/clipboard/clipboard.min.js"></script>
<script src="modeling_files/libs/quarto-html/quarto.js"></script>
<script src="modeling_files/libs/quarto-html/popper.min.js"></script>
<script src="modeling_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="modeling_files/libs/quarto-html/anchor.min.js"></script>
<link href="modeling_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="modeling_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="modeling_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="modeling_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="modeling_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Cleaning</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div id="cell-1" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas.api.types <span class="im">as</span> ptypes</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> optuna</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> joblib</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> step <span class="im">import</span> <span class="op">*</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> ensemble</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># from pycaret.regression import *</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xgboost <span class="im">import</span> XGBRegressor</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lightgbm <span class="im">import</span> LGBMRegressor</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> StratifiedShuffleSplit, cross_val_score, KFold</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-2" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df_alg <span class="op">=</span> pd.read_csv(<span class="st">"../../data/joao-pessoa-aluguel.csv"</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>df1 <span class="op">=</span> pd.read_csv(<span class="st">"../../data/joao_pessoa.csv"</span>).drop(columns<span class="op">=</span>[<span class="st">"andar"</span>])</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> pd.read_csv(<span class="st">"../../data/joao_pessoa1.csv"</span>) <span class="op">\</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    .drop(columns<span class="op">=</span>[<span class="st">"z_lat"</span>, <span class="st">"z_lon"</span>, <span class="st">"bairro_completo"</span>,</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>                   <span class="st">"comercio"</span>, <span class="st">"bairro"</span>, <span class="st">"zona"</span>]) <span class="op">\</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    .transform(<span class="kw">lambda</span> x: x.<span class="bu">apply</span>(<span class="kw">lambda</span> y: <span class="bu">float</span>(y)) <span class="cf">if</span> ptypes.is_bool_dtype(x) <span class="cf">else</span> x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-3" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>df3 <span class="op">=</span> pd <span class="op">\</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    .read_csv(<span class="st">'../../data/aluguel_social_jp.csv'</span>, delimiter<span class="op">=</span><span class="st">';'</span>) <span class="op">\</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    .query(<span class="st">'`ANO DO PAGAMENTO` == 2023'</span>) <span class="op">\</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    .dropna(subset<span class="op">=</span>[<span class="st">'BAIRRO'</span>]) <span class="op">\</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    .rename(columns<span class="op">=</span>{<span class="st">'BAIRRO'</span>: <span class="st">'bairro'</span>}) <span class="op">\</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    .assign(bairro<span class="op">=</span><span class="kw">lambda</span> x: x.bairro.<span class="bu">str</span>.strip().<span class="bu">str</span>.title()) <span class="op">\</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    .replace(</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>            <span class="vs">r'M[AaNnGg]([a-zA-Z])*\sI'</span>: <span class="st">'Mangabeira I'</span>,</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>            <span class="vs">r'M[AaNnGg]([a-zA-Z])*\sII'</span>: <span class="st">'Mangabeira II'</span>,</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>            <span class="vs">r'M[AaNnGg]([a-zA-Z])*\sIII'</span>: <span class="st">'Mangabeira III'</span>,</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>            <span class="vs">r'M[AaNnGg]([a-zA-Z])*\sIV'</span>: <span class="st">'Mangabeira IV'</span>,</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>            <span class="vs">r'M[AaNnGg]([a-zA-Z])*\sVii'</span>: <span class="st">'Mangabeira IV'</span>,</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Mangabeira Iv'</span>: <span class="st">'Mangabeira IV'</span>,</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Mangabeira Iii'</span>: <span class="st">'Mangabeira III'</span>,</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Mangabeira Ii'</span>: <span class="st">'Mangabeira II'</span>,</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Mangabeira Vi'</span>: <span class="st">'Mangabeira VI'</span>,</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Mangabeira Vii'</span>: <span class="st">'Mangabeira VII'</span>,</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Mangabeira Viii'</span>: <span class="st">'Mangabeira VIII'</span>,</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Mangabeira, Viii'</span>: <span class="st">'Mangabeira VIII'</span>,</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Mangabeira 8'</span>: <span class="st">'Mangabeira VIII'</span>,</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>            <span class="vs">r'M[AaNnGg]([a-zA-Z])*'</span>: <span class="st">'Mangabeira'</span>,</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>            <span class="vs">r'Varad([a-zA-Z]).*'</span>: <span class="st">'Varadouro'</span>,</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Jd Veneza'</span>: <span class="st">'Jardim Veneza'</span>,</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Jd Cidade Universitaria'</span>: <span class="st">'Jardim Cidade Universitaria'</span>,</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Mangabeira \( Aratu\)'</span>: <span class="st">'Mangabeira'</span>,</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Monsenhor Mangabeira'</span>: <span class="st">'Mangabeira'</span>,</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Mangabeira 1'</span>: <span class="st">'Mangabeira'</span>,</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Mangabeira \(Aratu\)'</span>: <span class="st">'Mangabeira'</span>,</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Bairro Dos Estados'</span>: <span class="st">'Estados'</span>,</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Mangabeira 6'</span>: <span class="st">'Mangabeira VI'</span>,</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Cristo'</span>: <span class="st">'Cristo Redentor'</span>,</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>        regex<span class="op">=</span><span class="va">True</span></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">\</span></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>    .replace(</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Monsenhor Mangabeira'</span>: <span class="st">'Mangabeira'</span>,</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Baixo Roger'</span>: <span class="st">'Roger'</span>,</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Funcionarios 2'</span>: <span class="st">'Funcionarios II a IV'</span>,</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Cristo Redentor Redentor'</span>: <span class="st">'Cristo Redentor'</span>,</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Baixo Roger ( Vila Lula</span><span class="ch">\n</span><span class="st">Lucena)'</span>: <span class="st">'Roger'</span>,</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Collinas Do Sul'</span>: <span class="st">'Colinas do Sul'</span>,</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Cidade Verde - Bairro Das Industrias'</span>: <span class="st">'Bairro das Industrias'</span>,</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Cristo Redentor/Vale Das Palmeiras'</span>: <span class="st">'Cristo Redentor'</span>,</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Biarro Das Industria'</span>: <span class="st">'Bairro das Industrias'</span>,</span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Altiplano 2'</span>: <span class="st">'Altiplano'</span>,</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Dos Ipes'</span>: <span class="st">'Bairro Dos Ipes'</span>,</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Aeroclube/Bessa'</span>: <span class="st">'Aeroclube'</span>,</span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Bairro Sao Jose'</span>: <span class="st">'Sao Jose'</span>,</span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a>            <span class="st">'B. Industrias'</span>: <span class="st">'Bairro das Industrias'</span>,</span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Industrias'</span>: <span class="st">'Bairro das Industrias'</span>,</span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>            <span class="st">'B Das Industrias'</span>: <span class="st">'Bairro das Industrias'</span>,</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Funcionarios Ii'</span>: <span class="st">'Funcionarios II a IV'</span>,</span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Bela Vista/Cristo Redentor'</span>: <span class="st">'Cristo Redentor'</span>,</span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Sao Jose/ Barreira'</span>: <span class="st">'Sao Jose'</span>,</span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a>            <span class="st">'B. Dos Estados'</span>: <span class="st">'Estados'</span>,</span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a>            <span class="st">'13 De Mangabeira'</span>: <span class="st">'Mangabeira'</span>,</span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Cristro Redentor'</span>: <span class="st">'Cristo Redentor'</span>,</span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Funcionario Iii'</span>: <span class="st">'Funcionarios II a IV'</span>,</span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Gervasio Mangabeira'</span>: <span class="st">'Mangabeira'</span>,</span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Ipes'</span>: <span class="st">'Bairro Dos Ipes'</span>,</span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true" tabindex="-1"></a>            <span class="st">'B. Das Industrias'</span>: <span class="st">'Bairro das Industrias'</span>,</span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Joao Paulo Ii'</span>: <span class="st">'Joao Paulo II'</span>,</span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Padreze'</span>: <span class="st">'Padre Ze'</span>,</span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Valentina I'</span>: <span class="st">'Valentina'</span>,</span>
<span id="cb3-67"><a href="#cb3-67" aria-hidden="true" tabindex="-1"></a>            <span class="st">'B. Dos Novais'</span>: <span class="st">'Bairro dos novais'</span>,</span>
<span id="cb3-68"><a href="#cb3-68" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Novais'</span>: <span class="st">'Bairro dos novais'</span>,</span>
<span id="cb3-69"><a href="#cb3-69" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Treze De Mangabeira'</span>: <span class="st">'Mangabeira'</span>,</span>
<span id="cb3-70"><a href="#cb3-70" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Estados'</span>: <span class="st">'Bairro dos estados'</span></span>
<span id="cb3-71"><a href="#cb3-71" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb3-72"><a href="#cb3-72" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">\</span></span>
<span id="cb3-73"><a href="#cb3-73" aria-hidden="true" tabindex="-1"></a>    .reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-74"><a href="#cb3-74" aria-hidden="true" tabindex="-1"></a>df3 <span class="op">=</span> df3.replace({<span class="st">'Estados'</span>: <span class="st">'bairro dos estados'</span>})</span>
<span id="cb3-75"><a href="#cb3-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-76"><a href="#cb3-76" aria-hidden="true" tabindex="-1"></a>df3 <span class="op">=</span> df3.assign(bairro<span class="op">=</span><span class="kw">lambda</span> x: x.bairro.<span class="bu">str</span>.lower().<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">'_'</span>)) <span class="op">\</span></span>
<span id="cb3-77"><a href="#cb3-77" aria-hidden="true" tabindex="-1"></a>    .groupby([<span class="st">'bairro'</span>], as_index<span class="op">=</span><span class="va">False</span>).size() <span class="op">\</span></span>
<span id="cb3-78"><a href="#cb3-78" aria-hidden="true" tabindex="-1"></a>    .rename(columns<span class="op">=</span>{<span class="st">'size'</span>: <span class="st">'qnt_beneficio'</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-4" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extract_location(address):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    pattern_joao_pessoa <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r'(.+),\s*João Pessoa$'</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    match_joao_pessoa <span class="op">=</span> pattern_joao_pessoa.search(address)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> match_joao_pessoa:</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> match_joao_pessoa.group(<span class="dv">1</span>).strip()</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    pattern_general <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r',\s*([^,]+)$'</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    match_general <span class="op">=</span> pattern_general.search(address)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> match_general:</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> match_general.group(<span class="dv">1</span>).strip()</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> clear_addr(x):</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    pattern <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r'[-,\s]*(.*?)\s*,?\s*João Pessoa - PB'</span>)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    extracted_parts <span class="op">=</span> [pattern.search(address).group(<span class="dv">1</span>) <span class="cf">if</span> pattern.search(address) <span class="cf">else</span> <span class="va">None</span> <span class="cf">for</span> address <span class="kw">in</span> x]</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [re.sub(<span class="vs">r'^.* - '</span>, <span class="st">''</span>, address) <span class="cf">for</span> address <span class="kw">in</span> extracted_parts]</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>df1 <span class="op">=</span> df1 <span class="op">\</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    .assign(</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>        bairro<span class="op">=</span><span class="kw">lambda</span> x: clear_addr(x.endereco),</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>        error<span class="op">=</span><span class="kw">lambda</span> x: <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> y: (<span class="st">'Rua'</span> <span class="kw">in</span> y) <span class="kw">or</span> (y <span class="op">==</span> <span class="st">''</span>), x.bairro.tolist())),</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">\</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    .query(<span class="st">'error == False'</span>) <span class="op">\</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>    .reset_index(drop<span class="op">=</span><span class="va">True</span>) <span class="op">\</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>    .drop(columns<span class="op">=</span>[<span class="st">'error'</span>]) <span class="op">\</span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>    .replace(</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Valentina Figueiredo'</span>: <span class="st">'Valentina de Figueiredo'</span>,</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Jardim Treze de Maio'</span>: <span class="st">'Jardim 13 de Maio'</span></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> df2.assign(bairro<span class="op">=</span><span class="kw">lambda</span> x: [extract_location(address) <span class="cf">for</span> address <span class="kw">in</span> x.endereco])</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>df_alg <span class="op">=</span> df_alg <span class="op">\</span></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>    .assign(bairro<span class="op">=</span><span class="kw">lambda</span> x: clear_addr(x.endereco)) <span class="op">\</span></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>    .replace({</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Altiplano Cabo Branco'</span>: <span class="st">'Altiplano'</span>,</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>        <span class="st">'ipes'</span>: <span class="st">'Bairro dos Ipes'</span>,</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Estados'</span>: <span class="st">'Bairro dos estados'</span>,</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Jardim Treze de Maio'</span>: <span class="st">'Jardim 13 de Maio'</span>,</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Ipês'</span>: <span class="st">'Bairro dos Ipes'</span></span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>df_alg <span class="op">=</span> df_alg <span class="op">\</span></span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>    .assign(</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>        bairro<span class="op">=</span><span class="kw">lambda</span> x: x.bairro.<span class="bu">str</span>.normalize(<span class="st">'NFKD'</span>) <span class="op">\</span></span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>            .<span class="bu">str</span>.encode(<span class="st">'ascii'</span>, errors<span class="op">=</span><span class="st">'ignore'</span>) <span class="op">\</span></span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>            .<span class="bu">str</span>.decode(<span class="st">'utf-8'</span>) <span class="op">\</span></span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>            .<span class="bu">str</span>.lower() <span class="op">\</span></span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a>            .<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">'_'</span>)</span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">\</span></span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a>    .rename(</span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>        columns<span class="op">=</span>{</span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a>            <span class="st">'area'</span>: <span class="st">'area_aluguel'</span>,</span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a>            <span class="st">'valor'</span>: <span class="st">'valor_aluguel'</span>,</span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 'vaga': 'vaga_aluguel',</span></span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 'quarto': 'quarto_aluguel',</span></span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 'banheiro': 'banheiro_aluguel'</span></span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a>        ) <span class="op">\</span></span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a>    .groupby([<span class="st">'bairro'</span>], as_index<span class="op">=</span><span class="va">False</span>) <span class="op">\</span></span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a>    [[<span class="st">'area_aluguel'</span>, <span class="st">'valor_aluguel'</span>]] <span class="op">\</span></span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a>    .median()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-5" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.concat([df1, df2]) <span class="op">\</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    .drop_duplicates(<span class="st">'id'</span>) <span class="op">\</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    .reset_index(drop<span class="op">=</span><span class="va">True</span>) <span class="op">\</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    .drop(columns<span class="op">=</span>[<span class="st">'id'</span>, <span class="st">'url'</span>]) <span class="op">\</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    .query(<span class="st">'bairro != "Monsenhor Magno"'</span>) <span class="op">\</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    .replace(</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Altiplano Cabo Branco'</span>: <span class="st">'Altiplano'</span>,</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Estados'</span>: <span class="st">'Bairro dos estados'</span>,</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Ipês'</span>: <span class="st">'Bairro dos ipes'</span>,</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Industrias'</span>: <span class="st">'Bairro das Industrias'</span>,</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Cidade dos Funcionarios II'</span>: <span class="st">'Funcionários II a IV'</span>,</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Cidade dos Colibris'</span>: <span class="st">'Colibris'</span>,</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Conjunto Pedro Gondim'</span>: <span class="st">'Pedro gondim'</span>,</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>            <span class="st">'José Américo de Almeida'</span>: <span class="st">'jose americo'</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df <span class="op">\</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    .assign(bairro<span class="op">=</span><span class="kw">lambda</span> x: x.bairro.<span class="bu">str</span>.normalize(<span class="st">'NFKD'</span>).<span class="bu">str</span>.encode(<span class="st">'ascii'</span>, errors<span class="op">=</span><span class="st">'ignore'</span>).<span class="bu">str</span>.decode(<span class="st">'utf-8'</span>).<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">'_'</span>).<span class="bu">str</span>.lower()) <span class="op">\</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    .merge(df_alg, on<span class="op">=</span><span class="st">'bairro'</span>, how<span class="op">=</span><span class="st">'left'</span>) <span class="op">\</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    .merge(df3, on<span class="op">=</span><span class="st">'bairro'</span>, how<span class="op">=</span><span class="st">'left'</span>) <span class="op">\</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    .reset_index(drop<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-7" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> remove_outliers_iqr(data, feature, threshold<span class="op">=</span><span class="fl">1.5</span>):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> data.copy()</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    q1, q3 <span class="op">=</span> np.percentile(df[feature],  [<span class="dv">1</span>, <span class="dv">99</span>])</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    iqr <span class="op">=</span> q3 <span class="op">-</span> q1</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    upper_bound <span class="op">=</span> q3 <span class="op">+</span> threshold <span class="op">*</span> iqr</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    removed_rows <span class="op">=</span> df[df[feature] <span class="op">&gt;</span> upper_bound].index</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(feature <span class="op">==</span> <span class="st">'valor'</span>):</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>        df <span class="op">=</span> df.drop(removed_rows, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> df.query(<span class="st">"valor &gt;= 40000"</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> df.drop(removed_rows, axis<span class="op">=</span><span class="dv">0</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-8" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.fillna(</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    value<span class="op">=</span>{</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>        <span class="st">"academia"</span>: <span class="dv">0</span>, <span class="st">"area_servico"</span>: <span class="dv">0</span>,</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">"elevador"</span>: <span class="dv">0</span>, <span class="st">"espaco_gourmet"</span>: <span class="dv">0</span>,</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">"piscina"</span>: <span class="dv">0</span>, <span class="st">"playground"</span>: <span class="dv">0</span>,</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">"portaria_24_horas"</span>: <span class="dv">0</span>, <span class="st">"quadra_de_esporte"</span>: <span class="dv">0</span>,</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">"salao_de_festa"</span>: <span class="dv">0</span>, <span class="st">"sauna"</span>: <span class="dv">0</span>,</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">"spa"</span>: <span class="dv">0</span>, <span class="st">"varanda_gourmet"</span>: <span class="dv">0</span>}</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">\</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    .replace([<span class="st">"flat"</span>, <span class="st">"terrenos_lotes_condominio"</span>],</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>             [<span class="st">"flats"</span>, <span class="st">"terrenos_lotes_e_condominios"</span>]) <span class="op">\</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    .assign(</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>        latitude_norm<span class="op">=</span><span class="kw">lambda</span> x: (x.latitude <span class="op">-</span> x.latitude.mean()) <span class="op">/</span> x.latitude.std(),</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>        longitude_norm<span class="op">=</span><span class="kw">lambda</span> x: (x.longitude <span class="op">-</span> x.longitude.mean()) <span class="op">/</span> x.longitude.std(),</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">\</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    .query(<span class="st">"-2 &lt; latitude_norm &lt; 2"</span>) <span class="op">\</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    .query(<span class="st">"-2 &lt; longitude_norm &lt; 2"</span>) <span class="op">\</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    .query(<span class="st">"area &lt; 150000 and area &gt;= 20 and valor &lt; 12_000_000 and valor &gt; 40000"</span>) <span class="op">\</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    .query(<span class="st">"tipo not in ['casas_de_vila', 'sobrados', 'coberturas', 'casas_comerciais']"</span>) <span class="op">\</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    .reset_index(drop<span class="op">=</span><span class="va">True</span>) <span class="op">\</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>    .drop(columns<span class="op">=</span>[<span class="st">"longitude_norm"</span>, <span class="st">"latitude_norm"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-9" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> remove_outliers_iqr(</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    df.assign(</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>        valor_area <span class="op">=</span> df.valor <span class="op">*</span> df.area</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>        ),</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"valor_area"</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">\</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    .drop(columns<span class="op">=</span>[<span class="st">"valor_area"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="train-and-test-dataset" class="level2">
<h2 class="anchored" data-anchor-id="train-and-test-dataset">Train and test dataset</h2>
<div id="cell-11" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'valor_cut'</span>] <span class="op">=</span> pd.cut(df[<span class="st">'valor'</span>],</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    bins<span class="op">=</span>[<span class="fl">0.</span>,<span class="fl">2e5</span>, <span class="fl">4e5</span>, <span class="fl">6e5</span>, <span class="fl">8e5</span>, np.inf],</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    labels<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>])</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>split <span class="op">=</span> StratifiedShuffleSplit(n_splits<span class="op">=</span><span class="dv">20</span>, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> train_index, test_index <span class="kw">in</span> split.split(df, df.valor_cut):</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    train_df <span class="op">=</span> df.loc[train_index]</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    test_df <span class="op">=</span> df.loc[test_index]</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> train_df.drop(columns<span class="op">=</span>[<span class="st">'valor_cut'</span>]).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>test_df <span class="op">=</span> test_df.drop(columns<span class="op">=</span>[<span class="st">'valor_cut'</span>]).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>df.drop(columns<span class="op">=</span>[<span class="st">"valor_cut"</span>]).to_csv(<span class="st">"../../data/cleaned/jp_limpo.csv"</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>train_df.to_csv(<span class="st">"../../data/cleaned/train.csv"</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>test_df.to_csv(<span class="st">"../../data/cleaned/test.csv"</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> train_df.drop(columns<span class="op">=</span>[<span class="st">'qnt_beneficio'</span>])</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>test_df <span class="op">=</span> test_df.drop(columns<span class="op">=</span>[<span class="st">'qnt_beneficio'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="missing-values" class="level2">
<h2 class="anchored" data-anchor-id="missing-values">Missing values</h2>
<div id="cell-13" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>g_missing <span class="op">=</span> sns.displot(</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>train_df.isnull() <span class="op">\</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>        .melt(value_name<span class="op">=</span><span class="st">"Valores ausentes"</span>) <span class="op">\</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>        .replace([<span class="va">False</span>, <span class="va">True</span>], [<span class="st">"Não é ausente"</span>, <span class="st">"Ausente"</span>]) <span class="op">\</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>        .groupby([<span class="st">"variable"</span>, <span class="st">"Valores ausentes"</span>]).size() <span class="op">\</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>        .reset_index(name<span class="op">=</span><span class="st">"count"</span>) <span class="op">\</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>        .assign(</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>            proportion<span class="op">=</span><span class="kw">lambda</span> x: x.groupby(<span class="st">"variable"</span>)[<span class="st">"count"</span>].transform(<span class="kw">lambda</span> y: y <span class="op">/</span> y.<span class="bu">sum</span>())</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>        ),</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    y<span class="op">=</span><span class="st">"variable"</span>,</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    hue<span class="op">=</span><span class="st">"Valores ausentes"</span>,</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    weights<span class="op">=</span><span class="st">"proportion"</span>,</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    multiple<span class="op">=</span><span class="st">"fill"</span>,</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    height<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    aspect<span class="op">=</span><span class="fl">1.1</span>,</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    palette<span class="op">=</span>{<span class="st">"Não é ausente"</span>: <span class="st">"#f9a602"</span>, <span class="st">"Ausente"</span>: <span class="st">"gray"</span>}</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>sns.move_legend(obj<span class="op">=</span>g_missing, loc<span class="op">=</span><span class="st">"upper center"</span>,</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>                bbox_to_anchor<span class="op">=</span>(<span class="fl">.5</span>, <span class="op">-</span><span class="fl">.0001</span>), ncol<span class="op">=</span><span class="dv">2</span>, title<span class="op">=</span><span class="st">""</span>)</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>g_missing.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="st">"Proporção de valores ausentes (%)"</span>, ylabel<span class="op">=</span><span class="st">""</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="modeling_files/figure-html/cell-11-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="some-functions" class="level3">
<h3 class="anchored" data-anchor-id="some-functions">Some functions</h3>
<div id="cell-15" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> display_scores(scores, confidence<span class="op">=</span><span class="fl">0.95</span>):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Scores:"</span>, scores)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Média:"</span>, scores.mean())</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Desvio Padrão:"</span>, scores.std())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-16" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_error(scores):</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    ax, fig <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">20</span>))</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    lineplot <span class="op">=</span> sns.lineplot(y<span class="op">=</span>scores, x<span class="op">=</span><span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">11</span>)))</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Raiz do erro quadrático médio'</span>, fontdict<span class="op">=</span>{<span class="st">'fontsize'</span>: <span class="dv">18</span>})</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'CV'</span>, fontdict<span class="op">=</span>{<span class="st">'fontsize'</span>: <span class="dv">14</span>})</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'RMSE'</span>, fontdict<span class="op">=</span>{<span class="st">'fontsize'</span>: <span class="dv">14</span>})</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    lineplot.set_xticklabels(lineplot.get_xticklabels(), fontdict<span class="op">=</span>{<span class="st">'fontsize'</span>: <span class="dv">13</span>})</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    lineplot.set_yticklabels(lineplot.get_yticklabels(), fontdict<span class="op">=</span>{<span class="st">'fontsize'</span>: <span class="dv">13</span>})</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-17" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_predict(model):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">20</span>))</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    scatter <span class="op">=</span> sns.scatterplot(y<span class="op">=</span>np.exp(model.predict(test_df.drop(<span class="st">'valor'</span>, axis<span class="op">=</span><span class="dv">1</span>))), x<span class="op">=</span>np.exp(test_df.valor) <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Predições VS Valores Reais'</span>, fontdict<span class="op">=</span>{<span class="st">'fontsize'</span>: <span class="dv">18</span>})</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Valores Reais'</span>, fontdict<span class="op">=</span>{<span class="st">'fontsize'</span>: <span class="dv">13</span>})</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Predições'</span>, fontdict<span class="op">=</span>{<span class="st">'fontsize'</span>: <span class="dv">13</span>})</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-18" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>gbr_native <span class="op">=</span> ensemble.GradientBoostingRegressor()</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>lgbm_native <span class="op">=</span> LGBMRegressor()</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>rf_native <span class="op">=</span> ensemble.RandomForestRegressor()</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>xgboost_native <span class="op">=</span> XGBRegressor()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="modeling" class="level2">
<h2 class="anchored" data-anchor-id="modeling">Modeling</h2>
<div id="cell-20" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> train_df.assign(valor<span class="op">=</span><span class="kw">lambda</span> x: np.log1p(x.valor))</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>test_df <span class="op">=</span> test_df.assign(valor<span class="op">=</span><span class="kw">lambda</span> x: np.log1p(x.valor))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-21" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>drop_cols_fit <span class="op">=</span> [<span class="st">'endereco'</span>, <span class="st">'bairro'</span>, <span class="st">'iptu'</span>, <span class="st">'condominio'</span>]</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>pipe_jp <span class="op">=</span> Pipeline(</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    [(<span class="st">"imputer"</span>, Imputer()),</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>     (<span class="st">"new_feature"</span>, BedAreaBedToi()),</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>     (<span class="st">"ordinal_encoder"</span>, OrdEncoder()),</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>     (<span class="st">"onehot_encoder"</span>, OneEncoder()),</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>     (<span class="st">"log_transform"</span>, LogTransform()),</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>     (<span class="st">"scaling"</span>, Scale())</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>pipe_jp.fit(train_df.drop(columns<span class="op">=</span>drop_cols_fit))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[('imputer', Imputer()), ('new_feature', BedAreaBedToi()),
                ('ordinal_encoder', OrdEncoder()),
                ('onehot_encoder', OneEncoder()),
                ('log_transform', LogTransform()), ('scaling', Scale())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label  sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox"><label for="sk-estimator-id-1" class="sk-toggleable__label  sk-toggleable__label-arrow ">&nbsp;&nbsp;Pipeline<a class="sk-estimator-doc-link " rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html">?<span>Documentation for Pipeline</span></a><span class="sk-estimator-doc-link ">i<span>Not fitted</span></span></label><div class="sk-toggleable__content "><pre>Pipeline(steps=[('imputer', Imputer()), ('new_feature', BedAreaBedToi()),
                ('ordinal_encoder', OrdEncoder()),
                ('onehot_encoder', OneEncoder()),
                ('log_transform', LogTransform()), ('scaling', Scale())])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator  sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox"><label for="sk-estimator-id-2" class="sk-toggleable__label  sk-toggleable__label-arrow ">Imputer</label><div class="sk-toggleable__content "><pre>Imputer()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator  sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox"><label for="sk-estimator-id-3" class="sk-toggleable__label  sk-toggleable__label-arrow ">BedAreaBedToi</label><div class="sk-toggleable__content "><pre>BedAreaBedToi()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator  sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox"><label for="sk-estimator-id-4" class="sk-toggleable__label  sk-toggleable__label-arrow ">OrdEncoder</label><div class="sk-toggleable__content "><pre>OrdEncoder()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator  sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox"><label for="sk-estimator-id-5" class="sk-toggleable__label  sk-toggleable__label-arrow ">OneEncoder</label><div class="sk-toggleable__content "><pre>OneEncoder()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator  sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox"><label for="sk-estimator-id-6" class="sk-toggleable__label  sk-toggleable__label-arrow ">LogTransform</label><div class="sk-toggleable__content "><pre>LogTransform()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator  sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox"><label for="sk-estimator-id-7" class="sk-toggleable__label  sk-toggleable__label-arrow ">Scale</label><div class="sk-toggleable__content "><pre>Scale()</pre></div> </div></div></div></div></div></div>
</div>
</div>
<div id="cell-22" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>train_df_novo <span class="op">=</span> pipe_jp.transform(train_df.drop(columns<span class="op">=</span>drop_cols_fit))</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>test_df_novo <span class="op">=</span> pipe_jp.transform(test_df.drop(columns<span class="op">=</span>drop_cols_fit))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-23" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># s = setup(train_df_novo, target='valor')</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="co"># best = compare_models()</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="optim" class="level2">
<h2 class="anchored" data-anchor-id="optim">Optim</h2>
<section id="lgbm" class="level3">
<h3 class="anchored" data-anchor-id="lgbm">LGBM</h3>
<div id="cell-26" class="cell" data-execution_count="119">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> objective_lgbm(trial):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    num_leaves <span class="op">=</span> trial.suggest_int(<span class="st">'num_leaves'</span>, <span class="dv">100</span>, <span class="dv">500</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    max_depth <span class="op">=</span> trial.suggest_int(<span class="st">'max_depth'</span>, <span class="dv">100</span>, <span class="dv">500</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    learning_rate <span class="op">=</span> trial.suggest_float(<span class="st">'learning_rate'</span>, <span class="fl">1e-4</span>, <span class="fl">.01</span>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    n_estimators <span class="op">=</span> trial.suggest_int(<span class="st">'n_estimators'</span>, <span class="dv">100</span>, <span class="dv">2000</span>)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> LGBMRegressor(</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>        num_leaves<span class="op">=</span>num_leaves,</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>        max_depth<span class="op">=</span>max_depth,</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>        learning_rate<span class="op">=</span>learning_rate,</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>        n_estimators<span class="op">=</span>n_estimators,</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    model.fit(X<span class="op">=</span>train_df_novo.drop(<span class="st">'valor'</span>, axis<span class="op">=</span><span class="dv">1</span>), y<span class="op">=</span>train_df_novo.valor)</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>    cv_scores <span class="op">=</span> np.exp(np.sqrt(<span class="op">-</span>cross_val_score(</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>        estimator<span class="op">=</span>model,</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>        X<span class="op">=</span>train_df_novo.drop(<span class="st">'valor'</span>, axis<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>        y<span class="op">=</span>train_df_novo.valor,</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>        scoring<span class="op">=</span><span class="st">'neg_mean_squared_error'</span>,</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>        cv<span class="op">=</span>KFold(n_splits<span class="op">=</span><span class="dv">20</span>))))</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean(cv_scores)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-27" class="cell" data-execution_count="120">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>study_lgbm <span class="op">=</span> optuna.create_study(direction<span class="op">=</span><span class="st">"minimize"</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>study_lgbm.optimize(objective_lgbm, n_trials<span class="op">=</span><span class="dv">100</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, show_progress_bar<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2024-09-10 19:23:09,687] A new study created in memory with name: no-name-34f1c535-9f59-47ce-8718-377b675d3778</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"026586e89646431691404322b3774416","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[LightGBM] [Info] [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027471 seconds.
You can set `force_col_wise=true` to remove the overhead.
Auto-choosing row-wise multi-threading, the overhead of testing was 0.016206 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013653 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007235 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016178 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006165 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018141 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008063 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008297 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005828 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011954 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009138 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006924 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006938 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010616 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008330 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006968 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025849 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007153 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007555 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007055 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006919 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007101 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006997 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006958 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006639 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007060 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007000 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007118 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006943 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007125 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017175 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007092 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006929 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008942 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007051 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006886 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017171 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007288 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004917 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007027 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013521 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006898 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009943 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006896 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006649 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006622 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011047 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007107 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006867 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011327 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005175 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007284 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007503 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006476 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007744 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007559 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010233 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015124 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006805 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007158 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011753 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006438 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006866 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[I 2024-09-10 19:26:04,235] Trial 5 finished with value: 1.8888941262293497 and parameters: {'num_leaves': 124, 'max_depth': 326, 'learning_rate': 0.0009085279807714038, 'n_estimators': 139}. Best is trial 5 with value: 1.8888941262293497.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009364 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007197 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006899 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007139 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006909 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019407 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006906 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007210 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006887 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007070 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006895 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007116 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007062 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007286 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009527 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006902 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006922 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006921 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007219 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006926 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007033 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006819 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014229 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006932 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007087 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011829 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006970 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007705 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006895 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014552 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011453 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[I 2024-09-10 19:28:23,576] Trial 4 finished with value: 1.8633652794951179 and parameters: {'num_leaves': 300, 'max_depth': 453, 'learning_rate': 0.0013639452554953958, 'n_estimators': 110}. Best is trial 4 with value: 1.8633652794951179.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007497 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018993 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012132 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007063 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006864 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007367 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010061 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007188 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007710 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007195 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006518 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008048 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011690 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007096 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007038 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005804 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026497 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006726 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006891 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007704 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018474 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007387 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009179 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007234 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007302 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010369 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010304 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007222 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007164 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009656 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006909 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012665 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[I 2024-09-10 19:32:03,786] Trial 7 finished with value: 1.331621291317336 and parameters: {'num_leaves': 207, 'max_depth': 313, 'learning_rate': 0.00833675222374556, 'n_estimators': 259}. Best is trial 7 with value: 1.331621291317336.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007513 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007127 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006925 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006375 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007140 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007132 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007239 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007291 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006650 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007260 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015313 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007174 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010740 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007936 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007138 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007025 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007260 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007378 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007155 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007164 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007176 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006333 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011612 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008445 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009885 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008288 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008372 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005000 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008308 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007826 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025587 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007654 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011743 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006974 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006955 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029026 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007193 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009055 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007167 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058380 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011549 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009526 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007029 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008845 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006471 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007180 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012487 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004081 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015358 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006958 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007103 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007124 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006960 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006998 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008900 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006920 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008437 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006973 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007147 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013315 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010955 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007195 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010734 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007233 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017072 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010155 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007412 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007158 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006572 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009921 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007228 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014312 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010681 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008180 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011980 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007836 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006739 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007263 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007699 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005090 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004315 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007071 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007292 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008182 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007145 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007204 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007136 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007073 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007179 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007602 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009163 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011725 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007764 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007393 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014441 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012630 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007170 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007116 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011922 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011108 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007224 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007241 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010070 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010646 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006832 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007600 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008508 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014458 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007281 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007136 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007127 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007328 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007240 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007264 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007396 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007318 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006772 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008349 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007500 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012320 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[I 2024-09-10 19:49:55,930] Trial 10 finished with value: 1.2956209131536927 and parameters: {'num_leaves': 159, 'max_depth': 340, 'learning_rate': 0.0074551400419583524, 'n_estimators': 1070}. Best is trial 10 with value: 1.2956209131536927.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011591 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063557 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008526 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007033 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008819 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012366 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007913 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005103 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009277 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007182 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005979 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006745 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006610 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007150 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007017 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007185 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011101 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009118 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007181 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006743 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008908 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007145 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007074 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010537 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007033 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007180 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007070 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007308 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007162 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007952 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013816 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009460 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007182 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008880 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007537 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011819 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007234 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007453 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007227 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007214 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008541 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007306 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007250 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006978 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[I 2024-09-10 19:56:43,717] Trial 6 finished with value: 1.2936018960596 and parameters: {'num_leaves': 346, 'max_depth': 126, 'learning_rate': 0.009638751242640221, 'n_estimators': 654}. Best is trial 6 with value: 1.2936018960596.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014637 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007236 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007239 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005064 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005267 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006674 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007285 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007119 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005741 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008493 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007093 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007113 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007390 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006727 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015198 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[I 2024-09-10 19:58:42,048] Trial 1 finished with value: 1.3027053978125829 and parameters: {'num_leaves': 252, 'max_depth': 104, 'learning_rate': 0.004400728053086252, 'n_estimators': 903}. Best is trial 6 with value: 1.2936018960596.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007390 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007079 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007089 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[I 2024-09-10 19:59:01,737] Trial 3 finished with value: 1.2996853844150615 and parameters: {'num_leaves': 313, 'max_depth': 460, 'learning_rate': 0.005631019273495918, 'n_estimators': 755}. Best is trial 6 with value: 1.2936018960596.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008295 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007194 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007037 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007689 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007605 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014587 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004782 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006677 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007242 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007118 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007248 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008136 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007285 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006660 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007279 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007124 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008145 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007611 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[I 2024-09-10 20:01:57,492] Trial 9 finished with value: 1.2985978282447912 and parameters: {'num_leaves': 160, 'max_depth': 101, 'learning_rate': 0.004118548033563286, 'n_estimators': 1499}. Best is trial 6 with value: 1.2936018960596.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012834 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010832 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007029 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[I 2024-09-10 20:02:14,795] Trial 16 finished with value: 1.3007121980931138 and parameters: {'num_leaves': 244, 'max_depth': 360, 'learning_rate': 0.004665144975717375, 'n_estimators': 942}. Best is trial 6 with value: 1.2936018960596.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008800 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007288 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007191 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007607 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013534 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009814 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007146 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007022 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007180 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007694 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007219 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010668 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007135 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011431 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006388 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007228 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010158 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007202 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006039 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007180 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006501 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007182 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007469 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007355 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016333 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007480 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010575 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007220 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007835 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007278 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[I 2024-09-10 20:06:53,134] Trial 12 finished with value: 1.2947480020840962 and parameters: {'num_leaves': 275, 'max_depth': 421, 'learning_rate': 0.005844598082461582, 'n_estimators': 1042}. Best is trial 6 with value: 1.2936018960596.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007700 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007864 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007172 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007115 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007098 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063158 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007427 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007769 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007439 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007384 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007245 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007993 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008808 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007084 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007413 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007068 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007143 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008037 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007309 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007138 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011308 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012131 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007117 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007093 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007111 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006238 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007184 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[I 2024-09-10 20:11:16,572] Trial 22 finished with value: 1.4598692345118554 and parameters: {'num_leaves': 365, 'max_depth': 300, 'learning_rate': 0.004335334154833436, 'n_estimators': 218}. Best is trial 6 with value: 1.2936018960596.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011488 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007237 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007060 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007173 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025542 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007132 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007206 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007050 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012157 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008508 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006890 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[I 2024-09-10 20:14:01,320] Trial 13 finished with value: 1.2930289795713379 and parameters: {'num_leaves': 209, 'max_depth': 185, 'learning_rate': 0.005316384502943655, 'n_estimators': 1605}. Best is trial 13 with value: 1.2930289795713379.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009302 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008795 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007206 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009646 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018201 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011192 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[I 2024-09-10 20:15:19,456] Trial 0 finished with value: 1.2985098858000614 and parameters: {'num_leaves': 260, 'max_depth': 393, 'learning_rate': 0.0036979337500339733, 'n_estimators': 1314}. Best is trial 13 with value: 1.2930289795713379.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007082 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007359 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007296 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007458 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007557 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007132 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007667 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007614 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007149 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006692 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007110 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007201 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007309 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007054 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007206 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007439 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007115 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007551 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007290 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013303 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007211 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011404 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007282 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011809 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007243 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008122 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007202 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[I 2024-09-10 20:21:04,298] Trial 8 finished with value: 1.305000910469023 and parameters: {'num_leaves': 226, 'max_depth': 418, 'learning_rate': 0.0023392386505755886, 'n_estimators': 1605}. Best is trial 13 with value: 1.2930289795713379.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008938 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006560 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007175 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013144 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007395 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004476 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[I 2024-09-10 20:22:52,883] Trial 14 finished with value: 1.2917644281155298 and parameters: {'num_leaves': 421, 'max_depth': 440, 'learning_rate': 0.007481214238186208, 'n_estimators': 980}. Best is trial 14 with value: 1.2917644281155298.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011517 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007154 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007319 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006641 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006977 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010518 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007109 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007120 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007267 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007150 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010933 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007238 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012918 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[I 2024-09-10 20:26:02,617] Trial 18 finished with value: 1.2975716108857152 and parameters: {'num_leaves': 346, 'max_depth': 307, 'learning_rate': 0.004505492312427836, 'n_estimators': 1041}. Best is trial 14 with value: 1.2917644281155298.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011709 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008202 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007369 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007801 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006651 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007186 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005796 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007250 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008958 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016539 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005877 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008922 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007293 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007367 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008343 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007046 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007051 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007353 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007214 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007213 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007107 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007176 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012808 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007293 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007161 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008063 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008345 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008145 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007178 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007169 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005068 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[I 2024-09-10 20:34:52,207] Trial 2 finished with value: 1.2879806368741575 and parameters: {'num_leaves': 302, 'max_depth': 215, 'learning_rate': 0.009453217825511515, 'n_estimators': 1638}. Best is trial 2 with value: 1.2879806368741575.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006682 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012248 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007504 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010055 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009835 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007150 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007048 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007985 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004688 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007437 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011146 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007570 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006302 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006239 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007199 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007061 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010362 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007185 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014090 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007410 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007199 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006800 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008385 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007217 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007299 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006729 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007756 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007216 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006633 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007489 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007231 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007199 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032997 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007087 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007302 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007098 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007032 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007310 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007171 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007436 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009875 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007451 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007281 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007169 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029145 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008930 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007346 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007223 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014252 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008115 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007718 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007611 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010700 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[I 2024-09-10 20:49:57,561] Trial 23 finished with value: 1.2898895096609768 and parameters: {'num_leaves': 326, 'max_depth': 111, 'learning_rate': 0.009707129989194326, 'n_estimators': 1035}. Best is trial 2 with value: 1.2879806368741575.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007456 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011693 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007123 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007586 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007341 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007167 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016507 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[I 2024-09-10 20:52:21,393] Trial 21 finished with value: 1.3511443680449962 and parameters: {'num_leaves': 171, 'max_depth': 256, 'learning_rate': 0.000934419628113736, 'n_estimators': 1947}. Best is trial 2 with value: 1.2879806368741575.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007415 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007086 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007564 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007280 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007144 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007172 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007275 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008163 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009554 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007226 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010201 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009617 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008547 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007254 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010961 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011143 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007209 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007425 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006350 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007928 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010526 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007147 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007217 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007915 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011830 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008358 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010001 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018288 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007332 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008806 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006452 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008236 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007401 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008080 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007988 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006440 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[I 2024-09-10 21:04:07,801] Trial 11 finished with value: 1.3228800504942346 and parameters: {'num_leaves': 365, 'max_depth': 344, 'learning_rate': 0.0012577464654169883, 'n_estimators': 1794}. Best is trial 2 with value: 1.2879806368741575.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008405 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007157 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007180 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009534 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008078 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007090 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013600 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007072 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006272 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007116 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007069 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007889 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007259 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007263 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006842 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007083 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007555 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030922 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007642 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009787 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007216 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007126 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007289 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007763 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029310 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010574 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007851 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007207 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007694 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009659 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007554 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010679 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008931 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007808 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007208 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009335 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007100 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006884 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007292 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007088 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007307 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007110 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007309 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007328 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007207 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007179 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007120 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010850 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[I 2024-09-10 21:19:34,919] Trial 19 finished with value: 1.3015913038936775 and parameters: {'num_leaves': 430, 'max_depth': 483, 'learning_rate': 0.002562419373109656, 'n_estimators': 1423}. Best is trial 2 with value: 1.2879806368741575.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011810 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007125 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007778 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010476 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010290 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006798 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007172 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007202 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007394 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007319 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010058 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007275 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009505 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007209 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007078 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007145 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007191 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006374 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006298 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[I 2024-09-10 21:26:21,390] Trial 17 finished with value: 1.2887649080733907 and parameters: {'num_leaves': 459, 'max_depth': 434, 'learning_rate': 0.00864611146058949, 'n_estimators': 1874}. Best is trial 2 with value: 1.2879806368741575.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008463 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013551 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007119 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007136 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007190 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007094 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008353 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010502 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011866 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007807 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007279 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012065 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007075 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007260 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014191 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007100 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009907 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007080 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007306 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005582 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008395 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006754 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007064 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007451 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007119 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006491 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013966 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009432 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[I 2024-09-10 21:34:39,200] Trial 20 finished with value: 1.2884479731663363 and parameters: {'num_leaves': 369, 'max_depth': 280, 'learning_rate': 0.00671051343195281, 'n_estimators': 1873}. Best is trial 2 with value: 1.2879806368741575.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007455 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[I 2024-09-10 21:34:51,121] Trial 15 finished with value: 1.2921516756968303 and parameters: {'num_leaves': 466, 'max_depth': 415, 'learning_rate': 0.003553385357818102, 'n_estimators': 1944}. Best is trial 2 with value: 1.2879806368741575.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007453 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010771 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012289 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007097 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007368 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[I 2024-09-10 21:36:38,708] Trial 24 finished with value: 1.3069654164290816 and parameters: {'num_leaves': 458, 'max_depth': 193, 'learning_rate': 0.0021695165665743116, 'n_estimators': 1377}. Best is trial 2 with value: 1.2879806368741575.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006850 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007192 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007304 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007278 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010394 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010913 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007110 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[I 2024-09-10 21:39:26,709] Trial 26 finished with value: 1.2886885293809733 and parameters: {'num_leaves': 466, 'max_depth': 187, 'learning_rate': 0.009945613976810562, 'n_estimators': 1353}. Best is trial 2 with value: 1.2879806368741575.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007375 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007225 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008296 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007551 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007569 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007255 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011148 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007250 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007297 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006268 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007258 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008396 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009936 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007393 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007350 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007182 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007296 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011713 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017893 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[I 2024-09-10 21:45:48,799] Trial 25 finished with value: 1.2883038680849228 and parameters: {'num_leaves': 429, 'max_depth': 215, 'learning_rate': 0.00960331669481315, 'n_estimators': 1680}. Best is trial 2 with value: 1.2879806368741575.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008624 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020895 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011737 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008346 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007502 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007290 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020710 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009089 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007253 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006815 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012090 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007928 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007199 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007639 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008008 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012018 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014233 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007328 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016474 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010554 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007324 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004649 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007344 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012022 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007325 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007900 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008746 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007959 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007072 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007722 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007126 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007189 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007865 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008384 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007096 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007094 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025450 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010899 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012814 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008892 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007207 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007832 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007255 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007493 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014277 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007179 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007805 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007154 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007163 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007898 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010670 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012232 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007172 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008305 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007674 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010039 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010867 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007201 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006391 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007123 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007262 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005040 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007520 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007145 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007285 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007298 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009433 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007097 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007234 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007278 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007343 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007240 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007307 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010769 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010500 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007858 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010227 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006432 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007375 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007220 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007990 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007185 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009480 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007221 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007211 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007256 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006866 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007125 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009248 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012682 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007165 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[I 2024-09-10 22:16:24,838] Trial 27 finished with value: 1.2887583794113031 and parameters: {'num_leaves': 447, 'max_depth': 199, 'learning_rate': 0.009902007933574038, 'n_estimators': 1979}. Best is trial 2 with value: 1.2879806368741575.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008289 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008315 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007307 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007358 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007661 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007205 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016538 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004192 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007931 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009494 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006832 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007356 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007480 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[I 2024-09-10 22:21:21,499] Trial 28 finished with value: 1.288832541741252 and parameters: {'num_leaves': 466, 'max_depth': 191, 'learning_rate': 0.00992141587803275, 'n_estimators': 1976}. Best is trial 2 with value: 1.2879806368741575.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014118 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009827 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006946 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007259 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010660 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007523 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007268 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007282 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007522 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007364 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023916 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008918 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012471 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008038 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009622 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007568 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009504 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007348 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007044 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007332 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018765 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009923 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007345 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007159 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007407 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007464 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[I 2024-09-10 22:29:54,042] Trial 30 finished with value: 1.2891416185762599 and parameters: {'num_leaves': 495, 'max_depth': 218, 'learning_rate': 0.007069899473511358, 'n_estimators': 1846}. Best is trial 2 with value: 1.2879806368741575.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007725 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007540 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010215 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[I 2024-09-10 22:30:15,153] Trial 35 finished with value: 1.2886949917243533 and parameters: {'num_leaves': 479, 'max_depth': 234, 'learning_rate': 0.009507244590415865, 'n_estimators': 1287}. Best is trial 2 with value: 1.2879806368741575.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007433 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[I 2024-09-10 22:31:56,309] Trial 31 finished with value: 1.288812950493592 and parameters: {'num_leaves': 465, 'max_depth': 219, 'learning_rate': 0.007090765330017072, 'n_estimators': 1939}. Best is trial 2 with value: 1.2879806368741575.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007393 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011011 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007595 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010857 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008528 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010104 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008412 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[I 2024-09-10 22:33:28,741] Trial 32 finished with value: 1.2885644618236114 and parameters: {'num_leaves': 457, 'max_depth': 243, 'learning_rate': 0.0098324286175661, 'n_estimators': 1881}. Best is trial 2 with value: 1.2879806368741575.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012721 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014220 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007103 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[I 2024-09-10 22:34:09,268] Trial 29 finished with value: 1.289288427208838 and parameters: {'num_leaves': 499, 'max_depth': 192, 'learning_rate': 0.009421148155778566, 'n_estimators': 1961}. Best is trial 2 with value: 1.2879806368741575.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012179 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007131 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006741 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007217 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011183 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007625 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007238 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005945 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007318 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010471 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007071 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019371 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057055 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007213 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007210 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010951 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008478 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008235 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007387 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007771 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011627 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007248 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007479 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007190 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007668 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007336 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007017 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014144 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009371 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007073 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006761 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007129 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[I 2024-09-10 22:44:11,280] Trial 36 finished with value: 1.2891857383166552 and parameters: {'num_leaves': 482, 'max_depth': 228, 'learning_rate': 0.00997215361769557, 'n_estimators': 1242}. Best is trial 2 with value: 1.2879806368741575.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009262 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007753 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[I 2024-09-10 22:45:03,828] Trial 33 finished with value: 1.288484595621123 and parameters: {'num_leaves': 425, 'max_depth': 225, 'learning_rate': 0.0099931819627154, 'n_estimators': 1959}. Best is trial 2 with value: 1.2879806368741575.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012264 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007672 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013867 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008219 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010785 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006907 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015336 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007195 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007166 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007286 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047081 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014053 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008347 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007201 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007331 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007443 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007224 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007284 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006162 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013646 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007163 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007090 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007134 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011304 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012045 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005534 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007177 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014397 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008390 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006589 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007609 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007367 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007206 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007246 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006684 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010877 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007408 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007114 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009369 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008462 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007559 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012639 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007671 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011480 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007191 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011370 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004405 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[I 2024-09-10 22:58:54,708] Trial 34 finished with value: 1.2894992275706416 and parameters: {'num_leaves': 478, 'max_depth': 186, 'learning_rate': 0.009989950687345681, 'n_estimators': 1939}. Best is trial 2 with value: 1.2879806368741575.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006666 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007195 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007617 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007002 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013320 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006509 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009533 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007479 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007378 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007106 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013595 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007321 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007441 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006965 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007456 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014027 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007288 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010235 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007408 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010051 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010409 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007786 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007130 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006044 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006622 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007590 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007269 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007603 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009087 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007250 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012946 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006506 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007329 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007184 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008041 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007396 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012670 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007314 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008400 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007200 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014086 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007847 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025703 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007317 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009310 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015306 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007147 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007063 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012016 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[I 2024-09-10 23:15:47,811] Trial 40 finished with value: 1.2879658058727403 and parameters: {'num_leaves': 400, 'max_depth': 248, 'learning_rate': 0.008715883576757923, 'n_estimators': 1787}. Best is trial 40 with value: 1.2879658058727403.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016301 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011215 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008336 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008256 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011276 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009870 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007293 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017819 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008195 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008623 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007102 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011085 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007124 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010161 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015203 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009483 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007244 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007069 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007190 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007220 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011959 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008950 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007134 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007237 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007111 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007163 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007287 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008038 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[I 2024-09-10 23:24:11,503] Trial 42 finished with value: 1.289018644872671 and parameters: {'num_leaves': 408, 'max_depth': 253, 'learning_rate': 0.006609026886632434, 'n_estimators': 1732}. Best is trial 40 with value: 1.2879658058727403.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012900 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007131 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014005 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007762 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007225 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008296 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007215 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007319 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007500 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007776 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011294 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007128 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009353 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009013 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007275 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007166 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011413 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007227 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006717 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005980 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007152 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007206 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013424 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010652 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006778 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007112 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007139 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006731 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015470 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007847 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009412 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007305 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007162 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007669 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007455 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007240 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007647 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007351 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[I 2024-09-10 23:34:53,480] Trial 37 finished with value: 1.289008134273176 and parameters: {'num_leaves': 485, 'max_depth': 236, 'learning_rate': 0.009964612416301174, 'n_estimators': 1943}. Best is trial 40 with value: 1.2879658058727403.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009185 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007182 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[I 2024-09-10 23:35:50,243] Trial 39 finished with value: 1.2891963196254725 and parameters: {'num_leaves': 500, 'max_depth': 239, 'learning_rate': 0.008609744067721649, 'n_estimators': 1752}. Best is trial 40 with value: 1.2879658058727403.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011181 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007211 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007220 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007396 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007412 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007098 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007100 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007187 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011332 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018295 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010448 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006852 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007929 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[I 2024-09-10 23:39:13,674] Trial 41 finished with value: 1.2891364722526313 and parameters: {'num_leaves': 497, 'max_depth': 247, 'learning_rate': 0.00673386401839319, 'n_estimators': 1734}. Best is trial 40 with value: 1.2879658058727403.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008200 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012481 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008206 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006704 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007200 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007345 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011189 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007110 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007065 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007346 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007228 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007158 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013175 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007123 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007816 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007081 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011625 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007143 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006682 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010125 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007253 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007053 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014968 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010351 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008705 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007150 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007016 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010953 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013058 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007173 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007281 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010145 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007087 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007300 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[I 2024-09-10 23:49:26,661] Trial 38 finished with value: 1.289323417562128 and parameters: {'num_leaves': 496, 'max_depth': 245, 'learning_rate': 0.008586425073110023, 'n_estimators': 1981}. Best is trial 40 with value: 1.2879658058727403.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007432 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007501 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007159 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007692 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009473 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007208 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007258 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007182 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009831 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007261 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011871 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007248 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007512 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010931 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[I 2024-09-10 23:53:37,361] Trial 43 finished with value: 1.287943457894141 and parameters: {'num_leaves': 396, 'max_depth': 246, 'learning_rate': 0.008613085068554033, 'n_estimators': 1757}. Best is trial 43 with value: 1.287943457894141.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004287 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007038 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007213 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008068 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008512 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007247 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007163 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007090 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007330 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007651 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007157 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009916 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007173 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007297 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017935 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008198 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009171 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007127 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006356 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010882 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007255 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007709 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010558 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007193 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009919 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010495 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007293 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010709 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009794 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007204 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007182 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016472 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007180 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011318 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007677 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014379 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007169 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007260 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006247 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007180 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009731 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013487 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[I 2024-09-11 00:06:07,570] Trial 47 finished with value: 1.2883853286954765 and parameters: {'num_leaves': 398, 'max_depth': 154, 'learning_rate': 0.00873056069249709, 'n_estimators': 1707}. Best is trial 43 with value: 1.287943457894141.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007465 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[I 2024-09-11 00:06:07,736] Trial 46 finished with value: 1.2883782470784024 and parameters: {'num_leaves': 405, 'max_depth': 149, 'learning_rate': 0.008639067558922759, 'n_estimators': 1693}. Best is trial 43 with value: 1.287943457894141.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008909 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007626 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007238 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018451 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011049 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007213 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008075 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[I 2024-09-11 00:07:12,603] Trial 45 finished with value: 1.288122937094244 and parameters: {'num_leaves': 399, 'max_depth': 257, 'learning_rate': 0.00864837533634594, 'n_estimators': 1715}. Best is trial 43 with value: 1.287943457894141.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009390 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006711 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013965 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010995 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009778 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008014 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007622 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007291 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007219 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007193 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007667 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[I 2024-09-11 00:10:49,051] Trial 48 finished with value: 1.2882221255012758 and parameters: {'num_leaves': 402, 'max_depth': 264, 'learning_rate': 0.00868416030458711, 'n_estimators': 1730}. Best is trial 43 with value: 1.287943457894141.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007477 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007356 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017399 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010731 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007437 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012633 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007284 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007114 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007154 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007420 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007400 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[I 2024-09-11 00:14:10,680] Trial 49 finished with value: 1.2882859570879215 and parameters: {'num_leaves': 404, 'max_depth': 274, 'learning_rate': 0.008650914625682262, 'n_estimators': 1725}. Best is trial 43 with value: 1.287943457894141.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007602 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057588 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006752 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007102 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012828 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008643 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007282 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009104 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005612 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008776 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007306 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007245 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007301 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011861 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[I 2024-09-11 00:18:19,119] Trial 44 finished with value: 1.28936457174114 and parameters: {'num_leaves': 499, 'max_depth': 245, 'learning_rate': 0.006377604450194677, 'n_estimators': 1667}. Best is trial 43 with value: 1.287943457894141.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016442 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010504 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[I 2024-09-11 00:18:21,700] Trial 51 finished with value: 1.2880675014882603 and parameters: {'num_leaves': 392, 'max_depth': 274, 'learning_rate': 0.008656441863845853, 'n_estimators': 1714}. Best is trial 43 with value: 1.287943457894141.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007845 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010853 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007296 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012078 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007493 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007199 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007979 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009381 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007926 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008150 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012055 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[I 2024-09-11 00:20:39,496] Trial 50 finished with value: 1.2882899047066696 and parameters: {'num_leaves': 400, 'max_depth': 275, 'learning_rate': 0.008567945774107126, 'n_estimators': 1724}. Best is trial 43 with value: 1.287943457894141.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013155 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008303 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006695 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007295 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007110 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008509 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007116 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007599 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007179 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007605 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009337 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008826 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007227 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037331 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011109 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007216 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007236 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007208 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010086 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008314 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007421 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007195 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008058 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007101 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008202 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007226 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007201 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007195 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006220 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007195 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007158 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007434 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007194 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008519 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007790 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011094 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013818 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011513 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008439 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007272 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007192 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005906 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009100 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009990 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009660 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007259 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007169 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007968 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005316 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007300 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007168 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009687 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007168 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007726 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007284 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007135 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007150 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012602 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007434 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007113 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007202 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017299 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007212 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011997 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013920 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010609 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008327 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007021 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008332 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[I 2024-09-11 00:37:58,165] Trial 52 finished with value: 1.288398007738253 and parameters: {'num_leaves': 411, 'max_depth': 271, 'learning_rate': 0.008584757048806372, 'n_estimators': 1726}. Best is trial 43 with value: 1.287943457894141.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007429 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013714 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007133 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007178 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007189 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007689 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007433 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009513 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010988 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007167 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007287 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012528 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018655 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007263 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014142 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011055 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007159 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009674 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007264 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007119 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011112 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007179 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007022 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007554 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007627 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008094 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007100 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010697 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009315 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007102 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007129 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007097 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007084 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007126 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007080 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007205 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007155 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008642 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007622 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012799 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007144 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007133 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007095 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013213 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007123 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010138 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007645 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007125 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008491 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006941 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007292 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007349 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008480 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007101 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007253 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007491 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007166 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013204 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007262 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007122 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007129 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[I 2024-09-11 00:52:41,655] Trial 53 finished with value: 1.2882880847988247 and parameters: {'num_leaves': 397, 'max_depth': 272, 'learning_rate': 0.00882038383578108, 'n_estimators': 1724}. Best is trial 43 with value: 1.287943457894141.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007734 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007294 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007236 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007631 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004128 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007028 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007269 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007287 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006812 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008518 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017167 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007176 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008430 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005589 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007487 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007251 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007242 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009793 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007309 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[I 2024-09-11 00:57:29,866] Trial 54 finished with value: 1.2883135134210693 and parameters: {'num_leaves': 397, 'max_depth': 278, 'learning_rate': 0.008628076435076848, 'n_estimators': 1668}. Best is trial 43 with value: 1.287943457894141.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007654 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007500 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007205 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007148 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007119 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007678 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007495 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007087 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007284 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007129 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007194 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007132 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007264 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004642 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010993 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009783 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011815 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011566 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007213 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008062 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007796 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010212 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014584 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007972 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007247 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009211 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006713 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006688 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014004 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007265 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007266 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007442 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008197 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007145 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007170 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[I 2024-09-11 01:05:48,233] Trial 55 finished with value: 1.2885512561807941 and parameters: {'num_leaves': 385, 'max_depth': 279, 'learning_rate': 0.008423311882784907, 'n_estimators': 1681}. Best is trial 43 with value: 1.287943457894141.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014349 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007011 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012004 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006862 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[I 2024-09-11 01:07:09,113] Trial 56 finished with value: 1.287926186161836 and parameters: {'num_leaves': 392, 'max_depth': 151, 'learning_rate': 0.009115418897558352, 'n_estimators': 1649}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007387 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007283 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[I 2024-09-11 01:07:36,276] Trial 57 finished with value: 1.2886987964280887 and parameters: {'num_leaves': 384, 'max_depth': 279, 'learning_rate': 0.008995929234668732, 'n_estimators': 1633}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007454 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008293 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007196 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005808 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008163 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010812 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010312 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007044 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007663 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008710 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006373 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[I 2024-09-11 01:09:56,971] Trial 62 finished with value: 1.2888163956782661 and parameters: {'num_leaves': 280, 'max_depth': 276, 'learning_rate': 0.00786441351755678, 'n_estimators': 1572}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005666 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010421 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007185 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071267 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010316 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007615 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007427 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007158 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008987 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007056 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010212 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006170 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007327 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008547 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006093 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007661 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008644 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017884 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006511 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007160 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007110 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007896 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007218 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007283 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007500 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007594 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008802 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007255 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007496 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007261 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007268 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035132 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[I 2024-09-11 01:16:51,425] Trial 64 finished with value: 1.2880462036930962 and parameters: {'num_leaves': 277, 'max_depth': 272, 'learning_rate': 0.009137883759837435, 'n_estimators': 1583}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006430 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007127 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007856 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007314 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008452 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[I 2024-09-11 01:18:26,515] Trial 58 finished with value: 1.288092643975017 and parameters: {'num_leaves': 394, 'max_depth': 275, 'learning_rate': 0.008031254429835417, 'n_estimators': 1619}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008042 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014300 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007169 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007262 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007154 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007208 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007208 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007088 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030244 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006786 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006846 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006741 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007270 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007122 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007495 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007216 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007653 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007156 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010890 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009146 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[I 2024-09-11 01:22:51,238] Trial 65 finished with value: 1.288707161913701 and parameters: {'num_leaves': 290, 'max_depth': 280, 'learning_rate': 0.008142452658470765, 'n_estimators': 1535}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007649 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007097 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005902 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007094 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007244 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006708 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009180 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008487 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009336 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007514 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009011 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007266 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007222 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006700 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011196 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[I 2024-09-11 01:25:38,337] Trial 59 finished with value: 1.288652861730629 and parameters: {'num_leaves': 392, 'max_depth': 272, 'learning_rate': 0.008016014805952664, 'n_estimators': 1650}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012660 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008456 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008875 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007184 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011622 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007293 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008362 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007321 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007316 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007253 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007082 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007239 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007270 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007616 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007598 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007209 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007316 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007284 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007900 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007083 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016609 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010027 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007047 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006839 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007433 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007423 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008658 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005936 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011975 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014566 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018203 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010014 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[I 2024-09-11 01:32:50,407] Trial 61 finished with value: 1.2886186886067692 and parameters: {'num_leaves': 399, 'max_depth': 152, 'learning_rate': 0.00797761932964959, 'n_estimators': 1563}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008557 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007208 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008338 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007156 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007152 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012184 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006817 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007127 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007818 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007172 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006977 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007432 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[I 2024-09-11 01:35:58,229] Trial 60 finished with value: 1.2887655489428778 and parameters: {'num_leaves': 395, 'max_depth': 135, 'learning_rate': 0.008016616541014111, 'n_estimators': 1610}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008826 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009474 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007336 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[I 2024-09-11 01:36:26,369] Trial 63 finished with value: 1.2882515732574042 and parameters: {'num_leaves': 383, 'max_depth': 275, 'learning_rate': 0.007983093215241146, 'n_estimators': 1579}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009391 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007213 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016445 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008528 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007391 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007608 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009879 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007354 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007283 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013613 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007176 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007285 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007212 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007214 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007123 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[I 2024-09-11 01:40:03,184] Trial 66 finished with value: 1.2885070653479362 and parameters: {'num_leaves': 379, 'max_depth': 275, 'learning_rate': 0.007928207845490759, 'n_estimators': 1535}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017781 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007167 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007163 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020231 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006854 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009459 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013874 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012513 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007606 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009492 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006709 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020413 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007088 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007510 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009225 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007135 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009781 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007264 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007185 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[I 2024-09-11 01:43:53,109] Trial 67 finished with value: 1.288734607384652 and parameters: {'num_leaves': 381, 'max_depth': 288, 'learning_rate': 0.007951414811410856, 'n_estimators': 1515}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007385 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007093 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007168 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007384 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007165 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006343 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007207 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007229 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030776 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011321 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008979 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008071 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007430 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007611 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006637 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007222 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017031 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007188 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006488 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007184 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007289 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007251 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007110 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008932 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007147 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007204 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009215 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007077 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007199 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007100 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007223 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007335 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009325 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007058 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007150 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007195 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010962 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007213 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007903 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007313 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007183 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007139 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012038 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007170 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007250 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007285 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005488 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004700 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007211 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007269 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007145 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007164 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013160 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007443 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006965 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007216 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007192 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007344 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007475 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007550 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007327 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007127 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008857 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007371 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007175 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007216 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007442 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009199 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007306 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008222 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007383 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007964 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007229 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007137 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007167 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007387 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007164 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007395 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007141 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007207 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010618 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011243 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006969 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006673 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007592 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007140 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006741 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[I 2024-09-11 02:01:44,240] Trial 68 finished with value: 1.2883498295654556 and parameters: {'num_leaves': 382, 'max_depth': 327, 'learning_rate': 0.0079861836311939, 'n_estimators': 1563}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007423 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008875 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008313 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007202 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009593 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007067 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007194 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011749 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009817 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007669 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007135 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007229 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007207 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008832 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011697 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007241 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007196 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007240 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007225 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011717 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008196 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013679 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006405 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007374 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007248 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013215 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006172 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007022 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007140 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007203 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007129 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007152 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006832 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011166 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011467 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007279 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007237 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029471 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[I 2024-09-11 02:09:52,231] Trial 72 finished with value: 1.288525361680658 and parameters: {'num_leaves': 286, 'max_depth': 160, 'learning_rate': 0.008058449526294637, 'n_estimators': 1506}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007552 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007070 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007284 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[I 2024-09-11 02:10:16,621] Trial 73 finished with value: 1.2887375413419035 and parameters: {'num_leaves': 281, 'max_depth': 163, 'learning_rate': 0.007797099357442786, 'n_estimators': 1545}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012318 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012815 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007101 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040231 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012450 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007324 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010619 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007168 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010882 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009263 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007159 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006813 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[I 2024-09-11 02:13:01,890] Trial 71 finished with value: 1.2885859157304123 and parameters: {'num_leaves': 303, 'max_depth': 325, 'learning_rate': 0.00798351575639665, 'n_estimators': 1552}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008218 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007106 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007485 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007452 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018615 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010982 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004863 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007171 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007088 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007098 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012065 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[I 2024-09-11 02:15:24,989] Trial 69 finished with value: 1.2888198610259392 and parameters: {'num_leaves': 383, 'max_depth': 323, 'learning_rate': 0.007940434186244733, 'n_estimators': 1538}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008840 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007137 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007117 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007191 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008248 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007202 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007122 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009798 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007145 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007151 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007154 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011679 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010491 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009170 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007049 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007900 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008138 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007349 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007184 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[I 2024-09-11 02:19:14,674] Trial 70 finished with value: 1.2890347303058765 and parameters: {'num_leaves': 380, 'max_depth': 316, 'learning_rate': 0.007913739277596985, 'n_estimators': 1526}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007601 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008927 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007784 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007215 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009782 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014673 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007082 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007317 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007233 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007149 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010680 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006441 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008540 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008119 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[I 2024-09-11 02:21:54,824] Trial 74 finished with value: 1.2883083648228675 and parameters: {'num_leaves': 334, 'max_depth': 165, 'learning_rate': 0.007939239406822307, 'n_estimators': 1532}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007518 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007025 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007092 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009469 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007297 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007248 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006494 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018272 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011138 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007241 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[I 2024-09-11 02:23:38,316] Trial 75 finished with value: 1.2885217818585868 and parameters: {'num_leaves': 313, 'max_depth': 165, 'learning_rate': 0.008118821315717416, 'n_estimators': 1498}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007908 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007137 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007140 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007190 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008627 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009897 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007396 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007237 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007655 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007065 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007410 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007408 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007161 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007227 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007752 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007186 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007241 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007312 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006647 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007418 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007108 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007654 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007154 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007196 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014646 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007415 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007164 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009488 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007127 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007604 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011932 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013320 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007178 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007898 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007359 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006806 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010573 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[I 2024-09-11 02:30:20,929] Trial 76 finished with value: 1.288819253213516 and parameters: {'num_leaves': 334, 'max_depth': 325, 'learning_rate': 0.007967606278806176, 'n_estimators': 1500}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010636 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007358 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010439 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007122 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007120 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006665 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007078 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006833 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007166 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007358 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[I 2024-09-11 02:33:13,898] Trial 78 finished with value: 1.2885471110719293 and parameters: {'num_leaves': 319, 'max_depth': 316, 'learning_rate': 0.007778414844461937, 'n_estimators': 1481}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007300 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008050 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008142 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007182 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009525 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007120 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007260 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006078 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009533 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006839 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007095 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007256 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007102 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007261 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009915 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007277 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007119 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007191 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006605 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[I 2024-09-11 02:36:36,547] Trial 77 finished with value: 1.2886059125920415 and parameters: {'num_leaves': 350, 'max_depth': 316, 'learning_rate': 0.009302242600595109, 'n_estimators': 1510}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011861 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007295 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007239 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007123 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007083 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007138 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007777 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007199 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007091 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007107 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007244 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007093 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012980 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007503 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007250 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015218 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007408 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007110 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010616 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016262 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012339 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[I 2024-09-11 02:40:11,542] Trial 80 finished with value: 1.2883151309303507 and parameters: {'num_leaves': 315, 'max_depth': 325, 'learning_rate': 0.009341922760112769, 'n_estimators': 1430}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007451 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010868 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[I 2024-09-11 02:40:24,223] Trial 79 finished with value: 1.2883831593672037 and parameters: {'num_leaves': 323, 'max_depth': 326, 'learning_rate': 0.009165468581364614, 'n_estimators': 1466}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007362 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007209 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007119 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007507 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007178 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007364 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026087 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008261 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007041 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007495 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006626 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011452 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009377 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006733 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007035 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009587 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006681 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007128 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007185 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007213 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007515 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007492 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[I 2024-09-11 02:44:41,352] Trial 89 finished with value: 1.298337945588561 and parameters: {'num_leaves': 346, 'max_depth': 206, 'learning_rate': 0.009280851644125863, 'n_estimators': 496}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006922 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007533 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007366 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007154 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006392 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013923 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008438 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009836 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[I 2024-09-11 02:46:37,114] Trial 81 finished with value: 1.2881254706492542 and parameters: {'num_leaves': 341, 'max_depth': 324, 'learning_rate': 0.009163230466142267, 'n_estimators': 1441}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007334 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007207 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007546 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008309 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007487 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007089 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011527 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007208 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007266 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007755 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007241 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007168 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007648 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007110 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008115 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007638 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007962 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007251 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007786 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[I 2024-09-11 02:50:40,928] Trial 83 finished with value: 1.2883004249266568 and parameters: {'num_leaves': 322, 'max_depth': 312, 'learning_rate': 0.00913342319111189, 'n_estimators': 1455}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007095 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 25424, number of used features: 28
[LightGBM] [Info] Start training from score 13.051175
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009988 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[I 2024-09-11 02:50:52,524] Trial 82 finished with value: 1.2884506305991235 and parameters: {'num_leaves': 349, 'max_depth': 314, 'learning_rate': 0.009175093910149857, 'n_estimators': 1444}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007318 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006644 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006529 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006012 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006796 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008911 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012759 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007684 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007081 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007160 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009425 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006439 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005954 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.049849
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004557 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007171 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005009 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006394 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007315 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007250 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006633 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010072 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005534 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007249 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007149 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006522 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006386 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020158 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050742
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007071 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007138 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009909 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006661 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006734 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006206 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007627 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007171 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006708 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007348 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007171 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006630 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005823 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006761 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010494 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005477 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.050045
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007186 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007892 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006656 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006604 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007878 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007062 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006708 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006424 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007186 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005099 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007971 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007280 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006542 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1566
[LightGBM] [Info] Number of data points in the train set: 24152, number of used features: 28
[LightGBM] [Info] Start training from score 13.052698
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006546 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007181 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006543 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019072 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004349 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007054 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007266 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006097 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010805 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006458 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[I 2024-09-11 03:04:39,544] Trial 84 finished with value: 1.2883889037241198 and parameters: {'num_leaves': 314, 'max_depth': 368, 'learning_rate': 0.00916381967366789, 'n_estimators': 1435}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008178 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007195 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006355 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051550
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007727 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006014 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005833 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009077 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006596 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006324 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006402 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006876 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006997 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004938 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005627 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007573 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007151 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051511
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006331 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005253 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004758 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007107 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006901 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008853 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006885 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006591 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005640 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006510 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006428 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004385 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004279 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005186 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005464 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052040
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006994 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007677 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006370 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006101 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007085 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004093 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005475 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007079 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009601 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006158 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007101 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013931 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005813 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006925 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005943 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007190 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050835
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005308 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006639 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006603 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006621 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007017 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008029 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007127 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007216 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006178 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007073 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006811 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006415 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005139 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007476 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008105 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009790 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006994 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[I 2024-09-11 03:19:31,385] Trial 86 finished with value: 1.2885856558969857 and parameters: {'num_leaves': 347, 'max_depth': 298, 'learning_rate': 0.0091025275461434, 'n_estimators': 1441}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005828 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007054 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[I 2024-09-11 03:20:04,541] Trial 85 finished with value: 1.2884372488530822 and parameters: {'num_leaves': 348, 'max_depth': 207, 'learning_rate': 0.009290222602879867, 'n_estimators': 1449}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005806 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007192 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006850 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051292
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004495 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005872 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006276 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004711 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007349 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[I 2024-09-11 03:22:04,273] Trial 88 finished with value: 1.2884608443105 and parameters: {'num_leaves': 340, 'max_depth': 205, 'learning_rate': 0.009184223048040473, 'n_estimators': 1450}. Best is trial 56 with value: 1.287926186161836.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005454 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004435 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005888 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005494 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005339 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007048 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004270 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005029 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005879 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005382 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004406 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051216
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005511 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006008 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005739 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006114 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006133 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[I 2024-09-11 03:26:05,309] Trial 91 finished with value: 1.2875611162912575 and parameters: {'num_leaves': 258, 'max_depth': 208, 'learning_rate': 0.00912207951785099, 'n_estimators': 1805}. Best is trial 91 with value: 1.2875611162912575.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005792 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004394 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005188 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006499 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004249 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004848 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008086 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005789 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004390 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1563
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051392
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004140 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003778 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004172 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004060 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003396 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003813 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004051 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005624 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005930 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005812 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[I 2024-09-11 03:30:57,088] Trial 92 finished with value: 1.2872628799212893 and parameters: {'num_leaves': 259, 'max_depth': 292, 'learning_rate': 0.00917722596166284, 'n_estimators': 1808}. Best is trial 92 with value: 1.2872628799212893.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003991 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003522 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003201 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004148 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003742 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1570
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.053273
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003208 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[I 2024-09-11 03:32:29,502] Trial 87 finished with value: 1.2877141978055586 and parameters: {'num_leaves': 347, 'max_depth': 295, 'learning_rate': 0.009103427614265759, 'n_estimators': 1793}. Best is trial 92 with value: 1.2872628799212893.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003697 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002207 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003404 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003499 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[I 2024-09-11 03:33:38,772] Trial 93 finished with value: 1.2873530040801575 and parameters: {'num_leaves': 262, 'max_depth': 297, 'learning_rate': 0.009152620050178643, 'n_estimators': 1781}. Best is trial 92 with value: 1.2872628799212893.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002616 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002392 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002479 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002241 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002574 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1568
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051603
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002842 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002224 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[I 2024-09-11 03:35:47,345] Trial 96 finished with value: 1.2872202373330905 and parameters: {'num_leaves': 247, 'max_depth': 299, 'learning_rate': 0.009035568789398086, 'n_estimators': 1798}. Best is trial 96 with value: 1.2872202373330905.
[I 2024-09-11 03:36:28,890] Trial 95 finished with value: 1.287693408414637 and parameters: {'num_leaves': 253, 'max_depth': 204, 'learning_rate': 0.00907782785777219, 'n_estimators': 1813}. Best is trial 96 with value: 1.2872202373330905.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002225 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002259 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002017 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002177 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002069 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.052448
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003021 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[I 2024-09-11 03:38:05,140] Trial 98 finished with value: 1.2875908100457774 and parameters: {'num_leaves': 247, 'max_depth': 294, 'learning_rate': 0.008976582096901688, 'n_estimators': 1771}. Best is trial 96 with value: 1.2872202373330905.
[I 2024-09-11 03:38:21,297] Trial 97 finished with value: 1.2876945578000285 and parameters: {'num_leaves': 256, 'max_depth': 299, 'learning_rate': 0.008938549016057666, 'n_estimators': 1798}. Best is trial 96 with value: 1.2872202373330905.
[I 2024-09-11 03:38:25,784] Trial 90 finished with value: 1.2877343790501707 and parameters: {'num_leaves': 351, 'max_depth': 205, 'learning_rate': 0.009163591519177037, 'n_estimators': 1810}. Best is trial 96 with value: 1.2872202373330905.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001430 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001369 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050988
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001303 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001322 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1564
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050144
[I 2024-09-11 03:39:38,940] Trial 99 finished with value: 1.2875824162002316 and parameters: {'num_leaves': 262, 'max_depth': 351, 'learning_rate': 0.008979989194785373, 'n_estimators': 1819}. Best is trial 96 with value: 1.2872202373330905.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000946 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.051200
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000951 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1567
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050427
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000921 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1569
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.049331
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000933 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1565
[LightGBM] [Info] Number of data points in the train set: 24153, number of used features: 28
[LightGBM] [Info] Start training from score 13.050917
[I 2024-09-11 03:40:28,876] Trial 94 finished with value: 1.288274223442139 and parameters: {'num_leaves': 437, 'max_depth': 206, 'learning_rate': 0.009065718884813358, 'n_estimators': 1810}. Best is trial 96 with value: 1.2872202373330905.</code></pre>
</div>
</div>
<div id="cell-28" class="cell" data-execution_count="125">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>best_params_lgbm <span class="op">=</span> {</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'num_leaves'</span>: <span class="dv">247</span>,</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: <span class="dv">299</span>,</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'learning_rate'</span>: <span class="fl">0.009035568789398086</span>,</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'n_estimators'</span>: <span class="dv">1798</span>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-29" class="cell" data-execution_count="127">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>joblib.dump(study_lgbm, <span class="st">'study_pkl/study_lgbm.pkl'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="127">
<pre><code>['study_pkl/study_lgbm.pkl']</code></pre>
</div>
</div>
</section>
<section id="random-forest" class="level3">
<h3 class="anchored" data-anchor-id="random-forest">Random Forest</h3>
<div id="cell-31" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>forest <span class="op">=</span> ensemble.RandomForestRegressor(</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">1500</span>,</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    max_features<span class="op">=</span><span class="st">"sqrt"</span>,</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-32" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>forest.fit(X<span class="op">=</span>train_df_novo.drop(columns<span class="op">=</span>[<span class="st">'valor'</span>]), y<span class="op">=</span>train_df_novo.valor)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<style>#sk-container-id-4 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-4 {
  color: var(--sklearn-color-text);
}

#sk-container-id-4 pre {
  padding: 0;
}

#sk-container-id-4 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-4 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-4 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-4 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-4 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-4 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-4 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-4 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-4 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-4 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-4 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-4 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-4 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-4 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-4 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-4 div.sk-label label.sk-toggleable__label,
#sk-container-id-4 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-4 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-4 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-4 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-4 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-4 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-4 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-4 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-4 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-4" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>RandomForestRegressor(max_depth=100, max_features='sqrt', n_estimators=1500,
                      n_jobs=1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-12" type="checkbox" checked=""><label for="sk-estimator-id-12" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;RandomForestRegressor<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestRegressor.html">?<span>Documentation for RandomForestRegressor</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>RandomForestRegressor(max_depth=100, max_features='sqrt', n_estimators=1500,
                      n_jobs=1, random_state=42)</pre></div> </div></div></div></div>
</div>
</div>
<div id="cell-33" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>forest.score(X<span class="op">=</span>test_df_novo.drop(columns<span class="op">=</span>[<span class="st">'valor'</span>]), y<span class="op">=</span>test_df_novo.valor)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="45">
<pre><code>0.8660368903247242</code></pre>
</div>
</div>
<div id="cell-34" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>test_df_clone <span class="op">=</span> test_df.copy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-35" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> forest.predict(X<span class="op">=</span>test_df_novo.drop(columns<span class="op">=</span>[<span class="st">'valor'</span>]))</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>test_df_clone[<span class="st">'preds'</span>] <span class="op">=</span> preds</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-36" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(data<span class="op">=</span>test_df_clone, x<span class="op">=</span><span class="st">'preds'</span>, y<span class="op">=</span><span class="st">'valor'</span>, hue<span class="op">=</span><span class="st">'tipo'</span>, alpha<span class="op">=</span><span class="fl">.6</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="modeling_files/figure-html/cell-29-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-37" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> objective_rf(trial):</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>    params <span class="op">=</span> <span class="bu">dict</span>(</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>        n_estimators<span class="op">=</span>trial.suggest_int(name<span class="op">=</span><span class="st">'n_estimators'</span>, low<span class="op">=</span><span class="dv">1</span>, high<span class="op">=</span><span class="dv">1000</span>),</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>        max_depth<span class="op">=</span>trial.suggest_int(name<span class="op">=</span><span class="st">'max_depth'</span>, low<span class="op">=</span><span class="dv">20</span>, high<span class="op">=</span><span class="dv">1000</span>),</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>        max_features<span class="op">=</span><span class="st">'sqrt'</span>,</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> ensemble.RandomForestRegressor(</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>        <span class="op">**</span>params,</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>        n_jobs<span class="op">=</span><span class="dv">3</span></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>    model.fit(X<span class="op">=</span>train_df_novo.drop(<span class="st">'valor'</span>, axis<span class="op">=</span><span class="dv">1</span>), y<span class="op">=</span>train_df_novo.valor)</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>    cv_scores <span class="op">=</span> np.exp(np.sqrt(<span class="op">-</span>cross_val_score(</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>        estimator<span class="op">=</span>model,</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>        X<span class="op">=</span>train_df_novo.drop(<span class="st">"valor"</span>, axis<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>        y<span class="op">=</span>train_df_novo.valor,</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>        scoring<span class="op">=</span><span class="st">"neg_mean_squared_error"</span>,</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>        n_jobs<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>        cv<span class="op">=</span>KFold(n_splits<span class="op">=</span><span class="dv">20</span>))))</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean(cv_scores)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-38" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>joblib.dump(study, <span class="st">'study_pkl/study_rf.pkl'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>['study_pkl/study_rf.pkl']</code></pre>
</div>
</div>
<div id="cell-39" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>study <span class="op">=</span> optuna.create_study(direction<span class="op">=</span><span class="st">"minimize"</span>)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>study.optimize(objective_rf, n_trials<span class="op">=</span><span class="dv">100</span>, show_progress_bar<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2024-09-11 22:49:19,647] A new study created in memory with name: no-name-b9bcb42c-6caa-474e-9f40-a58c2912094a
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(
/home/cowvin/.cache/pypoetry/virtualenvs/scrapy-zap-SVflkDOc-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1580525f8ff4431e8d5de9f63ece3723","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[I 2024-09-11 22:50:38,696] Trial 0 finished with value: 1.3004480838192738 and parameters: {'n_estimators': 287, 'max_depth': 862}. Best is trial 0 with value: 1.3004480838192738.
[I 2024-09-11 22:53:46,204] Trial 1 finished with value: 1.29967715517818 and parameters: {'n_estimators': 687, 'max_depth': 490}. Best is trial 1 with value: 1.29967715517818.
[I 2024-09-11 22:57:29,496] Trial 2 finished with value: 1.2996182581633962 and parameters: {'n_estimators': 851, 'max_depth': 840}. Best is trial 2 with value: 1.2996182581633962.
[I 2024-09-11 22:59:52,412] Trial 3 finished with value: 1.2997950505443376 and parameters: {'n_estimators': 593, 'max_depth': 609}. Best is trial 2 with value: 1.2996182581633962.
[I 2024-09-11 23:01:16,967] Trial 4 finished with value: 1.3001112012078295 and parameters: {'n_estimators': 366, 'max_depth': 577}. Best is trial 2 with value: 1.2996182581633962.
[I 2024-09-11 23:02:22,013] Trial 5 finished with value: 1.300511519645649 and parameters: {'n_estimators': 284, 'max_depth': 139}. Best is trial 2 with value: 1.2996182581633962.
[I 2024-09-11 23:02:37,604] Trial 6 finished with value: 1.3028724339330906 and parameters: {'n_estimators': 67, 'max_depth': 213}. Best is trial 2 with value: 1.2996182581633962.
[I 2024-09-11 23:18:09,791] Trial 7 finished with value: 1.299583984904427 and parameters: {'n_estimators': 984, 'max_depth': 980}. Best is trial 7 with value: 1.299583984904427.
[I 2024-09-11 23:19:21,063] Trial 8 finished with value: 1.3006888130927843 and parameters: {'n_estimators': 215, 'max_depth': 938}. Best is trial 7 with value: 1.299583984904427.
[I 2024-09-11 23:20:06,085] Trial 9 finished with value: 1.3007860380558305 and parameters: {'n_estimators': 197, 'max_depth': 651}. Best is trial 7 with value: 1.299583984904427.
[I 2024-09-11 23:24:52,187] Trial 10 finished with value: 1.2995807065274165 and parameters: {'n_estimators': 995, 'max_depth': 359}. Best is trial 10 with value: 1.2995807065274165.
[I 2024-09-11 23:49:38,536] Trial 11 finished with value: 1.2995803419604244 and parameters: {'n_estimators': 996, 'max_depth': 322}. Best is trial 11 with value: 1.2995803419604244.
[I 2024-09-12 00:13:51,569] Trial 12 finished with value: 1.29958357014105 and parameters: {'n_estimators': 985, 'max_depth': 353}. Best is trial 11 with value: 1.2995803419604244.
[I 2024-09-12 00:17:37,168] Trial 13 finished with value: 1.2994631241095669 and parameters: {'n_estimators': 784, 'max_depth': 33}. Best is trial 13 with value: 1.2994631241095669.
[I 2024-09-12 00:22:03,764] Trial 14 finished with value: 1.2996604389900583 and parameters: {'n_estimators': 792, 'max_depth': 56}. Best is trial 13 with value: 1.2994631241095669.
[I 2024-09-12 00:25:10,314] Trial 15 finished with value: 1.2968341239844148 and parameters: {'n_estimators': 778, 'max_depth': 23}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 00:27:04,068] Trial 16 finished with value: 1.2990768248795286 and parameters: {'n_estimators': 491, 'max_depth': 29}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 00:29:00,802] Trial 17 finished with value: 1.2999876266642836 and parameters: {'n_estimators': 485, 'max_depth': 201}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 00:30:41,600] Trial 18 finished with value: 1.2971424005593368 and parameters: {'n_estimators': 490, 'max_depth': 21}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 00:33:14,905] Trial 19 finished with value: 1.299761196944646 and parameters: {'n_estimators': 619, 'max_depth': 163}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 00:34:55,811] Trial 20 finished with value: 1.3000934839311031 and parameters: {'n_estimators': 439, 'max_depth': 263}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 00:37:08,991] Trial 21 finished with value: 1.2998408894907059 and parameters: {'n_estimators': 558, 'max_depth': 74}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 00:38:49,562] Trial 22 finished with value: 1.2991847082411123 and parameters: {'n_estimators': 418, 'max_depth': 30}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 00:41:39,601] Trial 23 finished with value: 1.2996774459907137 and parameters: {'n_estimators': 686, 'max_depth': 150}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 00:43:40,052] Trial 24 finished with value: 1.2999163899211563 and parameters: {'n_estimators': 510, 'max_depth': 273}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 00:46:35,391] Trial 25 finished with value: 1.2996797886537457 and parameters: {'n_estimators': 695, 'max_depth': 110}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 00:47:56,624] Trial 26 finished with value: 1.3001921583056988 and parameters: {'n_estimators': 348, 'max_depth': 425}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 00:49:58,437] Trial 27 finished with value: 1.2998958575936597 and parameters: {'n_estimators': 519, 'max_depth': 699}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 00:53:39,746] Trial 28 finished with value: 1.2971441415115013 and parameters: {'n_estimators': 901, 'max_depth': 24}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 00:57:34,967] Trial 29 finished with value: 1.2995920392725226 and parameters: {'n_estimators': 882, 'max_depth': 112}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 01:01:50,141] Trial 30 finished with value: 1.299591526532494 and parameters: {'n_estimators': 867, 'max_depth': 226}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 01:04:21,238] Trial 31 finished with value: 1.2983364796920758 and parameters: {'n_estimators': 621, 'max_depth': 28}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 01:07:42,201] Trial 32 finished with value: 1.299668647847507 and parameters: {'n_estimators': 770, 'max_depth': 98}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 01:10:04,683] Trial 33 finished with value: 1.296933170152314 and parameters: {'n_estimators': 646, 'max_depth': 23}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 01:12:50,623] Trial 34 finished with value: 1.299692695295486 and parameters: {'n_estimators': 701, 'max_depth': 772}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 01:24:02,669] Trial 35 finished with value: 1.299587626899879 and parameters: {'n_estimators': 901, 'max_depth': 178}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 01:27:15,143] Trial 36 finished with value: 1.2996825233479536 and parameters: {'n_estimators': 757, 'max_depth': 467}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 01:33:04,959] Trial 37 finished with value: 1.299581931513686 and parameters: {'n_estimators': 923, 'max_depth': 95}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 01:37:27,716] Trial 38 finished with value: 1.2996325975432224 and parameters: {'n_estimators': 815, 'max_depth': 280}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 01:40:06,457] Trial 39 finished with value: 1.299697142944444 and parameters: {'n_estimators': 668, 'max_depth': 537}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 01:43:53,817] Trial 40 finished with value: 1.299663062793002 and parameters: {'n_estimators': 739, 'max_depth': 137}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 01:46:37,957] Trial 41 finished with value: 1.2983455705245777 and parameters: {'n_estimators': 620, 'max_depth': 28}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 01:49:12,890] Trial 42 finished with value: 1.2998096791063136 and parameters: {'n_estimators': 570, 'max_depth': 80}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 01:51:44,968] Trial 43 finished with value: 1.2997648887764188 and parameters: {'n_estimators': 618, 'max_depth': 77}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 01:54:42,706] Trial 44 finished with value: 1.297021372757683 and parameters: {'n_estimators': 832, 'max_depth': 21}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 01:58:24,448] Trial 45 finished with value: 1.2996422105710281 and parameters: {'n_estimators': 831, 'max_depth': 138}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 02:14:57,678] Trial 46 finished with value: 1.2995830524399694 and parameters: {'n_estimators': 918, 'max_depth': 236}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 02:15:28,358] Trial 47 finished with value: 1.3049622044265201 and parameters: {'n_estimators': 43, 'max_depth': 191}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 02:20:22,232] Trial 48 finished with value: 1.2995771969651937 and parameters: {'n_estimators': 941, 'max_depth': 67}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 02:24:42,644] Trial 49 finished with value: 1.2996205639065763 and parameters: {'n_estimators': 839, 'max_depth': 127}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 02:27:27,832] Trial 50 finished with value: 1.296865728211315 and parameters: {'n_estimators': 731, 'max_depth': 23}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 02:31:27,093] Trial 51 finished with value: 1.2996759499716695 and parameters: {'n_estimators': 719, 'max_depth': 57}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 02:33:54,226] Trial 52 finished with value: 1.2972076135758908 and parameters: {'n_estimators': 659, 'max_depth': 24}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 02:38:05,846] Trial 53 finished with value: 1.2996508764938441 and parameters: {'n_estimators': 801, 'max_depth': 65}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 02:42:56,474] Trial 54 finished with value: 1.299621456958411 and parameters: {'n_estimators': 856, 'max_depth': 163}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 02:46:28,336] Trial 55 finished with value: 1.2973049785693092 and parameters: {'n_estimators': 961, 'max_depth': 20}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 02:46:58,180] Trial 56 finished with value: 1.3014935817407085 and parameters: {'n_estimators': 125, 'max_depth': 874}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 02:50:57,278] Trial 57 finished with value: 1.299663062793002 and parameters: {'n_estimators': 739, 'max_depth': 115}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 02:52:42,063] Trial 58 finished with value: 1.3001055138799658 and parameters: {'n_estimators': 440, 'max_depth': 318}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 02:53:49,840] Trial 59 finished with value: 1.3003018296605706 and parameters: {'n_estimators': 293, 'max_depth': 69}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 02:56:06,394] Trial 60 finished with value: 1.2998468035219566 and parameters: {'n_estimators': 544, 'max_depth': 201}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 02:59:39,426] Trial 61 finished with value: 1.299661546550364 and parameters: {'n_estimators': 679, 'max_depth': 46}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 03:01:57,205] Trial 62 finished with value: 1.2970711871281277 and parameters: {'n_estimators': 653, 'max_depth': 21}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 03:06:47,096] Trial 63 finished with value: 1.299667221725112 and parameters: {'n_estimators': 786, 'max_depth': 88}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 03:09:06,369] Trial 64 finished with value: 1.299806903489215 and parameters: {'n_estimators': 585, 'max_depth': 111}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 03:10:52,775] Trial 65 finished with value: 1.3000382494457476 and parameters: {'n_estimators': 456, 'max_depth': 53}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 03:12:22,096] Trial 66 finished with value: 1.3000629736578824 and parameters: {'n_estimators': 386, 'max_depth': 160}. Best is trial 15 with value: 1.2968341239844148.
[I 2024-09-12 03:14:42,427] Trial 67 finished with value: 1.2968276888752437 and parameters: {'n_estimators': 650, 'max_depth': 22}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 03:16:50,719] Trial 68 finished with value: 1.299853155569862 and parameters: {'n_estimators': 541, 'max_depth': 626}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 03:19:27,793] Trial 69 finished with value: 1.2996820488066938 and parameters: {'n_estimators': 648, 'max_depth': 86}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 03:22:33,846] Trial 70 finished with value: 1.299683665705548 and parameters: {'n_estimators': 713, 'max_depth': 393}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 03:26:58,009] Trial 71 finished with value: 1.299585788686159 and parameters: {'n_estimators': 884, 'max_depth': 47}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 03:31:13,321] Trial 72 finished with value: 1.299657081546395 and parameters: {'n_estimators': 749, 'max_depth': 44}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 03:34:30,637] Trial 73 finished with value: 1.2996551197138309 and parameters: {'n_estimators': 795, 'max_depth': 115}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 03:37:13,819] Trial 74 finished with value: 1.2977171398120793 and parameters: {'n_estimators': 634, 'max_depth': 25}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 03:39:36,370] Trial 75 finished with value: 1.2997950505443376 and parameters: {'n_estimators': 593, 'max_depth': 83}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 03:41:33,302] Trial 76 finished with value: 1.2999806093195583 and parameters: {'n_estimators': 489, 'max_depth': 130}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 03:44:03,122] Trial 77 finished with value: 1.2970051869378825 and parameters: {'n_estimators': 715, 'max_depth': 21}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 03:46:51,186] Trial 78 finished with value: 1.2997034373039118 and parameters: {'n_estimators': 698, 'max_depth': 57}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 03:49:56,083] Trial 79 finished with value: 1.2996539003798904 and parameters: {'n_estimators': 729, 'max_depth': 996}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 03:53:22,444] Trial 80 finished with value: 1.2996841834762842 and parameters: {'n_estimators': 761, 'max_depth': 173}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 03:56:17,965] Trial 81 finished with value: 1.2973140664076748 and parameters: {'n_estimators': 820, 'max_depth': 20}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 03:58:57,256] Trial 82 finished with value: 1.299695689329028 and parameters: {'n_estimators': 665, 'max_depth': 97}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 04:03:29,149] Trial 83 finished with value: 1.2996097634462342 and parameters: {'n_estimators': 862, 'max_depth': 49}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 04:06:55,599] Trial 84 finished with value: 1.2996817279683435 and parameters: {'n_estimators': 768, 'max_depth': 139}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 04:09:16,869] Trial 85 finished with value: 1.2997712081035147 and parameters: {'n_estimators': 602, 'max_depth': 73}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 04:11:51,099] Trial 86 finished with value: 1.2997069739150084 and parameters: {'n_estimators': 641, 'max_depth': 97}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 04:14:35,579] Trial 87 finished with value: 1.299727539783817 and parameters: {'n_estimators': 686, 'max_depth': 41}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 04:16:39,894] Trial 88 finished with value: 1.2998978028251638 and parameters: {'n_estimators': 525, 'max_depth': 681}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 04:19:48,849] Trial 89 finished with value: 1.2972961462369494 and parameters: {'n_estimators': 891, 'max_depth': 20}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 04:25:53,145] Trial 90 finished with value: 1.299562994323953 and parameters: {'n_estimators': 948, 'max_depth': 69}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 04:28:04,993] Trial 91 finished with value: 1.297386787644412 and parameters: {'n_estimators': 567, 'max_depth': 20}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 04:30:49,453] Trial 92 finished with value: 1.2997031385377336 and parameters: {'n_estimators': 663, 'max_depth': 44}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 04:33:50,769] Trial 93 finished with value: 1.299651123572906 and parameters: {'n_estimators': 727, 'max_depth': 106}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 04:38:17,181] Trial 94 finished with value: 1.2996325975432224 and parameters: {'n_estimators': 815, 'max_depth': 68}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 04:47:18,158] Trial 95 finished with value: 1.2995696183571468 and parameters: {'n_estimators': 840, 'max_depth': 39}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 04:50:14,192] Trial 96 finished with value: 1.2996772221522517 and parameters: {'n_estimators': 647, 'max_depth': 92}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 04:53:37,190] Trial 97 finished with value: 1.2996895216751563 and parameters: {'n_estimators': 710, 'max_depth': 55}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 04:56:47,583] Trial 98 finished with value: 1.2996641042139367 and parameters: {'n_estimators': 777, 'max_depth': 769}. Best is trial 67 with value: 1.2968276888752437.
[I 2024-09-12 05:03:26,270] Trial 99 finished with value: 1.2995777525873842 and parameters: {'n_estimators': 912, 'max_depth': 120}. Best is trial 67 with value: 1.2968276888752437.</code></pre>
</div>
</div>
<div id="cell-40" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>plot <span class="op">=</span> optuna.visualization.plot_param_importances(study)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>plot.update_layout(</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    title<span class="op">=</span><span class="st">""</span>,</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>    xaxis_title<span class="op">=</span><span class="st">"Importância dos Hiperparâmetros"</span>,</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    yaxis_title<span class="op">=</span><span class="st">"Hiperparâmetros"</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>Unable to display output for mime type(s): application/vnd.plotly.v1+json</code></pre>
</div>
</div>
</section>
</section>
<section id="gradient-boosting" class="level2">
<h2 class="anchored" data-anchor-id="gradient-boosting">Gradient boosting</h2>
<div id="cell-42" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> objective_gbr(trial):</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>    learning_rate <span class="op">=</span> trial.suggest_float(name<span class="op">=</span><span class="st">'learning_rate'</span>, low<span class="op">=</span><span class="fl">0.1e-4</span>, high<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>    n_estimators <span class="op">=</span> trial.suggest_int(name<span class="op">=</span><span class="st">'n_estimators'</span>, low<span class="op">=</span><span class="dv">50</span>, high<span class="op">=</span><span class="dv">1500</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>    max_depth <span class="op">=</span> trial.suggest_int(name<span class="op">=</span><span class="st">'max_depth'</span>, low<span class="op">=</span><span class="dv">3</span>, high<span class="op">=</span><span class="dv">500</span>)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>    max_features <span class="op">=</span> <span class="st">'sqrt'</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> ensemble.GradientBoostingRegressor(</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>        learning_rate<span class="op">=</span>learning_rate,</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>        n_estimators<span class="op">=</span>n_estimators,</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>        max_depth<span class="op">=</span>max_depth,</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>        max_features<span class="op">=</span>max_features,</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>    model.fit(X<span class="op">=</span>train_df_novo.drop(<span class="st">'valor'</span>, axis<span class="op">=</span><span class="dv">1</span>), y<span class="op">=</span>train_df_novo.valor)</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>    cv_scores <span class="op">=</span> np.exp(np.sqrt(<span class="op">-</span>cross_val_score(</span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>        estimator<span class="op">=</span>model,</span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a>        X<span class="op">=</span>train_df_novo.drop(<span class="st">'valor'</span>, axis<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a>        y<span class="op">=</span>train_df_novo.valor,</span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a>        scoring<span class="op">=</span><span class="st">'neg_mean_squared_error'</span>,</span>
<span id="cb41-22"><a href="#cb41-22" aria-hidden="true" tabindex="-1"></a>        cv<span class="op">=</span>KFold(n_splits<span class="op">=</span><span class="dv">20</span>))))</span>
<span id="cb41-23"><a href="#cb41-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-24"><a href="#cb41-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean(cv_scores)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-43" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>study_gdr <span class="op">=</span> optuna.create_study(direction<span class="op">=</span><span class="st">'minimize'</span>)</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>study_gdr.optimize(objective_gbr, n_trials<span class="op">=</span><span class="dv">100</span>, show_progress_bar<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2024-09-12 06:13:33,859] A new study created in memory with name: no-name-f57397ae-7762-48d6-8f44-b6d16841db32</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0d1e990172f9435fbd24e51b70396b0d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[I 2024-09-12 06:16:01,309] Trial 0 finished with value: 1.309410004963538 and parameters: {'learning_rate': 0.06138296056570036, 'n_estimators': 118, 'max_depth': 304}. Best is trial 0 with value: 1.309410004963538.
[I 2024-09-12 06:41:14,101] Trial 1 finished with value: 1.3080826359073288 and parameters: {'learning_rate': 0.05234234858027838, 'n_estimators': 1294, 'max_depth': 98}. Best is trial 1 with value: 1.3080826359073288.
[I 2024-09-12 07:09:29,889] Trial 2 finished with value: 1.3062891445094378 and parameters: {'learning_rate': 0.02259534314938676, 'n_estimators': 1442, 'max_depth': 215}. Best is trial 2 with value: 1.3062891445094378.
[I 2024-09-12 07:12:02,201] Trial 3 finished with value: 1.3082688691732494 and parameters: {'learning_rate': 0.05085071010601454, 'n_estimators': 122, 'max_depth': 269}. Best is trial 2 with value: 1.3062891445094378.
[I 2024-09-12 07:20:26,619] Trial 4 finished with value: 1.305631998630822 and parameters: {'learning_rate': 0.01934053502454407, 'n_estimators': 412, 'max_depth': 37}. Best is trial 4 with value: 1.305631998630822.
[I 2024-09-12 07:43:35,031] Trial 5 finished with value: 1.3100625509139816 and parameters: {'learning_rate': 0.08067418011999762, 'n_estimators': 1211, 'max_depth': 310}. Best is trial 4 with value: 1.305631998630822.
[I 2024-09-12 07:50:12,935] Trial 6 finished with value: 1.3209132233947625 and parameters: {'learning_rate': 0.006310868044573657, 'n_estimators': 325, 'max_depth': 66}. Best is trial 4 with value: 1.305631998630822.
[I 2024-09-12 08:05:31,291] Trial 7 finished with value: 1.3072037619819743 and parameters: {'learning_rate': 0.03526616267703238, 'n_estimators': 798, 'max_depth': 455}. Best is trial 4 with value: 1.305631998630822.
[I 2024-09-12 08:10:24,901] Trial 8 finished with value: 1.306162529898472 and parameters: {'learning_rate': 0.032135865431758046, 'n_estimators': 241, 'max_depth': 390}. Best is trial 4 with value: 1.305631998630822.
[I 2024-09-12 08:15:35,524] Trial 9 finished with value: 1.3094933697777689 and parameters: {'learning_rate': 0.06762279730561191, 'n_estimators': 268, 'max_depth': 248}. Best is trial 4 with value: 1.305631998630822.
[I 2024-09-12 08:27:47,992] Trial 10 finished with value: 1.3125039936899527 and parameters: {'learning_rate': 0.09981032146445687, 'n_estimators': 632, 'max_depth': 139}. Best is trial 4 with value: 1.305631998630822.
[I 2024-09-12 08:40:13,873] Trial 11 finished with value: 1.3065419397834481 and parameters: {'learning_rate': 0.025138019603888714, 'n_estimators': 617, 'max_depth': 453}. Best is trial 4 with value: 1.305631998630822.
[I 2024-09-12 08:44:16,895] Trial 12 finished with value: 1.6846769821057006 and parameters: {'learning_rate': 0.0007251007774539409, 'n_estimators': 569, 'max_depth': 10}. Best is trial 4 with value: 1.305631998630822.
[I 2024-09-12 08:52:24,011] Trial 13 finished with value: 1.3065687456924393 and parameters: {'learning_rate': 0.033423048842936565, 'n_estimators': 404, 'max_depth': 357}. Best is trial 4 with value: 1.305631998630822.
[I 2024-09-12 09:12:03,542] Trial 14 finished with value: 1.3052540644151613 and parameters: {'learning_rate': 0.016799141986569864, 'n_estimators': 973, 'max_depth': 389}. Best is trial 14 with value: 1.3052540644151613.
[I 2024-09-12 09:31:36,069] Trial 15 finished with value: 1.3047291758116293 and parameters: {'learning_rate': 0.013848394084162139, 'n_estimators': 952, 'max_depth': 187}. Best is trial 15 with value: 1.3047291758116293.
[I 2024-09-12 09:51:19,677] Trial 16 finished with value: 1.3046987012939781 and parameters: {'learning_rate': 0.007960476227887056, 'n_estimators': 955, 'max_depth': 191}. Best is trial 16 with value: 1.3046987012939781.
[I 2024-09-12 10:11:31,847] Trial 17 finished with value: 1.3049327486059306 and parameters: {'learning_rate': 0.007836351408708623, 'n_estimators': 978, 'max_depth': 170}. Best is trial 16 with value: 1.3046987012939781.
[I 2024-09-12 10:30:02,392] Trial 18 finished with value: 1.3079583300421669 and parameters: {'learning_rate': 0.04258457883894076, 'n_estimators': 937, 'max_depth': 160}. Best is trial 16 with value: 1.3046987012939781.
[I 2024-09-12 10:53:26,336] Trial 19 finished with value: 1.3053910890981508 and parameters: {'learning_rate': 0.01229924611735982, 'n_estimators': 1138, 'max_depth': 199}. Best is trial 16 with value: 1.3046987012939781.
[I 2024-09-12 11:09:42,539] Trial 20 finished with value: 1.399613074068225 and parameters: {'learning_rate': 0.0014859589840780238, 'n_estimators': 771, 'max_depth': 138}. Best is trial 16 with value: 1.3046987012939781.
[I 2024-09-12 11:30:57,696] Trial 21 finished with value: 1.304731635320436 and parameters: {'learning_rate': 0.011005921312158546, 'n_estimators': 1019, 'max_depth': 183}. Best is trial 16 with value: 1.3046987012939781.
[I 2024-09-12 11:53:16,843] Trial 22 finished with value: 1.3049888168515313 and parameters: {'learning_rate': 0.012920287059243507, 'n_estimators': 1077, 'max_depth': 98}. Best is trial 16 with value: 1.3046987012939781.
[I 2024-09-12 12:08:51,606] Trial 23 finished with value: 1.3059882602861086 and parameters: {'learning_rate': 0.024886633218884017, 'n_estimators': 816, 'max_depth': 231}. Best is trial 16 with value: 1.3046987012939781.
[I 2024-09-12 12:38:10,323] Trial 24 finished with value: 1.845893782206009 and parameters: {'learning_rate': 0.00011938655659243097, 'n_estimators': 1357, 'max_depth': 191}. Best is trial 16 with value: 1.3046987012939781.
[I 2024-09-12 12:59:20,342] Trial 25 finished with value: 1.3072998400242297 and parameters: {'learning_rate': 0.0427414806701217, 'n_estimators': 1063, 'max_depth': 110}. Best is trial 16 with value: 1.3046987012939781.
[I 2024-09-12 13:18:04,817] Trial 26 finished with value: 1.3049512429951053 and parameters: {'learning_rate': 0.009944311896680193, 'n_estimators': 894, 'max_depth': 280}. Best is trial 16 with value: 1.3046987012939781.
[I 2024-09-12 13:42:11,323] Trial 27 finished with value: 1.3067599901311522 and parameters: {'learning_rate': 0.0277887661615216, 'n_estimators': 1224, 'max_depth': 224}. Best is trial 16 with value: 1.3046987012939781.
[I 2024-09-12 13:57:19,750] Trial 28 finished with value: 1.3055410382538086 and parameters: {'learning_rate': 0.017342787454010026, 'n_estimators': 743, 'max_depth': 164}. Best is trial 16 with value: 1.3046987012939781.
[I 2024-09-12 14:18:22,732] Trial 29 finished with value: 1.3091455395982934 and parameters: {'learning_rate': 0.05958896242693622, 'n_estimators': 1085, 'max_depth': 318}. Best is trial 16 with value: 1.3046987012939781.
[I 2024-09-12 14:36:20,249] Trial 30 finished with value: 1.3048718262394954 and parameters: {'learning_rate': 0.008472119726272105, 'n_estimators': 877, 'max_depth': 66}. Best is trial 16 with value: 1.3046987012939781.
[I 2024-09-12 14:55:10,920] Trial 31 finished with value: 1.3050579412194394 and parameters: {'learning_rate': 0.014986724501091305, 'n_estimators': 915, 'max_depth': 54}. Best is trial 16 with value: 1.3046987012939781.
[I 2024-09-12 15:09:40,008] Trial 32 finished with value: 1.3042933324068446 and parameters: {'learning_rate': 0.006968190737313207, 'n_estimators': 704, 'max_depth': 129}. Best is trial 32 with value: 1.3042933324068446.
[I 2024-09-12 15:23:44,259] Trial 33 finished with value: 1.3048876966570337 and parameters: {'learning_rate': 0.005357803760125885, 'n_estimators': 691, 'max_depth': 129}. Best is trial 32 with value: 1.3042933324068446.
[I 2024-09-12 15:34:30,713] Trial 34 finished with value: 1.305301530220743 and parameters: {'learning_rate': 0.020389440500467117, 'n_estimators': 533, 'max_depth': 192}. Best is trial 32 with value: 1.3042933324068446.
[I 2024-09-12 15:54:14,860] Trial 35 finished with value: 1.3075269760191301 and parameters: {'learning_rate': 0.03957860772208322, 'n_estimators': 1003, 'max_depth': 248}. Best is trial 32 with value: 1.3042933324068446.
[I 2024-09-12 16:23:34,411] Trial 36 finished with value: 1.306864945052457 and parameters: {'learning_rate': 0.02751176320959573, 'n_estimators': 1493, 'max_depth': 280}. Best is trial 32 with value: 1.3042933324068446.
[I 2024-09-12 16:45:30,941] Trial 37 finished with value: 1.3054912514040968 and parameters: {'learning_rate': 0.020682342024269593, 'n_estimators': 1171, 'max_depth': 115}. Best is trial 32 with value: 1.3042933324068446.
[I 2024-09-12 17:18:44,699] Trial 38 finished with value: 1.3044353305938878 and parameters: {'learning_rate': 0.00417685388254504, 'n_estimators': 1345, 'max_depth': 88}. Best is trial 32 with value: 1.3042933324068446.
[I 2024-09-12 17:54:43,622] Trial 39 finished with value: 1.3042309730522086 and parameters: {'learning_rate': 0.004970232314934667, 'n_estimators': 1328, 'max_depth': 87}. Best is trial 39 with value: 1.3042309730522086.
[I 2024-09-12 18:28:14,661] Trial 40 finished with value: 1.3041396563247099 and parameters: {'learning_rate': 0.005099146261072941, 'n_estimators': 1351, 'max_depth': 85}. Best is trial 40 with value: 1.3041396563247099.
[I 2024-09-12 18:59:23,100] Trial 41 finished with value: 1.3042963248985124 and parameters: {'learning_rate': 0.005247412811897261, 'n_estimators': 1356, 'max_depth': 76}. Best is trial 40 with value: 1.3041396563247099.
[I 2024-09-12 19:23:35,698] Trial 42 finished with value: 1.2973612384752378 and parameters: {'learning_rate': 0.0033594469708703965, 'n_estimators': 1372, 'max_depth': 20}. Best is trial 42 with value: 1.2973612384752378.
[I 2024-09-12 19:34:27,636] Trial 43 finished with value: 1.2912821290379426 and parameters: {'learning_rate': 0.004164222908286959, 'n_estimators': 1392, 'max_depth': 11}. Best is trial 43 with value: 1.2912821290379426.
[I 2024-09-12 19:39:34,508] Trial 44 finished with value: 1.294958257245622 and parameters: {'learning_rate': 0.0747280179160318, 'n_estimators': 1434, 'max_depth': 5}. Best is trial 43 with value: 1.2912821290379426.
[I 2024-09-12 19:44:40,209] Trial 45 finished with value: 1.2941661668292184 and parameters: {'learning_rate': 0.07866830602321973, 'n_estimators': 1435, 'max_depth': 5}. Best is trial 43 with value: 1.2912821290379426.
[I 2024-09-12 19:49:44,584] Trial 46 finished with value: 1.2949335410280411 and parameters: {'learning_rate': 0.07661927481359547, 'n_estimators': 1434, 'max_depth': 5}. Best is trial 43 with value: 1.2912821290379426.
[I 2024-09-12 19:54:46,449] Trial 47 finished with value: 1.2937417299831382 and parameters: {'learning_rate': 0.08235364570352545, 'n_estimators': 1422, 'max_depth': 5}. Best is trial 43 with value: 1.2912821290379426.
[I 2024-09-12 20:19:31,957] Trial 48 finished with value: 1.3099417489797478 and parameters: {'learning_rate': 0.07916665514595186, 'n_estimators': 1428, 'max_depth': 36}. Best is trial 43 with value: 1.2912821290379426.
[I 2024-09-12 20:40:48,342] Trial 49 finished with value: 1.310827620333844 and parameters: {'learning_rate': 0.08116526488538237, 'n_estimators': 1265, 'max_depth': 33}. Best is trial 43 with value: 1.2912821290379426.
[I 2024-09-12 20:47:05,798] Trial 50 finished with value: 1.2889178996528552 and parameters: {'learning_rate': 0.08730488291054857, 'n_estimators': 1500, 'max_depth': 6}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-12 20:57:27,873] Trial 51 finished with value: 1.2956757852543317 and parameters: {'learning_rate': 0.08823356929194451, 'n_estimators': 1496, 'max_depth': 10}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-12 21:01:37,503] Trial 52 finished with value: 1.3029493618487558 and parameters: {'learning_rate': 0.07295863963466859, 'n_estimators': 1428, 'max_depth': 4}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-12 21:25:48,340] Trial 53 finished with value: 1.312019827800091 and parameters: {'learning_rate': 0.0937604948365955, 'n_estimators': 1284, 'max_depth': 55}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-12 21:49:06,667] Trial 54 finished with value: 1.3093525296719946 and parameters: {'learning_rate': 0.06800610405016674, 'n_estimators': 1427, 'max_depth': 31}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-12 22:16:10,146] Trial 55 finished with value: 1.3115921418657717 and parameters: {'learning_rate': 0.08582001626128023, 'n_estimators': 1456, 'max_depth': 49}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-12 22:33:19,988] Trial 56 finished with value: 1.3084199411687467 and parameters: {'learning_rate': 0.07553959997481392, 'n_estimators': 1250, 'max_depth': 21}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-12 22:40:11,133] Trial 57 finished with value: 1.2890945166659038 and parameters: {'learning_rate': 0.09806379927882525, 'n_estimators': 1404, 'max_depth': 7}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-12 23:01:58,289] Trial 58 finished with value: 1.3126940253031676 and parameters: {'learning_rate': 0.0981092072060698, 'n_estimators': 1178, 'max_depth': 47}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-12 23:27:09,953] Trial 59 finished with value: 1.3121480594160055 and parameters: {'learning_rate': 0.09180314745656153, 'n_estimators': 1309, 'max_depth': 483}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-12 23:28:38,379] Trial 60 finished with value: 1.3053581627492594 and parameters: {'learning_rate': 0.05461422515022683, 'n_estimators': 78, 'max_depth': 24}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-12 23:43:03,537] Trial 61 finished with value: 1.3046968017873248 and parameters: {'learning_rate': 0.06963265902362567, 'n_estimators': 1394, 'max_depth': 14}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-12 23:46:25,500] Trial 62 finished with value: 1.3127578530985096 and parameters: {'learning_rate': 0.08562647529555246, 'n_estimators': 1491, 'max_depth': 3}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 00:13:27,943] Trial 63 finished with value: 1.309116863811759 and parameters: {'learning_rate': 0.06342913349024497, 'n_estimators': 1400, 'max_depth': 65}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 00:39:05,165] Trial 64 finished with value: 1.3112029495856752 and parameters: {'learning_rate': 0.08150838410790905, 'n_estimators': 1461, 'max_depth': 38}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 00:43:08,188] Trial 65 finished with value: 1.3021722447240478 and parameters: {'learning_rate': 0.07657421555885893, 'n_estimators': 1401, 'max_depth': 4}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 01:05:53,284] Trial 66 finished with value: 1.3100314109519746 and parameters: {'learning_rate': 0.09610561595463223, 'n_estimators': 1289, 'max_depth': 41}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 01:28:47,233] Trial 67 finished with value: 1.312419941480361 and parameters: {'learning_rate': 0.09325860310090059, 'n_estimators': 1209, 'max_depth': 66}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 01:48:26,145] Trial 68 finished with value: 1.3105560296217407 and parameters: {'learning_rate': 0.0892541968899149, 'n_estimators': 1459, 'max_depth': 22}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 02:09:42,914] Trial 69 finished with value: 1.3107115559348776 and parameters: {'learning_rate': 0.08576561360891197, 'n_estimators': 1125, 'max_depth': 55}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 02:27:27,371] Trial 70 finished with value: 1.3075103888939905 and parameters: {'learning_rate': 0.0719984189473935, 'n_estimators': 1322, 'max_depth': 20}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 02:33:34,472] Trial 71 finished with value: 1.289679537044194 and parameters: {'learning_rate': 0.08958642902148246, 'n_estimators': 1465, 'max_depth': 6}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 02:37:39,615] Trial 72 finished with value: 1.3021982175388596 and parameters: {'learning_rate': 0.08248692263374838, 'n_estimators': 1403, 'max_depth': 4}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 03:01:56,961] Trial 73 finished with value: 1.3098709054293893 and parameters: {'learning_rate': 0.07808109043785097, 'n_estimators': 1461, 'max_depth': 33}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 03:21:50,140] Trial 74 finished with value: 1.3090446918527945 and parameters: {'learning_rate': 0.08853685233119987, 'n_estimators': 1499, 'max_depth': 21}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 03:48:26,159] Trial 75 finished with value: 1.3090641497176203 and parameters: {'learning_rate': 0.06270052477007843, 'n_estimators': 1381, 'max_depth': 69}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 04:13:55,963] Trial 76 finished with value: 1.3110936188554336 and parameters: {'learning_rate': 0.08375571254422126, 'n_estimators': 1435, 'max_depth': 40}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 04:36:57,314] Trial 77 finished with value: 1.3122909561314224 and parameters: {'learning_rate': 0.09558796416564211, 'n_estimators': 1232, 'max_depth': 52}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 05:01:25,632] Trial 78 finished with value: 1.3121294097112026 and parameters: {'learning_rate': 0.09982400190617696, 'n_estimators': 1302, 'max_depth': 418}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 05:17:40,260] Trial 79 finished with value: 1.3060864317718337 and parameters: {'learning_rate': 0.09054106325769781, 'n_estimators': 1345, 'max_depth': 16}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 05:44:24,699] Trial 80 finished with value: 1.310280100113361 and parameters: {'learning_rate': 0.07398351266217723, 'n_estimators': 1380, 'max_depth': 78}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 05:47:47,427] Trial 81 finished with value: 1.312395652147073 and parameters: {'learning_rate': 0.08629712441064709, 'n_estimators': 1491, 'max_depth': 3}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 06:10:45,885] Trial 82 finished with value: 1.311598734489539 and parameters: {'learning_rate': 0.0882363614272699, 'n_estimators': 1457, 'max_depth': 30}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 06:25:27,836] Trial 83 finished with value: 1.3047677093077148 and parameters: {'learning_rate': 0.07993106839829564, 'n_estimators': 1421, 'max_depth': 14}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 06:52:50,851] Trial 84 finished with value: 1.3117039595950595 and parameters: {'learning_rate': 0.09616893095524064, 'n_estimators': 1500, 'max_depth': 45}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 07:05:41,412] Trial 85 finished with value: 1.3038459752306983 and parameters: {'learning_rate': 0.08280492956040053, 'n_estimators': 1363, 'max_depth': 13}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 07:27:27,016] Trial 86 finished with value: 1.3110900209590364 and parameters: {'learning_rate': 0.09288686157695067, 'n_estimators': 1457, 'max_depth': 27}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 07:51:56,486] Trial 87 finished with value: 1.3098207946998868 and parameters: {'learning_rate': 0.06580838929795349, 'n_estimators': 1276, 'max_depth': 340}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 08:17:18,900] Trial 88 finished with value: 1.3098940721678818 and parameters: {'learning_rate': 0.07728131788512269, 'n_estimators': 1330, 'max_depth': 102}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 08:44:39,160] Trial 89 finished with value: 1.3083034084779088 and parameters: {'learning_rate': 0.05376852373700305, 'n_estimators': 1420, 'max_depth': 60}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 08:48:25,610] Trial 90 finished with value: 1.2909762964679958 and parameters: {'learning_rate': 0.0474193131781287, 'n_estimators': 407, 'max_depth': 13}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 08:52:49,901] Trial 91 finished with value: 1.3076959029825947 and parameters: {'learning_rate': 0.048651460702905054, 'n_estimators': 219, 'max_depth': 37}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 08:56:10,044] Trial 92 finished with value: 1.2914298239785023 and parameters: {'learning_rate': 0.03605017667784144, 'n_estimators': 324, 'max_depth': 14}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 09:00:11,231] Trial 93 finished with value: 1.291370678717871 and parameters: {'learning_rate': 0.03766347816515172, 'n_estimators': 393, 'max_depth': 14}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 09:07:34,492] Trial 94 finished with value: 1.3063995386237215 and parameters: {'learning_rate': 0.034849859611274035, 'n_estimators': 385, 'max_depth': 25}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 09:16:33,114] Trial 95 finished with value: 1.3078433407091477 and parameters: {'learning_rate': 0.04084458825983111, 'n_estimators': 484, 'max_depth': 50}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 09:20:10,263] Trial 96 finished with value: 1.2911073658921373 and parameters: {'learning_rate': 0.046792329175043466, 'n_estimators': 390, 'max_depth': 13}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 09:23:14,713] Trial 97 finished with value: 1.2946334492230924 and parameters: {'learning_rate': 0.04815481368392479, 'n_estimators': 271, 'max_depth': 15}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 09:30:05,912] Trial 98 finished with value: 1.3082236802368885 and parameters: {'learning_rate': 0.04565616344902474, 'n_estimators': 347, 'max_depth': 75}. Best is trial 50 with value: 1.2889178996528552.
[I 2024-09-13 09:37:53,831] Trial 99 finished with value: 1.3090177460135974 and parameters: {'learning_rate': 0.05732460052685411, 'n_estimators': 439, 'max_depth': 30}. Best is trial 50 with value: 1.2889178996528552.</code></pre>
</div>
</div>
<div id="cell-44" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>joblib.dump(study_gdr, <span class="st">"study_pkl/study_gdt.pkl"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>['study_pkl/study_gdt.pkl']</code></pre>
</div>
</div>
<section id="xgboost" class="level3">
<h3 class="anchored" data-anchor-id="xgboost">XGBoost</h3>
<div id="cell-46" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> objective_xgboost(trial):</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>    params <span class="op">=</span> {</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>        <span class="st">'n_estimators'</span>: trial.suggest_int(<span class="st">'n_estimators'</span>, <span class="dv">50</span>, <span class="dv">1000</span>),</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">'learning_rate'</span>: trial.suggest_float(<span class="st">'learning_rate'</span>, <span class="fl">1e-7</span>, <span class="fl">0.5</span>),</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">'max_depth'</span>: trial.suggest_int(<span class="st">'max_depth'</span>, <span class="dv">3</span>, <span class="dv">50</span>),</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">'random_state'</span>: <span class="dv">42</span></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> XGBRegressor(<span class="op">**</span>params)</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>    model.fit(X<span class="op">=</span>train_df_novo.drop(<span class="st">'valor'</span>, axis<span class="op">=</span><span class="dv">1</span>), y<span class="op">=</span>train_df_novo.valor)</span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>    cv_scores <span class="op">=</span> np.exp(np.sqrt(<span class="op">-</span>cross_val_score(</span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a>        estimator<span class="op">=</span>model,</span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a>        X<span class="op">=</span>train_df_novo.drop(<span class="st">'valor'</span>, axis<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a>        y<span class="op">=</span>train_df_novo.valor,</span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a>        scoring<span class="op">=</span><span class="st">'neg_mean_squared_error'</span>,</span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a>        cv<span class="op">=</span>KFold(n_splits<span class="op">=</span><span class="dv">20</span>))))</span>
<span id="cb47-18"><a href="#cb47-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-19"><a href="#cb47-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean(cv_scores)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-47" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>study_xgb <span class="op">=</span> optuna.create_study(direction<span class="op">=</span><span class="st">'minimize'</span>)</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>study_xgb.optimize(objective_xgboost, n_trials<span class="op">=</span><span class="dv">100</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2024-09-14 07:52:00,537] A new study created in memory with name: no-name-ba5b7570-e253-4932-b5f4-a8f4cfee3754
[I 2024-09-14 07:55:09,683] Trial 3 finished with value: 1.295879387937784 and parameters: {'n_estimators': 667, 'learning_rate': 0.17747877170871648, 'max_depth': 8}. Best is trial 3 with value: 1.295879387937784.
[I 2024-09-14 07:56:27,909] Trial 0 finished with value: 1.3274665735476463 and parameters: {'n_estimators': 395, 'learning_rate': 0.37045391620335755, 'max_depth': 30}. Best is trial 3 with value: 1.295879387937784.
[I 2024-09-14 07:58:33,700] Trial 1 finished with value: 1.3244464063666843 and parameters: {'n_estimators': 420, 'learning_rate': 0.24890743920844008, 'max_depth': 39}. Best is trial 3 with value: 1.295879387937784.
[I 2024-09-14 07:59:29,133] Trial 6 finished with value: 1.29723506854688 and parameters: {'n_estimators': 462, 'learning_rate': 0.2739019082111031, 'max_depth': 5}. Best is trial 3 with value: 1.295879387937784.
[I 2024-09-14 08:00:57,016] Trial 4 finished with value: 1.3249370828091585 and parameters: {'n_estimators': 853, 'learning_rate': 0.2892214789022761, 'max_depth': 31}. Best is trial 3 with value: 1.295879387937784.
[I 2024-09-14 08:02:33,742] Trial 8 finished with value: 1.2913880717254704 and parameters: {'n_estimators': 689, 'learning_rate': 0.1702487450003809, 'max_depth': 6}. Best is trial 8 with value: 1.2913880717254704.
[I 2024-09-14 08:03:14,098] Trial 7 finished with value: 1.3325720753450296 and parameters: {'n_estimators': 459, 'learning_rate': 0.4286709058483622, 'max_depth': 47}. Best is trial 8 with value: 1.2913880717254704.
[I 2024-09-14 08:05:15,544] Trial 10 finished with value: 1.324323542807682 and parameters: {'n_estimators': 355, 'learning_rate': 0.4830767300809991, 'max_depth': 9}. Best is trial 8 with value: 1.2913880717254704.
[I 2024-09-14 08:06:15,380] Trial 2 finished with value: 1.3216650776419914 and parameters: {'n_estimators': 881, 'learning_rate': 0.10917400651111506, 'max_depth': 26}. Best is trial 8 with value: 1.2913880717254704.
[I 2024-09-14 08:10:14,587] Trial 12 finished with value: 1.3319534382131233 and parameters: {'n_estimators': 896, 'learning_rate': 0.4476756602719053, 'max_depth': 36}. Best is trial 8 with value: 1.2913880717254704.
[I 2024-09-14 08:11:40,723] Trial 9 finished with value: 1.324120511746262 and parameters: {'n_estimators': 187, 'learning_rate': 0.17413771963317018, 'max_depth': 37}. Best is trial 8 with value: 1.2913880717254704.
[I 2024-09-14 08:11:46,875] Trial 11 finished with value: 1.324280634416527 and parameters: {'n_estimators': 641, 'learning_rate': 0.2553605945495564, 'max_depth': 34}. Best is trial 8 with value: 1.2913880717254704.
[I 2024-09-14 08:13:26,433] Trial 13 finished with value: 2.0067180205348945 and parameters: {'n_estimators': 58, 'learning_rate': 0.0001605363673352067, 'max_depth': 18}. Best is trial 8 with value: 1.2913880717254704.
[I 2024-09-14 08:22:33,276] Trial 16 finished with value: 1.3086385515557988 and parameters: {'n_estimators': 641, 'learning_rate': 0.12552278826033858, 'max_depth': 13}. Best is trial 8 with value: 1.2913880717254704.
[I 2024-09-14 08:23:25,844] Trial 17 finished with value: 1.323891311172242 and parameters: {'n_estimators': 706, 'learning_rate': 0.05478985557007504, 'max_depth': 3}. Best is trial 8 with value: 1.2913880717254704.
[I 2024-09-14 08:30:17,970] Trial 18 finished with value: 1.3209302986655576 and parameters: {'n_estimators': 755, 'learning_rate': 0.1922346972626254, 'max_depth': 19}. Best is trial 8 with value: 1.2913880717254704.
[I 2024-09-14 08:30:50,433] Trial 14 finished with value: 1.3023529695602645 and parameters: {'n_estimators': 700, 'learning_rate': 0.018745769193659723, 'max_depth': 14}. Best is trial 8 with value: 1.2913880717254704.
[I 2024-09-14 08:35:15,186] Trial 20 finished with value: 1.32571450257725 and parameters: {'n_estimators': 569, 'learning_rate': 0.33860745346560134, 'max_depth': 23}. Best is trial 8 with value: 1.2913880717254704.
[I 2024-09-14 08:36:53,112] Trial 19 finished with value: 1.3110313305154873 and parameters: {'n_estimators': 585, 'learning_rate': 0.17826229814176944, 'max_depth': 13}. Best is trial 8 with value: 1.2913880717254704.
[I 2024-09-14 08:39:27,495] Trial 21 finished with value: 1.301385555557796 and parameters: {'n_estimators': 812, 'learning_rate': 0.18072600355281443, 'max_depth': 9}. Best is trial 8 with value: 1.2913880717254704.
[I 2024-09-14 08:39:50,333] Trial 22 finished with value: 1.2883372658509267 and parameters: {'n_estimators': 787, 'learning_rate': 0.08949057059438655, 'max_depth': 8}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 08:42:19,379] Trial 23 finished with value: 1.2895494060270756 and parameters: {'n_estimators': 1000, 'learning_rate': 0.11875588279043431, 'max_depth': 7}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 08:42:34,617] Trial 24 finished with value: 1.2885185398447896 and parameters: {'n_estimators': 958, 'learning_rate': 0.09915673225459172, 'max_depth': 7}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 08:43:13,191] Trial 5 finished with value: 1.3222837576887132 and parameters: {'n_estimators': 301, 'learning_rate': 0.02359451291235107, 'max_depth': 40}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 08:43:29,791] Trial 25 finished with value: 1.3105920837086944 and parameters: {'n_estimators': 978, 'learning_rate': 0.10790359471528399, 'max_depth': 3}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 08:46:46,101] Trial 15 finished with value: 1.3100355400010417 and parameters: {'n_estimators': 688, 'learning_rate': 0.013893998167671034, 'max_depth': 16}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 08:56:22,447] Trial 26 finished with value: 1.315448172485424 and parameters: {'n_estimators': 962, 'learning_rate': 0.08337802086647755, 'max_depth': 16}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 08:57:04,217] Trial 27 finished with value: 1.3169138459471679 and parameters: {'n_estimators': 984, 'learning_rate': 0.08496421346591694, 'max_depth': 17}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:00:27,479] Trial 28 finished with value: 1.3198858973434016 and parameters: {'n_estimators': 998, 'learning_rate': 0.0778604492375766, 'max_depth': 20}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:04:26,107] Trial 31 finished with value: 1.30600761660545 and parameters: {'n_estimators': 795, 'learning_rate': 0.1369567436577998, 'max_depth': 11}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:04:51,056] Trial 29 finished with value: 1.319652773024252 and parameters: {'n_estimators': 980, 'learning_rate': 0.0738778487801458, 'max_depth': 21}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:04:57,861] Trial 30 finished with value: 1.2980063203941397 and parameters: {'n_estimators': 924, 'learning_rate': 0.06196437675116745, 'max_depth': 11}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:05:41,330] Trial 32 finished with value: 1.3016901690388636 and parameters: {'n_estimators': 792, 'learning_rate': 0.13337488481303988, 'max_depth': 10}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:06:36,125] Trial 35 finished with value: 1.2944287815364743 and parameters: {'n_estimators': 825, 'learning_rate': 0.21785362531430225, 'max_depth': 6}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:06:45,667] Trial 33 finished with value: 1.298264741833781 and parameters: {'n_estimators': 912, 'learning_rate': 0.2223057596248735, 'max_depth': 7}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:07:08,659] Trial 34 finished with value: 1.2978083288925977 and parameters: {'n_estimators': 909, 'learning_rate': 0.22146129953187532, 'max_depth': 7}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:07:23,356] Trial 36 finished with value: 1.2948788206203257 and parameters: {'n_estimators': 869, 'learning_rate': 0.2223466094356258, 'max_depth': 6}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:08:12,306] Trial 38 finished with value: 1.293594966442559 and parameters: {'n_estimators': 865, 'learning_rate': 0.15144570066211874, 'max_depth': 5}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:09:53,005] Trial 37 finished with value: 1.295345610111054 and parameters: {'n_estimators': 905, 'learning_rate': 0.15033251575712622, 'max_depth': 8}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:17:23,822] Trial 39 finished with value: 1.3233319882343682 and parameters: {'n_estimators': 748, 'learning_rate': 0.15126541821828718, 'max_depth': 28}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:17:38,132] Trial 40 finished with value: 1.3228040379865393 and parameters: {'n_estimators': 751, 'learning_rate': 0.15254395267245496, 'max_depth': 27}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:18:40,344] Trial 44 finished with value: 1.3127751032302206 and parameters: {'n_estimators': 829, 'learning_rate': 0.1107358922404462, 'max_depth': 3}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:20:16,577] Trial 45 finished with value: 1.3020617919083355 and parameters: {'n_estimators': 858, 'learning_rate': 0.04333101851950302, 'max_depth': 5}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:29:40,145] Trial 46 finished with value: 1.3034965990655736 and parameters: {'n_estimators': 944, 'learning_rate': 0.09752029470898277, 'max_depth': 11}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:33:09,838] Trial 43 finished with value: 1.3235560130728985 and parameters: {'n_estimators': 544, 'learning_rate': 0.10105085837326784, 'max_depth': 50}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:34:51,865] Trial 48 finished with value: 1.298225254778341 and parameters: {'n_estimators': 868, 'learning_rate': 0.2990801173942965, 'max_depth': 5}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:43:32,838] Trial 49 finished with value: 1.3231925193024392 and parameters: {'n_estimators': 477, 'learning_rate': 0.1929626641985716, 'max_depth': 42}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:43:39,197] Trial 41 finished with value: 1.321590604355474 and parameters: {'n_estimators': 744, 'learning_rate': 0.043167535925968684, 'max_depth': 25}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:49:31,656] Trial 42 finished with value: 1.3217999705693346 and parameters: {'n_estimators': 751, 'learning_rate': 0.03818478164069069, 'max_depth': 24}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:52:49,966] Trial 51 finished with value: 1.3117724740731265 and parameters: {'n_estimators': 628, 'learning_rate': 0.12191677762456536, 'max_depth': 14}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:52:56,245] Trial 50 finished with value: 1.3115047775691653 and parameters: {'n_estimators': 775, 'learning_rate': 0.12371727131149524, 'max_depth': 14}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:54:26,244] Trial 54 finished with value: 1.296372954894086 and parameters: {'n_estimators': 838, 'learning_rate': 0.2607597610791337, 'max_depth': 5}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:57:27,987] Trial 53 finished with value: 1.3009102477049208 and parameters: {'n_estimators': 933, 'learning_rate': 0.15648663237818888, 'max_depth': 9}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:57:57,881] Trial 55 finished with value: 1.3006836047909005 and parameters: {'n_estimators': 948, 'learning_rate': 0.20169313325760738, 'max_depth': 8}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:57:58,562] Trial 52 finished with value: 1.311374852216539 and parameters: {'n_estimators': 651, 'learning_rate': 0.12388107768492998, 'max_depth': 14}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:58:19,620] Trial 57 finished with value: 1.3106640021368163 and parameters: {'n_estimators': 250, 'learning_rate': 0.16846108459179127, 'max_depth': 4}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:58:45,928] Trial 58 finished with value: 1.3108394768857874 and parameters: {'n_estimators': 701, 'learning_rate': 0.1648788402774938, 'max_depth': 3}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 09:59:53,695] Trial 56 finished with value: 1.296679427855295 and parameters: {'n_estimators': 884, 'learning_rate': 0.20846937084864695, 'max_depth': 7}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 10:00:08,594] Trial 59 finished with value: 1.2961869818103122 and parameters: {'n_estimators': 826, 'learning_rate': 0.23238278037122048, 'max_depth': 6}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 10:03:30,128] Trial 60 finished with value: 1.3123512912314736 and parameters: {'n_estimators': 820, 'learning_rate': 0.2471987392505371, 'max_depth': 12}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 10:04:00,773] Trial 61 finished with value: 1.3153206108504143 and parameters: {'n_estimators': 818, 'learning_rate': 0.3068079446115076, 'max_depth': 12}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 10:04:21,035] Trial 62 finished with value: 1.3036885112008039 and parameters: {'n_estimators': 612, 'learning_rate': 0.18224913177382523, 'max_depth': 10}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 10:05:21,513] Trial 63 finished with value: 1.306449825378582 and parameters: {'n_estimators': 382, 'learning_rate': 0.30353815079976043, 'max_depth': 9}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 10:05:52,227] Trial 64 finished with value: 1.2984057027643205 and parameters: {'n_estimators': 859, 'learning_rate': 0.27827356555538907, 'max_depth': 6}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 10:06:11,306] Trial 65 finished with value: 1.29733944654472 and parameters: {'n_estimators': 868, 'learning_rate': 0.26752795042068156, 'max_depth': 6}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 10:07:11,176] Trial 68 finished with value: 1.301959457420335 and parameters: {'n_estimators': 722, 'learning_rate': 0.4034713164401944, 'max_depth': 4}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 10:07:22,784] Trial 69 finished with value: 1.3056850198746626 and parameters: {'n_estimators': 57, 'learning_rate': 0.24118687214948237, 'max_depth': 7}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 10:07:40,954] Trial 66 finished with value: 1.3017724920208482 and parameters: {'n_estimators': 870, 'learning_rate': 0.26989829927917663, 'max_depth': 7}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 10:07:44,622] Trial 67 finished with value: 1.307825335293503 and parameters: {'n_estimators': 882, 'learning_rate': 0.3851994815210038, 'max_depth': 6}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 10:08:09,354] Trial 47 finished with value: 1.3230351301641645 and parameters: {'n_estimators': 578, 'learning_rate': 0.03913817670624331, 'max_depth': 44}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 10:13:35,398] Trial 70 finished with value: 1.3095656678292198 and parameters: {'n_estimators': 897, 'learning_rate': 0.21192993510992755, 'max_depth': 10}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 10:13:59,971] Trial 71 finished with value: 1.3082295331331124 and parameters: {'n_estimators': 998, 'learning_rate': 0.2129592107974627, 'max_depth': 10}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 10:19:31,737] Trial 73 finished with value: 1.3223808752531172 and parameters: {'n_estimators': 1000, 'learning_rate': 0.1401136610218191, 'max_depth': 34}. Best is trial 22 with value: 1.2883372658509267.
[I 2024-09-14 10:23:12,772] Trial 76 finished with value: 1.2882400355275174 and parameters: {'n_estimators': 960, 'learning_rate': 0.06762527356834845, 'max_depth': 8}. Best is trial 76 with value: 1.2882400355275174.
[I 2024-09-14 10:24:12,029] Trial 74 finished with value: 1.3231609372633713 and parameters: {'n_estimators': 973, 'learning_rate': 0.1503460448536123, 'max_depth': 32}. Best is trial 76 with value: 1.2882400355275174.
[I 2024-09-14 10:24:36,166] Trial 77 finished with value: 1.3021193677180727 and parameters: {'n_estimators': 958, 'learning_rate': 0.08756033591264471, 'max_depth': 4}. Best is trial 76 with value: 1.2882400355275174.
[I 2024-09-14 10:24:59,184] Trial 75 finished with value: 1.3224919003745554 and parameters: {'n_estimators': 961, 'learning_rate': 0.14229955023064061, 'max_depth': 31}. Best is trial 76 with value: 1.2882400355275174.
[I 2024-09-14 10:25:33,561] Trial 78 finished with value: 1.3059622364068424 and parameters: {'n_estimators': 949, 'learning_rate': 0.06002355123255297, 'max_depth': 4}. Best is trial 76 with value: 1.2882400355275174.
[I 2024-09-14 10:27:44,919] Trial 80 finished with value: 1.2882445212304485 and parameters: {'n_estimators': 791, 'learning_rate': 0.06866517955967454, 'max_depth': 8}. Best is trial 76 with value: 1.2882400355275174.
[I 2024-09-14 10:28:20,063] Trial 81 finished with value: 1.2875255999411288 and parameters: {'n_estimators': 788, 'learning_rate': 0.07119699155402735, 'max_depth': 8}. Best is trial 81 with value: 1.2875255999411288.
[I 2024-09-14 10:28:23,542] Trial 79 finished with value: 1.3951884395102445 and parameters: {'n_estimators': 797, 'learning_rate': 0.0017320904600187925, 'max_depth': 8}. Best is trial 81 with value: 1.2875255999411288.
[I 2024-09-14 10:30:53,403] Trial 72 finished with value: 1.3236801648990955 and parameters: {'n_estimators': 995, 'learning_rate': 0.06352123478665149, 'max_depth': 31}. Best is trial 81 with value: 1.2875255999411288.
[I 2024-09-14 10:30:56,392] Trial 84 finished with value: 1.288863645582806 and parameters: {'n_estimators': 669, 'learning_rate': 0.07260100999318148, 'max_depth': 8}. Best is trial 81 with value: 1.2875255999411288.
[I 2024-09-14 10:33:48,470] Trial 85 finished with value: 1.2892794099803127 and parameters: {'n_estimators': 784, 'learning_rate': 0.09406872457285427, 'max_depth': 8}. Best is trial 81 with value: 1.2875255999411288.
[I 2024-09-14 10:39:53,803] Trial 86 finished with value: 1.2953093368976218 and parameters: {'n_estimators': 667, 'learning_rate': 0.025210454051548044, 'max_depth': 12}. Best is trial 81 with value: 1.2875255999411288.
[I 2024-09-14 10:41:54,555] Trial 82 finished with value: 1.2961626965961348 and parameters: {'n_estimators': 789, 'learning_rate': 0.00818740776899772, 'max_depth': 12}. Best is trial 81 with value: 1.2875255999411288.
[I 2024-09-14 10:42:50,833] Trial 87 finished with value: 1.303124466405606 and parameters: {'n_estimators': 718, 'learning_rate': 0.07299369435259612, 'max_depth': 12}. Best is trial 81 with value: 1.2875255999411288.
[I 2024-09-14 10:43:46,181] Trial 88 finished with value: 1.2905067715364578 and parameters: {'n_estimators': 774, 'learning_rate': 0.07261903664660996, 'max_depth': 9}. Best is trial 81 with value: 1.2875255999411288.
[I 2024-09-14 10:45:27,855] Trial 89 finished with value: 1.292201384363765 and parameters: {'n_estimators': 721, 'learning_rate': 0.09541423729866177, 'max_depth': 9}. Best is trial 81 with value: 1.2875255999411288.
[I 2024-09-14 10:46:12,329] Trial 90 finished with value: 1.2928985568417606 and parameters: {'n_estimators': 676, 'learning_rate': 0.11198694956938349, 'max_depth': 9}. Best is trial 81 with value: 1.2875255999411288.
[I 2024-09-14 10:55:41,119] Trial 91 finished with value: 1.3136199272893312 and parameters: {'n_estimators': 681, 'learning_rate': 0.09356751287540033, 'max_depth': 15}. Best is trial 81 with value: 1.2875255999411288.
[I 2024-09-14 10:55:46,675] Trial 92 finished with value: 1.313125885129937 and parameters: {'n_estimators': 775, 'learning_rate': 0.10968415731579001, 'max_depth': 15}. Best is trial 81 with value: 1.2875255999411288.
[I 2024-09-14 10:58:26,289] Trial 94 finished with value: 1.287577391362471 and parameters: {'n_estimators': 737, 'learning_rate': 0.06923361295057996, 'max_depth': 8}. Best is trial 81 with value: 1.2875255999411288.
[I 2024-09-14 10:59:06,153] Trial 95 finished with value: 1.2905628835463303 and parameters: {'n_estimators': 494, 'learning_rate': 0.07182130443357529, 'max_depth': 10}. Best is trial 81 with value: 1.2875255999411288.
[I 2024-09-14 11:01:22,659] Trial 96 finished with value: 1.2918075398130129 and parameters: {'n_estimators': 771, 'learning_rate': 0.0268419408271781, 'max_depth': 8}. Best is trial 81 with value: 1.2875255999411288.
[I 2024-09-14 11:01:55,540] Trial 97 finished with value: 1.2881163203625674 and parameters: {'n_estimators': 762, 'learning_rate': 0.049565591174541956, 'max_depth': 8}. Best is trial 81 with value: 1.2875255999411288.
[I 2024-09-14 11:03:31,100] Trial 98 finished with value: 1.291344800015392 and parameters: {'n_estimators': 744, 'learning_rate': 0.04910969971615011, 'max_depth': 7}. Best is trial 81 with value: 1.2875255999411288.
[I 2024-09-14 11:09:08,887] Trial 83 finished with value: 1.3084818193554661 and parameters: {'n_estimators': 791, 'learning_rate': 0.007576570751989142, 'max_depth': 16}. Best is trial 81 with value: 1.2875255999411288.
[I 2024-09-14 11:09:40,178] Trial 99 finished with value: 1.2957012154033163 and parameters: {'n_estimators': 911, 'learning_rate': 0.0475971446692151, 'max_depth': 11}. Best is trial 81 with value: 1.2875255999411288.
[I 2024-09-14 11:10:54,725] Trial 93 finished with value: 1.3130502373578747 and parameters: {'n_estimators': 771, 'learning_rate': 0.027871048281341217, 'max_depth': 16}. Best is trial 81 with value: 1.2875255999411288.</code></pre>
</div>
</div>
<div id="cell-48" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>joblib.dump(study_xgb, <span class="st">'study_pkl/study_xgb.pkl'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>['study_pkl/study_xgb.pkl']</code></pre>
</div>
</div>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>