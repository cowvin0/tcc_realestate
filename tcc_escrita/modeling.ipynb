{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pandas.api.types as ptypes\n",
    "import numpy as np\n",
    "import optuna\n",
    "import joblib\n",
    "from app.step import *\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
    "from sklearn import ensemble\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alg = pd.read_csv(\"../data/joao-pessoa-aluguel.csv\")\n",
    "df1 = pd.read_csv(\"../data/joao_pessoa.csv\").drop(columns=[\"andar\"])\n",
    "df2 = pd.read_csv(\"../data/joao_pessoa1.csv\") \\\n",
    "    .drop(columns=[\"z_lat\", \"z_lon\", \"bairro_completo\",\n",
    "                   \"comercio\", \"bairro\", \"zona\"]) \\\n",
    "    .transform(lambda x: x.apply(lambda y: float(y)) if ptypes.is_bool_dtype(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd \\\n",
    "    .read_csv('../data/aluguel_social_jp.csv', delimiter=';') \\\n",
    "    .query('`ANO DO PAGAMENTO` == 2023') \\\n",
    "    .dropna(subset=['BAIRRO']) \\\n",
    "    .rename(columns={'BAIRRO': 'bairro'}) \\\n",
    "    .assign(bairro=lambda x: x.bairro.str.strip().str.title()) \\\n",
    "    .replace(\n",
    "        {\n",
    "            r'M[AaNnGg]([a-zA-Z])*\\sI': 'Mangabeira I',\n",
    "            r'M[AaNnGg]([a-zA-Z])*\\sII': 'Mangabeira II',\n",
    "            r'M[AaNnGg]([a-zA-Z])*\\sIII': 'Mangabeira III',\n",
    "            r'M[AaNnGg]([a-zA-Z])*\\sIV': 'Mangabeira IV',\n",
    "            r'M[AaNnGg]([a-zA-Z])*\\sVii': 'Mangabeira IV',\n",
    "            'Mangabeira Iv': 'Mangabeira IV',\n",
    "            'Mangabeira Iii': 'Mangabeira III',\n",
    "            'Mangabeira Ii': 'Mangabeira II',\n",
    "            'Mangabeira Vi': 'Mangabeira VI',\n",
    "            'Mangabeira Vii': 'Mangabeira VII',\n",
    "            'Mangabeira Viii': 'Mangabeira VIII',\n",
    "            'Mangabeira, Viii': 'Mangabeira VIII',\n",
    "            'Mangabeira 8': 'Mangabeira VIII',\n",
    "            r'M[AaNnGg]([a-zA-Z])*': 'Mangabeira',\n",
    "            r'Varad([a-zA-Z]).*': 'Varadouro',\n",
    "            'Jd Veneza': 'Jardim Veneza',\n",
    "            'Jd Cidade Universitaria': 'Jardim Cidade Universitaria',\n",
    "            'Mangabeira \\( Aratu\\)': 'Mangabeira',\n",
    "            'Monsenhor Mangabeira': 'Mangabeira',\n",
    "            'Mangabeira 1': 'Mangabeira',\n",
    "            'Mangabeira \\(Aratu\\)': 'Mangabeira',\n",
    "            'Bairro Dos Estados': 'Estados',\n",
    "            'Mangabeira 6': 'Mangabeira VI',\n",
    "            'Cristo': 'Cristo Redentor',\n",
    "        },\n",
    "        regex=True\n",
    "    ) \\\n",
    "    .replace(\n",
    "        {\n",
    "            'Monsenhor Mangabeira': 'Mangabeira',\n",
    "            'Baixo Roger': 'Roger',\n",
    "            'Funcionarios 2': 'Funcionarios II a IV',\n",
    "            'Cristo Redentor Redentor': 'Cristo Redentor',\n",
    "            'Baixo Roger ( Vila Lula\\nLucena)': 'Roger',\n",
    "            'Collinas Do Sul': 'Colinas do Sul',\n",
    "            'Cidade Verde - Bairro Das Industrias': 'Bairro das Industrias',\n",
    "            'Cristo Redentor/Vale Das Palmeiras': 'Cristo Redentor',\n",
    "            'Biarro Das Industria': 'Bairro das Industrias',\n",
    "            'Altiplano 2': 'Altiplano',\n",
    "            'Dos Ipes': 'Bairro Dos Ipes',\n",
    "            'Aeroclube/Bessa': 'Aeroclube',\n",
    "            'Bairro Sao Jose': 'Sao Jose',\n",
    "            'B. Industrias': 'Bairro das Industrias',\n",
    "            'Industrias': 'Bairro das Industrias',\n",
    "            'B Das Industrias': 'Bairro das Industrias',\n",
    "            'Funcionarios Ii': 'Funcionarios II a IV',\n",
    "            'Bela Vista/Cristo Redentor': 'Cristo Redentor',\n",
    "            'Sao Jose/ Barreira': 'Sao Jose',\n",
    "            'B. Dos Estados': 'Estados',\n",
    "            '13 De Mangabeira': 'Mangabeira',\n",
    "            'Cristro Redentor': 'Cristo Redentor',\n",
    "            'Funcionario Iii': 'Funcionarios II a IV',\n",
    "            'Gervasio Mangabeira': 'Mangabeira',\n",
    "            'Ipes': 'Bairro Dos Ipes',\n",
    "            'B. Das Industrias': 'Bairro das Industrias',\n",
    "            'Joao Paulo Ii': 'Joao Paulo II',\n",
    "            'Padreze': 'Padre Ze',\n",
    "            'Valentina I': 'Valentina',\n",
    "            'B. Dos Novais': 'Bairro dos novais',\n",
    "            'Novais': 'Bairro dos novais',\n",
    "            'Treze De Mangabeira': 'Mangabeira',\n",
    "            'Estados': 'Bairro dos estados'\n",
    "        }\n",
    "    ) \\\n",
    "    .reset_index(drop=True)\n",
    "df3 = df3.replace({'Estados': 'bairro dos estados'})\n",
    "\n",
    "df3 = df3.assign(bairro=lambda x: x.bairro.str.lower().str.replace(' ', '_')) \\\n",
    "    .groupby(['bairro'], as_index=False).size() \\\n",
    "    .rename(columns={'size': 'qnt_beneficio'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_location(address):\n",
    "    pattern_joao_pessoa = re.compile(r'(.+),\\s*João Pessoa$')\n",
    "    match_joao_pessoa = pattern_joao_pessoa.search(address)\n",
    "\n",
    "    if match_joao_pessoa:\n",
    "        return match_joao_pessoa.group(1).strip()\n",
    "\n",
    "    pattern_general = re.compile(r',\\s*([^,]+)$')\n",
    "    match_general = pattern_general.search(address)\n",
    "\n",
    "    if match_general:\n",
    "        return match_general.group(1).strip()\n",
    "\n",
    "    return None\n",
    "\n",
    "def clear_addr(x):\n",
    "    pattern = re.compile(r'[-,\\s]*(.*?)\\s*,?\\s*João Pessoa - PB')\n",
    "    extracted_parts = [pattern.search(address).group(1) if pattern.search(address) else None for address in x]\n",
    "\n",
    "    return [re.sub(r'^.* - ', '', address) for address in extracted_parts]\n",
    "\n",
    "df1 = df1 \\\n",
    "    .assign(\n",
    "        bairro=lambda x: clear_addr(x.endereco),\n",
    "        error=lambda x: list(map(lambda y: ('Rua' in y) or (y == ''), x.bairro.tolist())),\n",
    "    ) \\\n",
    "    .query('error == False') \\\n",
    "    .reset_index(drop=True) \\\n",
    "    .drop(columns=['error']) \\\n",
    "    .replace(\n",
    "        {\n",
    "            'Valentina Figueiredo': 'Valentina de Figueiredo',\n",
    "            'Jardim Treze de Maio': 'Jardim 13 de Maio'\n",
    "        }\n",
    "    )\n",
    "\n",
    "df2 = df2.assign(bairro=lambda x: [extract_location(address) for address in x.endereco])\n",
    "\n",
    "df_alg = df_alg \\\n",
    "    .assign(bairro=lambda x: clear_addr(x.endereco)) \\\n",
    "    .replace({\n",
    "        'Altiplano Cabo Branco': 'Altiplano',\n",
    "        'ipes': 'Bairro dos Ipes',\n",
    "        'Estados': 'Bairro dos estados',\n",
    "        'Jardim Treze de Maio': 'Jardim 13 de Maio',\n",
    "        'Ipês': 'Bairro dos Ipes'\n",
    "    })\n",
    "\n",
    "df_alg = df_alg \\\n",
    "    .assign(\n",
    "        bairro=lambda x: x.bairro.str.normalize('NFKD') \\\n",
    "            .str.encode('ascii', errors='ignore') \\\n",
    "            .str.decode('utf-8') \\\n",
    "            .str.lower() \\\n",
    "            .str.replace(' ', '_')\n",
    "    ) \\\n",
    "    .rename(\n",
    "        columns={\n",
    "            'area': 'area_aluguel',\n",
    "            'valor': 'valor_aluguel',\n",
    "            # 'vaga': 'vaga_aluguel',\n",
    "            # 'quarto': 'quarto_aluguel',\n",
    "            # 'banheiro': 'banheiro_aluguel'\n",
    "            }\n",
    "        ) \\\n",
    "    .groupby(['bairro'], as_index=False) \\\n",
    "    [['area_aluguel', 'valor_aluguel']] \\\n",
    "    .median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2]) \\\n",
    "    .drop_duplicates('id') \\\n",
    "    .reset_index(drop=True) \\\n",
    "    .drop(columns=['id', 'url']) \\\n",
    "    .query('bairro != \"Monsenhor Magno\"') \\\n",
    "    .replace(\n",
    "        {\n",
    "            'Altiplano Cabo Branco': 'Altiplano',\n",
    "            'Estados': 'Bairro dos estados',\n",
    "            'Ipês': 'Bairro dos ipes',\n",
    "            'Industrias': 'Bairro das Industrias',\n",
    "            'Cidade dos Funcionarios II': 'Funcionários II a IV',\n",
    "            'Cidade dos Colibris': 'Colibris',\n",
    "            'Conjunto Pedro Gondim': 'Pedro gondim',\n",
    "            'José Américo de Almeida': 'jose americo'\n",
    "        }\n",
    "    )\n",
    "\n",
    "df = df \\\n",
    "    .assign(bairro=lambda x: x.bairro.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.replace(' ', '_').str.lower()) \\\n",
    "    .merge(df_alg, on='bairro', how='left') \\\n",
    "    .merge(df3, on='bairro', how='left')\\\n",
    "    .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(data, feature, threshold=1.5):\n",
    "    df = data.copy()\n",
    "    q1, q3 = np.percentile(df[feature],  [1, 99])\n",
    "    iqr = q3 - q1\n",
    "    upper_bound = q3 + threshold * iqr\n",
    "\n",
    "    removed_rows = df[df[feature] > upper_bound].index\n",
    "\n",
    "    if(feature == 'valor'):\n",
    "        df = df.drop(removed_rows, axis=0)\n",
    "        return df.query(\"valor >= 40000\").reset_index(drop=True)\n",
    "    else:\n",
    "        return df.drop(removed_rows, axis=0).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(\n",
    "    value={\n",
    "        \"academia\": 0, \"area_servico\": 0,\n",
    "        \"elevador\": 0, \"espaco_gourmet\": 0,\n",
    "        \"piscina\": 0, \"playground\": 0,\n",
    "        \"portaria_24_horas\": 0, \"quadra_de_esporte\": 0,\n",
    "        \"salao_de_festa\": 0, \"sauna\": 0,\n",
    "        \"spa\": 0, \"varanda_gourmet\": 0}\n",
    "    ) \\\n",
    "    .replace([\"flat\", \"terrenos_lotes_condominio\"],\n",
    "             [\"flats\", \"terrenos_lotes_e_condominios\"]) \\\n",
    "    .assign(\n",
    "        latitude_norm=lambda x: (x.latitude - x.latitude.mean()) / x.latitude.std(),\n",
    "        longitude_norm=lambda x: (x.longitude - x.longitude.mean()) / x.longitude.std(),\n",
    "    ) \\\n",
    "    .query(\"-2 < latitude_norm < 2\") \\\n",
    "    .query(\"-2 < longitude_norm < 2\") \\\n",
    "    .query(\"area < 150000 and area >= 20 and valor < 12_000_000 and valor > 40000\") \\\n",
    "    .query(\"tipo not in ['casas_de_vila', 'sobrados', 'coberturas', 'casas_comerciais']\") \\\n",
    "    .reset_index(drop=True) \\\n",
    "    .drop(columns=[\"longitude_norm\", \"latitude_norm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_outliers_iqr(\n",
    "    df.assign(\n",
    "        valor_area = df.valor * df.area\n",
    "        ),\n",
    "    \"valor_area\"\n",
    "    ) \\\n",
    "    .drop(columns=[\"valor_area\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['valor_cut'] = pd.cut(df['valor'],\n",
    "    bins=[0.,2e5, 4e5, 6e5, 8e5, np.inf],\n",
    "    labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=20, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(df, df.valor_cut):\n",
    "    train_df = df.loc[train_index]\n",
    "    test_df = df.loc[test_index]\n",
    "train_df = train_df.drop(columns=['valor_cut']).reset_index(drop=True)\n",
    "test_df = test_df.drop(columns=['valor_cut']).reset_index(drop=True)\n",
    "\n",
    "df.drop(columns=[\"valor_cut\"]).to_csv(\"../../data/cleaned/jp_limpo.csv\", index=False)\n",
    "train_df.to_csv(\"../../data/cleaned/train.csv\", index=False)\n",
    "test_df.to_csv(\"../../data/cleaned/test.csv\", index=False)\n",
    "\n",
    "train_df = train_df.drop(columns=['qnt_beneficio'])\n",
    "test_df = test_df.drop(columns=['qnt_beneficio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_missing = sns.displot(\n",
    "#     data=train_df.isnull() \\\n",
    "#         .melt(value_name=\"Valores ausentes\") \\\n",
    "#         .replace([False, True], [\"Não é ausente\", \"Ausente\"]) \\\n",
    "#         .groupby([\"variable\", \"Valores ausentes\"]).size() \\\n",
    "#         .reset_index(name=\"count\") \\\n",
    "#         .assign(\n",
    "#             proportion=lambda x: x.groupby(\"variable\")[\"count\"].transform(lambda y: y / y.sum())\n",
    "#         ),\n",
    "#     y=\"variable\",\n",
    "#     hue=\"Valores ausentes\",\n",
    "#     weights=\"proportion\",\n",
    "#     multiple=\"fill\",\n",
    "#     height=8,\n",
    "#     aspect=1.1,\n",
    "#     palette={\"Não é ausente\": \"#f9a602\", \"Ausente\": \"gray\"}\n",
    "#     )\n",
    "\n",
    "# sns.move_legend(obj=g_missing, loc=\"upper center\",\n",
    "#                 bbox_to_anchor=(.5, -.0001), ncol=2, title=\"\")\n",
    "# g_missing.set(xlabel=\"Proporção de valores ausentes (%)\", ylabel=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores, confidence=0.95):\n",
    "\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Média:\", scores.mean())\n",
    "    print(\"Desvio Padrão:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error(scores):\n",
    "    ax, fig = plt.subplots(figsize=(20, 20))\n",
    "    lineplot = sns.lineplot(y=scores, x=list(range(1, 11)))\n",
    "    plt.title('Raiz do erro quadrático médio', fontdict={'fontsize': 18})\n",
    "    plt.xlabel('CV', fontdict={'fontsize': 14})\n",
    "    plt.ylabel('RMSE', fontdict={'fontsize': 14})\n",
    "    lineplot.set_xticklabels(lineplot.get_xticklabels(), fontdict={'fontsize': 13})\n",
    "    lineplot.set_yticklabels(lineplot.get_yticklabels(), fontdict={'fontsize': 13})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predict(model):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    scatter = sns.scatterplot(y=np.exp(model.predict(test_df.drop('valor', axis=1))), x=np.exp(test_df.valor) - 1)\n",
    "    plt.title('Predições VS Valores Reais', fontdict={'fontsize': 18})\n",
    "    plt.xlabel('Valores Reais', fontdict={'fontsize': 13})\n",
    "    plt.ylabel('Predições', fontdict={'fontsize': 13})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_native = ensemble.GradientBoostingRegressor()\n",
    "lgbm_native = LGBMRegressor()\n",
    "rf_native = ensemble.RandomForestRegressor()\n",
    "xgboost_native = XGBRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.assign(valor=lambda x: np.log1p(x.valor))\n",
    "test_df = test_df.assign(valor=lambda x: np.log1p(x.valor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols_fit = ['endereco', 'bairro', 'iptu', 'condominio']\n",
    "\n",
    "pipe_jp = Pipeline(\n",
    "    [(\"imputer\", Imputer()),\n",
    "     (\"new_feature\", BedAreaBedToi()),\n",
    "     (\"ordinal_encoder\", OrdEncoder()),\n",
    "     (\"onehot_encoder\", OneEncoder()),\n",
    "     (\"log_transform\", LogTransform()),\n",
    "     (\"scaling\", Scale()),\n",
    "    ])\n",
    "pipe_jp.fit(train_df.drop(columns=drop_cols_fit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_novo = pipe_jp.transform(train_df.drop(columns=drop_cols_fit))\n",
    "test_df_novo = pipe_jp.transform(test_df.drop(columns=drop_cols_fit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_novo = train_df_novo\\\n",
    "    .drop(columns=['portaria_24_horas', 'total_comodo', 'vertical_horizontal', 'area_quarto_banheiro'])\n",
    "test_df_novo = test_df_novo\\\n",
    "    .drop(columns=['portaria_24_horas', 'total_comodo', 'vertical_horizontal', 'area_quarto_banheiro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_des_tree = DecisionTreeRegressor(random_state=42, max_depth=50)\\\n",
    "#     .fit(\n",
    "#         X=train_df_novo.loc[:, ['banheiro', 'quarto']],\n",
    "#         y=train_df_novo.valor\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_novo.loc[:, 'tree1'] = np.apply_along_axis(\n",
    "#     lambda x: (x - x.mean()) / x.std(),\n",
    "#     axis=0,\n",
    "#     arr=fit_des_tree.predict(X=train_df_novo.loc[:, [\"banheiro\", \"quarto\"]])\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_novo.loc[:, 'tree1'] = np.apply_along_axis(\n",
    "#     lambda x: (x - x.mean()) / x.std(),\n",
    "#     axis=0,\n",
    "#     arr=fit_des_tree.predict(X=test_df_novo.loc[:, [\"banheiro\", \"quarto\"]])\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = setup(train_df_novo, target='valor')\n",
    "# best = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_clone = test_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgbm(trial):\n",
    "    num_leaves = trial.suggest_int('num_leaves', 100, 2000)\n",
    "    max_depth = trial.suggest_int('max_depth', 100, 500)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, .01)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 2000)\n",
    "\n",
    "    model = LGBMRegressor(\n",
    "        num_leaves=num_leaves,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X=train_df_novo.drop('valor', axis=1), y=train_df_novo.valor)\n",
    "\n",
    "    cv_scores = np.expm1(np.sqrt(-cross_val_score(\n",
    "        estimator=model,\n",
    "        X=train_df_novo.drop('valor', axis=1),\n",
    "        y=train_df_novo.valor,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        cv=KFold(n_splits=20))))\n",
    "\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_lgbm = optuna.create_study(direction=\"minimize\")\n",
    "# study_lgbm.optimize(objective_lgbm, n_trials=100, n_jobs=-1, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lgbm = {\n",
    "    'num_leaves': 247,\n",
    "    'max_depth': 299,\n",
    "    'learning_rate': 0.009035568789398086,\n",
    "    'n_estimators': 1798}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMRegressor(\n",
    "    **best_params_lgbm,\n",
    "    random_state=42,\n",
    "    n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm.fit(X=train_df_novo.drop(columns=['valor']), y=train_df_novo.valor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm.score(X=test_df_novo.drop(columns=['valor']), y=test_df_novo.valor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_lgbm = lgbm.predict(X=test_df_novo.drop(columns=['valor']))\n",
    "test_df_clone['preds_lgbm'] = preds_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_absolute_percentage_error(test_df_clone.valor, preds_lgbm))\n",
    "print(np.expm1(root_mean_squared_error(test_df_clone.valor, preds_lgbm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.Figure(figsize=(20, 20))\n",
    "\n",
    "plot = sns.scatterplot(\n",
    "    # data=test_df_clone\\\n",
    "    # .assign(\n",
    "    #     nivel=lambda x: (x.academia + x.espaco_gourmet + x.quadra_de_esporte +\n",
    "    #      x.sauna + x.varanda_gourmet + x.playground).astype(object)\n",
    "    # ),\n",
    "    data=test_df_clone,\n",
    "    x='valor',\n",
    "    y='preds_lgbm',\n",
    "    s=100,\n",
    "    # style='nivel',\n",
    "    hue='tipo',\n",
    "    palette='mako',\n",
    "    alpha=.6)\n",
    "\n",
    "min_val = min(test_df_clone['valor'].min(), test_df_clone['preds_lgbm'].min())\n",
    "max_val = max(test_df_clone['valor'].max(), test_df_clone['preds_lgbm'].max())\n",
    "plot.plot(\n",
    "    [min_val, max_val],\n",
    "    [min_val, max_val],\n",
    "    color=\"black\",\n",
    "    linewidth=3.5,\n",
    "    alpha=.5\n",
    "    )\n",
    "\n",
    "plot.grid(True, color='grey', linewidth=.05)\n",
    "plot.set_facecolor('white')\n",
    "plot.spines['top'].set_visible(True)\n",
    "plot.spines['right'].set_visible(True)\n",
    "plot.spines['left'].set_visible(True)\n",
    "plot.spines['bottom'].set_visible(True)\n",
    "\n",
    "sns.set_theme(rc={'figure.figsize': (20, 20)})\n",
    "plot.set_xlabel('Valor do imóvel observado')\n",
    "plot.set_ylabel('Valor do imóvel estimado')\n",
    "\n",
    "l = plt.legend(loc=\"upper center\", bbox_to_anchor=(.5, -.08), ncol=7)\n",
    "l.get_texts()[0].set_text('Casas')\n",
    "l.get_texts()[1].set_text('Apartamentos')\n",
    "l.get_texts()[2].set_text('Casas de condomínio')\n",
    "l.get_texts()[3].set_text('Flats')\n",
    "l.get_texts()[4].set_text('Terrenos e lotes comerciais')\n",
    "l.get_texts()[5].set_text('Terrenos, lotes e condomínios')\n",
    "# plt.savefig(\"../../tcc_escrita/includes/lgbm_plot_predict.svg\", dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(study_lgbm, 'study_pkl/study_lgbm.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = ensemble.RandomForestRegressor(\n",
    "    n_estimators=650,\n",
    "    random_state=42,\n",
    "    max_depth=22,\n",
    "    max_features=\"sqrt\",\n",
    "    n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.fit(X=train_df_novo.drop(columns=['valor']), y=train_df_novo.valor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.score(X=test_df_novo.drop(columns=['valor']), y=test_df_novo.valor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = forest.predict(X=test_df_novo.drop(columns=['valor']))\n",
    "test_df_clone['preds'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.expm1(mean_absolute_error(test_df_clone.valor, preds)))\n",
    "print(mean_absolute_percentage_error(test_df_clone.valor, preds))\n",
    "print(np.expm1(root_mean_squared_error(test_df_clone.valor, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.Figure(figsize=(20, 10))\n",
    "\n",
    "plot = sns.scatterplot(\n",
    "    data=test_df_clone,\n",
    "    x='valor',\n",
    "    y='preds',\n",
    "    s=100,\n",
    "    hue='tipo',\n",
    "    palette='mako',\n",
    "    alpha=.6)\n",
    "\n",
    "min_val = min(test_df_clone['valor'].min(), test_df_clone['preds'].min())\n",
    "max_val = max(test_df_clone['valor'].max(), test_df_clone['preds'].max())\n",
    "plot.plot(\n",
    "    [min_val, max_val],\n",
    "    [min_val, max_val],\n",
    "    color=\"black\",\n",
    "    linewidth=3.5,\n",
    "    alpha=.5\n",
    "    )\n",
    "\n",
    "plot.grid(True, color='grey', linewidth=.05)\n",
    "plot.set_facecolor('white')\n",
    "plot.spines['top'].set_visible(True)\n",
    "plot.spines['right'].set_visible(True)\n",
    "plot.spines['left'].set_visible(True)\n",
    "plot.spines['bottom'].set_visible(True)\n",
    "\n",
    "sns.set_theme(rc={'figure.figsize': (20, 10)})\n",
    "plot.set_xlabel('Valor do imóvel observado')\n",
    "plot.set_ylabel('Valor do imóvel estimado')\n",
    "\n",
    "l = plt.legend(loc=\"upper center\", bbox_to_anchor=(.5, -.08), ncol=7)\n",
    "l.get_texts()[0].set_text('Casas')\n",
    "l.get_texts()[1].set_text('Apartamentos')\n",
    "l.get_texts()[2].set_text('Casas de condomínio')\n",
    "l.get_texts()[3].set_text('Flats')\n",
    "l.get_texts()[4].set_text('Terrenos e lotes comerciais')\n",
    "l.get_texts()[5].set_text('Terrenos, lotes e condomínios')\n",
    "# plt.savefig(\"../../tcc_escrita/includes/rf_plot_predict.svg\", dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_rf(trial):\n",
    "    params = dict(\n",
    "        n_estimators=trial.suggest_int(name='n_estimators', low=1, high=2000),\n",
    "        max_depth=trial.suggest_int(name='max_depth', low=20, high=1000),\n",
    "        max_features='sqrt',\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    model = ensemble.RandomForestRegressor(\n",
    "        **params,\n",
    "        n_jobs=3\n",
    "    )\n",
    "    model.fit(X=train_df_novo.drop('valor', axis=1), y=train_df_novo.valor)\n",
    "\n",
    "    cv_scores = np.expm1(np.sqrt(-cross_val_score(\n",
    "        estimator=model,\n",
    "        X=train_df_novo.drop(\"valor\", axis=1),\n",
    "        y=train_df_novo.valor,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        n_jobs=3,\n",
    "        cv=KFold(n_splits=20))))\n",
    "\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(study, 'study_pkl/study_rf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction=\"minimize\")\n",
    "# study.optimize(objective_rf, n_trials=100, show_progress_bar=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = optuna.visualization.plot_param_importances(study)\n",
    "plot.update_layout(\n",
    "    title=\"\",\n",
    "    xaxis_title=\"Importância dos Hiperparâmetros\",\n",
    "    yaxis_title=\"Hiperparâmetros\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_gbr(trial):\n",
    "    learning_rate = trial.suggest_float(name='learning_rate', low=0.1e-4, high=0.1)\n",
    "    n_estimators = trial.suggest_int(name='n_estimators', low=50, high=1500)\n",
    "    max_depth = trial.suggest_int(name='max_depth', low=3, high=500)\n",
    "    max_features = 'sqrt'\n",
    "\n",
    "\n",
    "    model = ensemble.GradientBoostingRegressor(\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42,\n",
    "        max_features=max_features,\n",
    "    )\n",
    "    model.fit(X=train_df_novo.drop('valor', axis=1), y=train_df_novo.valor)\n",
    "\n",
    "    cv_scores = np.expm1(np.sqrt(-cross_val_score(\n",
    "        estimator=model,\n",
    "        X=train_df_novo.drop('valor', axis=1),\n",
    "        y=train_df_novo.valor,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        cv=KFold(n_splits=20))))\n",
    "\n",
    "    return np.mean(cv_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_gdr = optuna.create_study(direction='minimize')\n",
    "# study_gdr.optimize(objective_gbr, n_trials=100, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_gdt = {\n",
    "    'learning_rate': 0.08730488291054857,\n",
    "    'n_estimators': 1500,\n",
    "    'max_depth': 6\n",
    "    }\n",
    "\n",
    "gdt = ensemble.GradientBoostingRegressor(\n",
    "    **best_params_gdt,\n",
    "    random_state=42,\n",
    "    max_features=\"sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdt.fit(X=train_df_novo.drop(columns=['valor']), y=train_df_novo.valor)\n",
    "gdt.score(X=test_df_novo.drop(columns=['valor']), y=test_df_novo.valor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_gdt = gdt.predict(X=test_df_novo.drop(columns=['valor']))\n",
    "test_df_clone['preds_gdt'] = preds_gdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.expm1(mean_absolute_error(test_df_clone.valor, preds_gdt)))\n",
    "print(mean_absolute_percentage_error(test_df_clone.valor, preds_gdt))\n",
    "print(np.expm1(root_mean_squared_error(test_df_clone.valor, preds_gdt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.Figure(figsize=(20, 20))\n",
    "\n",
    "plot = sns.scatterplot(\n",
    "    data=test_df_clone,\n",
    "    x='valor',\n",
    "    y='preds_gdt',\n",
    "    s=100,\n",
    "    hue='tipo',\n",
    "    palette='mako',\n",
    "    alpha=.6)\n",
    "\n",
    "min_val = min(test_df_clone['valor'].min(), test_df_clone['preds_gdt'].min())\n",
    "max_val = max(test_df_clone['valor'].max(), test_df_clone['preds_gdt'].max())\n",
    "plot.plot(\n",
    "    [min_val, max_val],\n",
    "    [min_val, max_val],\n",
    "    color=\"black\",\n",
    "    linewidth=3.5,\n",
    "    alpha=.5\n",
    "    )\n",
    "\n",
    "plot.grid(True, color='grey', linewidth=.05)\n",
    "plot.set_facecolor('white')\n",
    "plot.spines['top'].set_visible(True)\n",
    "plot.spines['right'].set_visible(True)\n",
    "plot.spines['left'].set_visible(True)\n",
    "plot.spines['bottom'].set_visible(True)\n",
    "\n",
    "sns.set_theme(rc={'figure.figsize': (20, 10)})\n",
    "plot.set_xlabel('Valor do imóvel observado')\n",
    "plot.set_ylabel('Valor do imóvel estimado')\n",
    "\n",
    "l = plt.legend(loc=\"upper center\", bbox_to_anchor=(.5, -.08), ncol=7)\n",
    "l.get_texts()[0].set_text('Casas')\n",
    "l.get_texts()[1].set_text('Apartamentos')\n",
    "l.get_texts()[2].set_text('Casas de condomínio')\n",
    "l.get_texts()[3].set_text('Flats')\n",
    "l.get_texts()[4].set_text('Terrenos e lotes comerciais')\n",
    "l.get_texts()[5].set_text('Terrenos, lotes e condomínios')\n",
    "plt.savefig(\"../../tcc_escrita/includes/gdt_plot_predict.svg\", dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(study_gdr, \"study_pkl/study_gdt.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xgboost(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-7, 0.5),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 50),\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(X=train_df_novo.drop('valor', axis=1), y=train_df_novo.valor)\n",
    "\n",
    "    cv_scores = np.expm1(np.sqrt(-cross_val_score(\n",
    "        estimator=model,\n",
    "        X=train_df_novo.drop('valor', axis=1),\n",
    "        y=train_df_novo.valor,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        cv=KFold(n_splits=20))))\n",
    "\n",
    "    return np.mean(cv_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgb = {\n",
    "    'n_estimators': 788,\n",
    "    'learning_rate': 0.07119699155402735,\n",
    "    'max_depth': 8}\n",
    "\n",
    "xgb = XGBRegressor(\n",
    "    **best_params_xgb,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(X=train_df_novo.drop(columns=['valor']), y=train_df_novo.valor)\n",
    "xgb.score(X=test_df_novo.drop(columns=['valor']), y=test_df_novo.valor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_xgb = xgb.predict(X=test_df_novo.drop(columns=['valor']))\n",
    "test_df_clone['preds_xgb'] = preds_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.expm1(mean_absolute_error(test_df_clone.valor, preds_xgb)))\n",
    "print(mean_absolute_percentage_error(test_df_clone.valor, preds_xgb))\n",
    "print(np.expm1(root_mean_squared_error(test_df_clone.valor, preds_xgb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.Figure(figsize=(20, 20))\n",
    "\n",
    "plot = sns.scatterplot(\n",
    "    data=test_df_clone,\n",
    "    x='valor',\n",
    "    y='preds_xgb',\n",
    "    s=100,\n",
    "    hue='tipo',\n",
    "    palette='mako',\n",
    "    alpha=.6)\n",
    "\n",
    "min_val = min(test_df_clone['valor'].min(), test_df_clone['preds_xgb'].min())\n",
    "max_val = max(test_df_clone['valor'].max(), test_df_clone['preds_xgb'].max())\n",
    "plot.plot(\n",
    "    [min_val, max_val],\n",
    "    [min_val, max_val],\n",
    "    color=\"black\",\n",
    "    linewidth=3.5,\n",
    "    alpha=.5\n",
    "    )\n",
    "\n",
    "plot.grid(True, color='grey', linewidth=.05)\n",
    "plot.set_facecolor('white')\n",
    "plot.spines['top'].set_visible(True)\n",
    "plot.spines['right'].set_visible(True)\n",
    "plot.spines['left'].set_visible(True)\n",
    "plot.spines['bottom'].set_visible(True)\n",
    "\n",
    "sns.set_theme(rc={'figure.figsize': (20, 10)})\n",
    "plot.set_xlabel('Valor do imóvel observado')\n",
    "plot.set_ylabel('Valor do imóvel estimado')\n",
    "\n",
    "l = plt.legend(loc=\"upper center\", bbox_to_anchor=(.5, -.08), ncol=7)\n",
    "l.get_texts()[0].set_text('Casas')\n",
    "l.get_texts()[1].set_text('Apartamentos')\n",
    "l.get_texts()[2].set_text('Casas de condomínio')\n",
    "l.get_texts()[3].set_text('Flats')\n",
    "l.get_texts()[4].set_text('Terrenos e lotes comerciais')\n",
    "l.get_texts()[5].set_text('Terrenos, lotes e condomínios')\n",
    "plt.savefig(\"../../tcc_escrita/includes/xgb_plot_predict.svg\", dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_xgb = optuna.create_study(direction='minimize')\n",
    "# study_xgb.optimize(objective_xgboost, n_trials=100, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(study_xgb, 'study_pkl/study_xgb.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('xgb', XGBRegressor(**best_params_xgb, random_state=42)),\n",
    "    ('rf', ensemble.RandomForestRegressor(\n",
    "        n_estimators=650,\n",
    "        random_state=42,\n",
    "        max_depth=22,\n",
    "        max_features=\"sqrt\",\n",
    "        n_jobs=1\n",
    "    )),\n",
    "    ('lgbm', LGBMRegressor(**best_params_lgbm, random_state=42, n_jobs=1)),\n",
    "    ('gdt', ensemble.GradientBoostingRegressor(\n",
    "        **best_params_gdt,\n",
    "        random_state=42,\n",
    "        max_features=\"sqrt\"\n",
    "    ))\n",
    "]\n",
    "\n",
    "stacking = ensemble.StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=ensemble.RandomForestRegressor(\n",
    "        n_estimators=650,\n",
    "        random_state=42,\n",
    "        max_depth=22,\n",
    "        max_features=\"sqrt\",\n",
    "        n_jobs=1\n",
    "    ),\n",
    "    verbose=2,\n",
    "    n_jobs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking.fit(X=train_df_novo.drop(columns=['valor']), y=train_df_novo.valor)\n",
    "# stacking.score(X=test_df_novo.drop(columns=['valor']), y=test_df_novo.valor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_stacking = stacking.predict(X=test_df_novo.drop(columns=['valor']))\n",
    "test_df_clone['preds_stacking'] = preds_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.expm1(mean_absolute_error(test_df_clone.valor, preds_stacking)))\n",
    "print(mean_absolute_percentage_error(test_df_clone.valor, preds_stacking))\n",
    "print(np.expm1(root_mean_squared_error(test_df_clone.valor, preds_stacking)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.Figure(figsize=(20, 20))\n",
    "\n",
    "plot = sns.scatterplot(\n",
    "    data=test_df_clone,\n",
    "    x='valor',\n",
    "    y='preds_stacking',\n",
    "    s=100,\n",
    "    hue='tipo',\n",
    "    palette='mako',\n",
    "    alpha=.6)\n",
    "\n",
    "min_val = min(test_df_clone['valor'].min(), test_df_clone['preds_stacking'].min())\n",
    "max_val = max(test_df_clone['valor'].max(), test_df_clone['preds_stacking'].max())\n",
    "plot.plot(\n",
    "    [min_val, max_val],\n",
    "    [min_val, max_val],\n",
    "    color=\"black\",\n",
    "    linewidth=3.5,\n",
    "    alpha=.5\n",
    "    )\n",
    "\n",
    "plot.grid(True, color='grey', linewidth=.05)\n",
    "plot.set_facecolor('white')\n",
    "plot.spines['top'].set_visible(True)\n",
    "plot.spines['right'].set_visible(True)\n",
    "plot.spines['left'].set_visible(True)\n",
    "plot.spines['bottom'].set_visible(True)\n",
    "\n",
    "sns.set_theme(rc={'figure.figsize': (20, 10)})\n",
    "plot.set_xlabel('Valor do imóvel observado')\n",
    "plot.set_ylabel('Valor do imóvel estimado')\n",
    "\n",
    "l = plt.legend(loc=\"upper center\", bbox_to_anchor=(.5, -.08), ncol=7)\n",
    "l.get_texts()[0].set_text('Casas')\n",
    "l.get_texts()[1].set_text('Apartamentos')\n",
    "l.get_texts()[2].set_text('Casas de condomínio')\n",
    "l.get_texts()[3].set_text('Flats')\n",
    "l.get_texts()[4].set_text('Terrenos e lotes comerciais')\n",
    "l.get_texts()[5].set_text('Terrenos, lotes e condomínios')\n",
    "plt.savefig(\"../../tcc_escrita/includes/stacking_plot_predict.svg\", dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.inspection import partial_dependence\n",
    "\n",
    "# X = test_df_novo.drop(columns=['valor'])\n",
    "# features = X.columns.tolist()\n",
    "# cat_features = [\n",
    "#     'encoder__tipo_apartamentos', 'encoder__tipo_casas',\n",
    "#     'encoder__tipo_casas_de_condominio', 'encoder__tipo_flats',\n",
    "#     'encoder__tipo_terrenos_e_lotes_comerciais', 'encoder__tipo_terrenos_lotes_e_condominios',\n",
    "#     'vertical_horizontal', 'varanda_gourmet', 'spa', 'sauna', 'salao_de_festa',\n",
    "#     'portaria_24_horas', 'quadra_de_esporte', 'playground', 'piscina', 'espaco_gourmet',\n",
    "#     'elevador', 'academia'\n",
    "# ]\n",
    "# num_features = np.array(features)[~X.columns.isin(cat_features)].tolist()\n",
    "\n",
    "# pdp = partial_dependence(\n",
    "#     stacking,\n",
    "#     features=num_features,\n",
    "#     # categorical_features=cat_features,\n",
    "#     kind='both',\n",
    "#     X=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "X = test_df_novo.drop(columns=['valor'])\n",
    "features = X.columns.tolist()\n",
    "cat_features = [\n",
    "    'encoder__tipo_apartamentos', 'encoder__tipo_casas',\n",
    "    'encoder__tipo_casas_de_condominio', 'encoder__tipo_flats',\n",
    "    'encoder__tipo_terrenos_e_lotes_comerciais', 'encoder__tipo_terrenos_lotes_e_condominios',\n",
    "    'vertical_horizontal', 'varanda_gourmet', 'spa', 'sauna', 'salao_de_festa',\n",
    "    'portaria_24_horas', 'quadra_de_esporte', 'playground', 'piscina', 'espaco_gourmet',\n",
    "    'elevador', 'academia', 'area_servico'\n",
    "]\n",
    "num_features = np.array(features)[~X.columns.isin(cat_features + [\"total_comodo\"])].tolist()\n",
    "\n",
    "ice_pdp = PartialDependenceDisplay\\\n",
    "    .from_estimator(\n",
    "        stacking,\n",
    "        X,\n",
    "        num_features,\n",
    "        kind='both',\n",
    "        centered=True,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "fig, ax = plt.gcf(), plt.gca()\n",
    "fig.set_size_inches(15, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "new_xlabels = [\"Área\", \"Banheiro\", \"Quarto\", \"Vaga\", \"Latitude\", \"Longitude\", \"Área de aluguel\", \"Valor de aluguel\"]\n",
    "\n",
    "\n",
    "for idx, (ax1, xlabel) in enumerate(zip(ice_pdp.axes_.ravel(), new_xlabels)):\n",
    "    if ax1 is not None:\n",
    "        for line in ax1.get_lines()[:-1]:\n",
    "            line.set_color('#00708d')\n",
    "            line.set_alpha(0.4)\n",
    "\n",
    "        pdp_line = ax1.get_lines()[-1]\n",
    "        pdp_line.set_color('orange')\n",
    "        pdp_line.set_linewidth(2.5)\n",
    "\n",
    "        if ax1.get_legend() is not None:\n",
    "            ax1.get_legend().remove()\n",
    "\n",
    "        ax1.set_xlabel(xlabel, fontsize=13)\n",
    "\n",
    "        if idx % 3 == 0:\n",
    "            ax1.set_ylabel(\"Dependência parcial\", fontsize=13)\n",
    "        ax1.grid(True, which=\"major\", axis=\"both\", linestyle=\"-\", color=\"lightgray\", linewidth=0.8, alpha=0.9)\n",
    "        ax1.grid(True, which=\"minor\", axis=\"both\", linestyle=\":\", color=\"lightgray\", linewidth=0.5, alpha=0.8)\n",
    "\n",
    "legend_line = Line2D([0], [0], color='orange', linestyle=\"--\", linewidth=2.5, label=\"Média\")\n",
    "fig.legend(\n",
    "    handles=[legend_line],\n",
    "    loc=\"lower center\",\n",
    "    fontsize=13,\n",
    "    ncol=1,\n",
    "    bbox_to_anchor=(0.5, 0.02),\n",
    ")\n",
    "\n",
    "fig.tight_layout(rect=[0, 0.05, 1, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"../../tcc_escrita/includes/pdp_ice.svg\", dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "X1000 = shap.utils.sample(train_df_novo.drop(columns=\"valor\"), 1000)\n",
    "\n",
    "explainer_stacking = shap.Explainer(stacking.predict, X1000)\n",
    "shap_values_stacking = explainer_stacking(\n",
    "    test_df_novo.drop(columns=\"valor\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = joblib.load('study_pkl/shap_values.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "custom_cmap = matplotlib.colormaps[\"viridis\"]\n",
    "\n",
    "selected_features = test_df_novo.loc[:, test_df_novo.columns.isin([\"area\", \"banheiro\", \"quarto\", \"vaga\", \"latitude\", \"longitude\", \"area_aluguel\", \"valor_aluguel\"])].columns.tolist()\n",
    "filtered_df = test_df_novo[selected_features]\n",
    "\n",
    "filtered_shap_values = shap_values[:, [1, 3, 10, 14, 16, 17, 18, 19]]\n",
    "\n",
    "shap.summary_plot(\n",
    "    filtered_shap_values,\n",
    "    filtered_df,\n",
    "    plot_type=\"dot\",\n",
    "    show=False,\n",
    "    cmap=custom_cmap,\n",
    "    plot_size=(10, 5)\n",
    ")\n",
    "feature_names = [\n",
    "    \"Área de aluguel\", \"Quarto\", \"Banheiro\",\n",
    "    \"Latitude\", \"Valor de aluguel\",\n",
    "    \"Longitude\", \"Vaga\", \"Área\"\n",
    "]\n",
    "\n",
    "fig, ax = plt.gcf(), plt.gca()\n",
    "\n",
    "ax.set_yticklabels(feature_names, fontsize=12)\n",
    "colorbar = fig.axes[-1]\n",
    "colorbar.set_ylabel(\"Valor da variável\", fontsize=13)\n",
    "colorbar.set_yticklabels([\"Baixo\", \"Alto\"])\n",
    "ax.grid(True, which=\"major\", axis=\"both\", linestyle=\"-\", color=\"lightgray\", linewidth=0.8, alpha=0.9)\n",
    "ax.grid(True, which=\"minor\", axis=\"both\", linestyle=\":\", color=\"lightgray\", linewidth=0.5, alpha=0.8)\n",
    "\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "ax.set_xlabel(\"Valor SHAP (impacto na predição do modelo)\", fontsize=13)\n",
    "\n",
    "plt.savefig(\"../../tcc_escrita/includes/shap_summary_plot.svg\", dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = test_df_novo.loc[:, test_df_novo.columns.isin([\n",
    "    \"academia\", \"area\", \"area_servico\",\n",
    "    \"banheiro\", \"elevador\", \"espaco_gourmet\",\n",
    "    \"piscina\", \"playground\", \"portaria_24_horas\",\n",
    "    \"quadra_de_esporte\", \"quarto\", \"salao_de_festa\",\n",
    "    \"sauna\", \"spa\", \"vaga\", \"varanda_gourmet\", \"latitude\", \"longitude\",\n",
    "    \"area_aluguel\", \"valor_aluguel\"])].columns.tolist()\n",
    "filtered_df = test_df_novo[selected_features]\n",
    "\n",
    "filtered_shap_values = shap_values[:, 0:20]\n",
    "\n",
    "shap.summary_plot(\n",
    "    filtered_shap_values,\n",
    "    filtered_df,\n",
    "    plot_type=\"bar\",\n",
    "    color=\"#00708d\",\n",
    "    show=False,\n",
    "    plot_size=(10, 5))\n",
    "\n",
    "fig, ax = plt.gcf(), plt.gca()\n",
    "ax.set_xlabel(\"Média(|Valor SHAP|) (impacto médio na magnitude da predição do modelo)\", fontsize=13)\n",
    "\n",
    "feature_names=[\n",
    "    \"Área\", \"Vaga\", \"Longitude\",\n",
    "    \"Valor de aluguel\", \"Latitude\",\n",
    "    \"Banheiro\", \"Academia\", \"Quarto\",\n",
    "    \"Área de aluguel\", \"Elevador\",\n",
    "    \"Piscina\", \"Espaço gourmet\",\n",
    "    \"Varanda gourmet\", \"Área  de serviço\",\n",
    "    \"Salão de festa\", \"Playground\",\n",
    "    \"Spa\", \"Sauna\", \"Portaria 24 horas\",\n",
    "    \"Quadra de esporte\"\n",
    "    ]\n",
    "ax.set_yticklabels(feature_names[::-1], fontsize=12)\n",
    "ax.grid(True, which=\"major\", axis=\"both\", linestyle=\"-\", color=\"lightgray\", linewidth=0.8, alpha=0.9)\n",
    "ax.grid(True, which=\"minor\", axis=\"both\", linestyle=\":\", color=\"lightgray\", linewidth=0.5, alpha=0.8)\n",
    "\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "plt.savefig(\"../../tcc_escrita/includes/shap_importance.svg\", dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep_plot(var, label):\n",
    "    shap.dependence_plot(\n",
    "        var,\n",
    "        shap_values.values,\n",
    "        test_df_novo.drop(columns=\"valor\").values,\n",
    "        feature_names=test_df_novo.drop(columns=\"valor\").columns,\n",
    "        alpha=.7,\n",
    "        dot_size=16,\n",
    "        show=False,\n",
    "        color=\"#00708d\",\n",
    "        interaction_index=None,\n",
    "        )\n",
    "    fig, ax = plt.gcf(), plt.gca()\n",
    "    fig.set_size_inches(10, 5)\n",
    "\n",
    "    ax.set_xlabel(label, fontsize=13)\n",
    "    ax.set_ylabel(f\"Valores SHAP para\\n{label}\", fontsize=13)\n",
    "    ax.grid(True, which=\"major\", axis=\"both\", linestyle=\"-\", color=\"lightgray\", linewidth=0.8, alpha=0.9)\n",
    "    ax.grid(True, which=\"minor\", axis=\"both\", linestyle=\":\", color=\"lightgray\", linewidth=0.5, alpha=0.8)\n",
    "    plt.savefig(f\"../../tcc_escrita/includes/dependence_plot_cat/dep_plot_{var}.svg\", dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_plot(\"elevador\", \"Elevador\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
