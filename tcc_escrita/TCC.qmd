---
nocite: |
  @bischl2023hyperparameter
  @garnett2023bayesian
format:
  pdf:
    include-before-body:
      text: |
        \numberwithin{algorithm}{chapter}
        \algrenewcommand{\algorithmiccomment}[1]{\hskip3em$\rightarrow$ #1}
crossref:
  custom:
    - kind: float
      key: algo
      reference-prefix: "Algoritmo"
      caption-prefix: "Algoritmo"
      latex-env: algo
      latex-list-of-description: Algoritmo
filters:
  - pseudocode
pseudocode:
  caption-prefix: "Algoritmo"
  reference-prefix: "Algoritmo"
  caption-number: true
number-sections: true
indent: true
documentclass: scrreprt
whitespace: small
lang: pt-br
bibliography: includes/bib.bib
csl: includes/ufpe-abnt.csl
urlcolor: Goldenrod
# linkcolor: Goldenrod
toc: true
title: |
  ![](includes/ufpb.png){width=1in}

  Escrever título (escolher no final)
subtitle: Universidade Federal da Paraíba - CCEN
author: Gabriel de Jesus Pereira
mermaid:
  theme: forest
date: today
date-format: long
highlight-style: github
fontsize: 12pt
interlinespace: 1.5pt
fig-cap-location: bottom
warning: false
echo: false
include-in-header:
  - text: |
      \usepackage{pdflscape}
      \newcommand{\blandscape}{\begin{landscape}}
      \newcommand{\elandscape}{\end{landscape}}
---

```{r}
library(tidyverse)
library(tidymodels)
set.seed(42)
```

\renewcommand{\listalgorithmname}{Lista de algoritmos}
\bgroup
\hypersetup{linkcolor = black}
\listofalgorithms
\egroup


\bgroup
\hypersetup{linkcolor = black}
\listoffigures
\egroup

# Resumo


# Capítulo 1

-- Fazer antes da conclusão --

## Introdução

## Objetivos

### Objetivo Geral

### Objetivos Específicos

## Organização do Trabalho

\newpage

# Capítulo 2

--- Fazer depois dos modelos baseados em árvore ---

## Recursos Computacionais

### Linguagem de Programação R

### Linguagem de Programação Python

### Quarto

### Linguagem de Programação Python

### Web Scraping

\newpage

# Algoritmos de Aprendizado de Máquina

---- MUDAR ISSO AQUI, NÃO TEM SÓ ALGORITMOS BASEADOS EM ÁRVORES ----

\ \ \ Neste capítulo, serão descritos os métodos baseados em árvore, que fundamentam os algoritmos de aprendizado de máquina utilizados neste trabalho e que podem ser aplicados tanto para regressão quanto para classificação. Os métodos baseados em árvore envolvem a estratificação ou segmentação do espaço dos preditores^[O espaço dos preditores é o conjunto de todos os valores possíveis para as $p$ variáveis  $X_1, X_2, ..., X_p$.] em várias regiões simples. Além disso, esses métodos são bastante simples, de fácil interpretação e, apesar de sua simplicidade, são poderosos. Alguns dos algoritmos de aprendizagem de máquinas mais conhecidos e que estão contidos nos métodos baseados em árvore e que foram utilizados nesse trabalho, é a Random Forest, Gradient Boosting e Light Gradient Boosting Machine. No entanto, para fundamentar os métodos baseados em árvore, começaremos pela definição da árvore de decisão.

## Árvores de decisão

\ \ \ Árvores de decisão são métodos de aprendizado supervisionado não paramétrico utilizado tanto para regressão quanto para classificação. Elas servem de base para muitos dos modelos baseados em árvores empregados neste trabalho, uma vez que esses modelos geram múltiplas árvores de decisão. @izbicki2020aprendizado define o processo de construção de uma árvore como o particionamento recursivo no espaço das covariáveis, em que cada particionamento recebe o nome de nós e o resultado final recebe o nome de folha. Em cada nó é definida uma condição e, caso essa condição seja satisfeita, ter-se-á como resultado uma das folhas desse nó. Não obstante, caso o resultado seja contrário, seguirá para o próximo nó e verificará a próxima condição, podendo gerar uma folha ou a condição de outro nó. Veja um exemplo na @fig-arvore:

```{mermaid}
%%| label: fig-arvore
%%| fig-cap: Exemplo de estrutura de árvore de regressão. A árvore tem cinco folhas e quatro nós internos.
%%| fig-width: 5.5

graph TD
    A[Condição 1] -->|Condição 1: Sim| B[Condição 2]
    A -->|Condição 1: Não| C[Condição 3]
    B -->|Condição 2: Sim| D[Folha 1]
    B -->|Condição 2: Não| E[Folha 2]
    C -->|Condição 3: Sim| F[Folha 3]
    C -->|Condição 3: Não| G[Condição 4]
    G -->|Condição 4: Sim| H[Folha 4]
    G -->|Condição 4: Não| I[Folha 5]
```

\vspace{12pt}

\ \ \ Descrevendo formalmente o processo de construção de uma árvore de regressão^[Uma árvore de regressão é um caso específico da árvore de decisão, mas para regressão.], a sua execução é composta por dois passos. No primeiro passo, dividimos o espaço dos preditores em $J$ regiões distintas e disjuntas denotadas por $R_1, R_2, ..., R_J$. No segundo passo, para cada observação que pertence a região $R_j$, a previsão será a mesma. Essa previsão será simplesmente a média dos valores da variável dependente das observações de treinamento que estão dentro da região $R_j$ [@james2013introduction]. Dessa forma, dado que se tenha duas regiões $R_1$ e $R_2$, e a média dos valores da variável resposta tenha sido 10 e 20, respectivamente. Então, Para uma observação $X = x, x \in R_1$, o valor previsto será 10 e, caso contrário, se $x \in R_2$, o valor previsto será 20.

\vspace{12pt}

\ \ \ As regiões $R_1, R_2, ..., R_J$ são construídas em formato de caixa de forma a minimizar a soma dos quadrados. Dessa forma, podemos modelar a variável resposta como uma constante $c_m$ em cada região $R_j$. Assim, definimos a resposta:

$$
f\left(x\right) = \sum^J_{j=1}c_j I\left(x \in R_j \right)
$$

\vspace{12pt}

\ \ \ Agora, utilizando o critério de minimizar a soma dos quadrados, deve-se minimizar $\sum_{x_i \in R_j} \left[y_i - f\left(xi\right)\right]^2$ para encontrar um estimador para o parâmetro $c_j$. No entanto, perceba que $f\left(x_i\right)$ está sendo avaliado somente em um ponto específico $x_i$, o que reduzirá $f\left(x_i\right)$ para uma constante $c_j$. É fácil de se chegar ao resultado se observarmos a definição da função indicadora $I\left(x \in R_j \right)$:

$$
I_{R_j}(x_i) =
\begin{cases}
    1,& \text{se } x_i \in R_j \\
    0,& \text{se } x_i \notin R_j
\end{cases}
$$
e, como um ponto $x_i$ não pode estar ao mesmo tempo em duas regiões $R_j$, pois as regiões são disjuntas, temos que apenas um dos casos a função indicadora será diferente de 0. Portanto, $f\left(x_i\right) = c_j$. Assim, derivando $\sum_{x_i \in R_j} \left(y_i - c_j\right)^2$ em relação a $c_j$

$$
\frac{\partial{\sum_{x_i \in R_j} \left(y_i - c_j\right)^2}}{\partial{c_j}} = -2\sum_{x_i \in R_j} \left(y_i - c_j\right)
$${#eq-partial}
e igualando @eq-partial a 0, temos a seguinte equação
$$
\sum_{x_i \in R_j} \left(y_i - \hat{c}_j\right) = 0
$$
que se abrirmos o somatório e dividirmos pelo número total de pontos $N_{j}$ na região $R_j$, teremos que o estimador de $c_j$ será somente a média dos $y_i$ na região $R_j$:

$$
\sum_{x_i \in R_j} y_i - c_j \sum_{x_i \in R_j} 1 = 0 \Longrightarrow \hat{c}_j = \frac{1}{N_{j}}\sum_{x_i \in R_j} y_i
$${#eq-estimacj}

\vspace{12pt}

No entanto, @james2013introduction caracteriza como inviável considerar todas as possíveis partições do espaço das variáveis em $J$ caixas devido ao alto custo computacional. Dessa forma, a abordagem a ser adotada é uma divisão binária recursiva. O processo começa no topo da árvore de regressão, o ponto em que contém todas as observações, e continua sucessivamente dividindo o espaço dos preditores. As divisões são indicadas como dois novos ramos na árvore, como pode ser visto na [@fig-arvore].

\vspace{12pt}

Para executar a divisão binária recursiva, deve-se primeiramente selecionar a variável independente $X_j$ e o ponto de corte $s$ tal que a divisão do espaço dos preditores conduza a maior redução possível na soma dos quadrados dos resíduos. Dessa forma, definimos dois semi-planos

$$
R_{1}\left(j, s\right) = \{X | X_j \leq s\} \text{ e } R_{2}\left(j, s\right) = \{X | X_j > s\}
$$
e procuramos a divisão da variável $j$ e o ponto de corte $s$ que resolve a equação

$$
\min_{j, s}\left[\min_{c_1} \sum_{x_i \in R_1\left(j, s\right)} \left(y_i - c_{1}\right)^2 + \min_{c_2} \sum_{x_i \in R_2\left(j, s\right)} \left(y_i - c_{2}\right)^2\right]
$$
em que $c_1$ e $c_2$ é a média da variável dependente para as observações de treinamento nas regiões $R_1\left(j, s\right)$ e $R_2\left(j, s\right)$, respectivamente. Assim, encontrando a melhor divisão, os dados são particionados nas duas regiões resultantes e o processo de divisão é repetido em todas as outras regiões.

\vspace{12pt}

\ \ \ O tamanho da árvore pode ser considerado como um hiperparâmetro para regular a complexidade do modelo pois, uma árvore muito grande pode causar um ajuste excessivo aos dados de treinamento, capturando não apenas os padrões relevantes, mas também os ruído. Dessa forma, o modelo apresenta um bom desempenho nos dados de treinamento, mas não consegue desempenhar bem em dados que não foram observados devido a sua incapacidade de generalizar. Não obstante, uma árvore pequena pode não capturar os padrões, relações e estruturas importantes contidas nos dados. Dessa forma, adotamos como estratégia para selecionar o tamanho da árvore é crescer uma grande árvore $T_0$ e interromper o processo de divisão apenas quando atingir um tamanho mínimo de nós. No fim, a grande árvore $T_0$ é podada usando o critério custo de complexidade, que será definida a seguir.

\vspace{12pt}

\ \ \ Para o processo de poda da árvore, definimos uma árvore qualquer $T$ que pode ser obtida através do processo de poda de $T_0$ e portanto $T \subset T_0$. Dessa forma, sendo $N_j$ a quantidade de pontos na região $R_j$, seja

$$
\begin{aligned}
\hat{c}_j &= \frac{1}{N_j}\sum_{xi \in R_j} y_i \\
Q_j\left(T\right) &= \frac{1}{N_j} \sum_{x_i \in R_j}\left(y_i - \hat{c}_j\right)^2
\end{aligned}
$$
$\hat{c}_j$ a média das observações da variável dependente na $R_j$ do nó interno $j$ e $Q_j\left(T\right)$ uma estatística medidas de impureza do nó pelo erro quadrático. Assim, definimos o critério custo de complexidade:

$$
C_{\alpha}\left(T\right) = \sum_{m = 1}^{|T|}N_jQ_j\left(T\right) + \alpha |T|
$$
em que $|T|$ denota a quantidade total de folhas e $\alpha \geq 0$ é o parâmetro de tunagem que equilibra o tamanho da árvore e a adequação aos dados de forma que para cada $\alpha$, a árvore $T_{\alpha} \subseteq T_0$ minimiza $C_{\alpha}\left(T\right)$. Valores grandes para $\alpha$ resulta em árvores menores, valores menores resulta em árvores maiores e $\alpha = 0$ resulta na própria árvore $T_0$. A procura por $T_{\alpha}$ consiste em sucessivamente colapsar o nó interno que produz o menor aumento em $\sum_j N_j Q_j\left(T\right)$ e o processo continua até produzir uma árvore de um único nó. Esse processo gera uma sequência de subárvores que contém uma única menor subárvore que, para cada $\alpha$, minimiza $C_{\alpha}\left(T\right)$. Além disso, a estimação de $\alpha$ é feita por validação cruzada com cinco ou dez folds, e a estimativa $\hat \alpha$ é escolhida para minimizar a soma dos quadrados dos resíduos durante a validação cruzada. Assim, a árvore final será $T_{\hat \alpha}$. O @algo-buildtree exemplifica o processo de crescimento de uma árvore de regressão:


::: {#algo-buildtree}

```pseudocode
#| pdf-line-number: false

\begin{algorithm}
\caption{Algoritmo para crescer uma árvore de regressão}
\begin{algorithmic}
\State \textbf{1.} Use a divisão binária recursiva para crescer uma árvore grande $T_0$ nos dados de treinamento, parando apenas quando cada folha tiver menos do que um número mínimo de observações.

\vspace{3.7pt}

\State \textbf{2.} Aplique o critério custo de complexidade à árvore grande \( T_0 \) para obter uma sequência de melhores subárvores \( T_\alpha \), em função de \( \alpha \).

\vspace{3.7pt}

\State \textbf{3.} Use validação cruzada K-fold para escolher \( \alpha \). Isto é, divida as observações de treinamento em K folds. Para cada \( k = 1, \ldots, K \):
    \State \hspace{1em} (a) Repita os Passos 1 e 2 em todos os folds, exceto no k-ésimo fold dos dados de
    \State \hspace{1em} treinamento.
    \State \hspace{1em} (b) Avalie o erro quadrático médio de previsão nos dados no k-ésimo fold deixado
    \State \hspace{1em} de fora, em função de \( \alpha \). Faça a média dos resultados para cada valor de \( \alpha \) e
    \State \hspace{1em} escolha \( \alpha \) que minimize o erro médio.

\vspace{3.7pt}

\State \textbf{4.} Retorne a subárvore \( T_{\hat{\alpha}} \) do Passo 2 que corresponde ao valor estimado de \( \alpha \).
\end{algorithmic}
\end{algorithm}
```

Fonte: @james2013introduction [p. 337].

:::

## Métodos Ensemble

\ \ \ As árvores de decisão são conhecidas por sua alta interpretabilidade, mas geralmente apresentam um desempenho preditivo preditivo inferior em comparação com outros modelos e algoritmos. No entanto, é possível superar essa limitação construindo um modelo preditivo que combina a força de uma coleção de modelos base mais simples, um processo conhecido como aprendizado Ensemble. De acordo com @hastie2009elements, o aprendizado Ensemble pode ser dividido em duas etapas principais: a primeira etapa consiste em desenvolver uma população de algoritmos de aprendizado base a partir dos dados de treinamento, e a segunda etapa envolve a combinação desses algoritmos para formar um estimador agregado. Portanto, nesta seção, serão definidos os métodos de aprendizagem Ensemble utilizados neste trabalho. O foco inicial será no Random Forest, seguido pela descrição e explicação teórica do Bagging, Boosting, Stacking e outros algoritmos de aprendizado de máquina.


### Bagging

\ \ \ O algoritmo de Bootstrap Aggregation, ou Bagging, foi introduzido por @breiman1996bagging. Sua ideia principal é gerar um estimador agregado a partir de múltiplas versões de um preditor, que são formadas fazendo réplicas bootstrap do conjunto de treinamento e utilizando-as como novos conjuntos de treinamento. O Bagging pode ser utilizado como uma forma de melhorar a estabilidade, precisão de modelos ou algoritmos de aprendizado de máquina, além de diminuir a variância e evitar sobreajuste. Por exemplo, o Bagging poderia ser utilizada para melhorar a árvore de regressão que foi descrita anteriormente, mas também poderia ser aplicado a outros métodos.


\vspace{12pt}

\ \ \ @breiman1996bagging define formalmente o algoritmo de Bagging, no qual temos um conjunto de treinamento $\mathcal{L}$. Tomamos amostras bootstrap $\mathcal{L}^{\left(B\right)}$ com $B$ réplicas de $\mathcal{L}$ para formar $\{\varphi \left(x, \mathcal{L}^{\left(B\right)}\right)\}$, onde $\varphi$ denota um modelo ou algoritmo treinado nas amostras bootstrap $\{\mathcal{L}^{\left(B\right)}\}$ com variáveis independentes $x$ para previsão ou classificação de uma variável dependente $y$. Caso a variável dependente $y$ seja numérica, a predição é feita tomando a média de $\varphi \left(x, \mathcal{L}^{\left(B\right)}\right)$. Assim, temos que a predição é feita da seguinte forma:

$$
\varphi_{B}\left(x\right) = \frac{1}{B} \sum_{b = 1}^B \varphi \left(x, \mathcal{L}^{\left(B\right)}\right)
$$
onde $\varphi_{B}$ denota a agregação. Não obstante, se $y$ prediz uma classe, utilizamos a votação majoritária. Ou seja, se estivermos classificando classes $j \in {1, \dots, J}$, então podemos tomar $N_j = \#\{B; \varphi\left(x, \mathcal{L}^{\left(B\right)}\right) = j\}$ que representa a quantidade de vezes que a classe $j$ foi predita pelos estimadores. Assim, tomamos
$$
\varphi_{B}\left(x\right) = \arg \max_{j} N_j
$$
isto é, o $j$ para o qual $N_j$ é máxima.

\vspace{12pt}

\ \ \ Embora a técnica de Bagging tenha o poder de melhorar o desempenho de uma árvore de regressão ou classificação, isso é alcançado ao custo de menor interpretabilidade. No caso da aplicação de Bagging para uma árvore de regressão, construímos $B$ árvores de regressão usando $B$ réplicas de amostra bootstrap e tomamos a média das predições resultantes [@james2013introduction]. Nesse caso, as árvores de regressão crescem ao máximo, sem passar pelo processo de poda, resultando em cada árvore individual com alta variância, mas baixo viés. No entanto, ao agregarmos $\varphi_{B}$ das $B$ árvores, reduzimos a variância. Para mitigar a falta de interpretabilidade do método Bagging aplicado a uma árvore de regressão, podemos utilizar a soma do quadrado dos resíduos como uma estatística da importância das variáveis independentes. Um valor elevado da redução total média da soma do quadrado dos resíduos devido às divisões em um determinado preditor, calculada sobre todas as árvores $B$, indica um preditor importante.

\vspace{12pt}

\ \ \ As árvores construídas pelo algoritmo de árvore de decisão são beneficiadas pela proposta de agregação do Bagging, mas esse benefício é limitado devido à correlação positiva existente entre as árvores. Se as árvores forem variáveis aleatórias independentes e identicamente distribuídas, cada uma com variância $\sigma^2$, a variância da média das variáveis aleatórias das $B$ árvores será $\frac{1}{B} \sigma ^2$. Não obstante, se forem apenas identicamente distribuídas, mas não necessariamente independente, com correlação pareada positiva $\rho$, a esperança da média das $B$ árvores é a mesma que a esperança de uma árvore individual. Portanto, o viés do agregado das árvores é o mesmo das árvores individuais, e a única melhora possível é através da redução de sua variância. Assim, a variância da média será

$$
\rho \sigma^2 + \frac{1 - \rho}{B}\sigma^2
$${#eq-cor}

Isso significa que, à medida que a quantidade de árvores $B$ aumenta, o segundo termo da soma desaparece. Portanto, os benefícios da agregação ocasionada pelo algoritmo de Bagging são limitados pela correlação das árvores [@hastie2009elements]. Ou seja, mesmo ao aumentar o número de árvores no Bagging, a correlação entre elas faz com que as previsões individuais não sejam completamente independentes, então a variância da média das previsões não diminui tão rapidamente quanto seria esperado se as árvores fossem completamente independentes. Uma forma de melhorar o algoritmo de Bagging foi através da Random Foreste, que será descrita adiante.


### Random Forest

\ \ \ O algoritmo da Random Forest é uma técnica derivada do método de Bagging, com algumas modificações para a construção das árvores. As árvores são construídas de forma a melhorar a redução da variância diminuindo a correlação entre as árvores, sem aumentar significantemente a variabilidade. Isso é alcançado no processo de crescimento das árvores por meio da seleção aleatória das variáveis independentes.

\vspace{12pt}

\ \ \ Ao construir uma árvore em amostras bootstrap no algoritmo da Random Forest, antes de cada divisão, selecionam-se aleatoriamente $m \leq p$ ($m = p$ é o caso do algoritmo de Bagging) variáveis independentes como candidatas para a divisão. No entanto, apenas um desses $m$ preditores é utilizado para a divisão. Com base em algum critério, como a minimização da impureza, selecionamos o melhor preditor possível para realizar a divisão. Portanto, diferente do Bagging, que criava árvores de decisão muito semelhantes e, portanto, resultava em predições altamente correlacionadas, a Random Forest busca minimizar esse problema dando chances a outros preditores. Dessa forma, em média, $\left(p−m\right)/p$ das divisões nem sequer considerarão o preditor mais forte, permitindo que outros preditores também tenham chance de serem utilizados [@james2013introduction]. Esse processo de diminuir a correlação entre as árvores torna a média das árvores resultantes menos variável e, portanto, mais confiável.

\vspace{12pt}

A quantidade de variáveis independentes mm selecionadas aleatoriamente pode ser considerada um parâmetro a ser ajustado por meio de validação cruzada. No entanto, de acordo com @hastie2009elements, os inventores do algoritmo recomendam os seguintes valores padrão: $m= \sqrt{p}$​ e tamanho mínimo do nó igual a um para classificação, e $m=p/3$ e tamanho mínimo do nó igual a cinco para regressão. Quando o número de variáveis é grande, mas poucas variáveis são relevantes, o algoritmo Random Forest pode não ter um bom desempenho com valores pequenos de $m$, pois isso reduz as chances de selecionar as variáveis relevantes. No entanto, utilizar um valor pequeno para $m$ pode ser útil quando há muitos preditores correlacionados. Além disso, assim como no algoritmo de Bagging, a Random Forest não sofre de sobreajuste se o valor de $B$ for aumentado. Portanto, basta usar um $B$ suficientemente grande para que a taxa de erro se estabilize [@james2013introduction]. O processo de construção de uma Random Forest pode ser visualizado no @algo-rf.

::: {#algo-rf}

```pseudocode
#| pdf-line-number: false

\begin{algorithm}
\caption{Algoritmo de uma Random Forest para regressão ou classificação}
\begin{algorithmic}
\State \hspace{1em} \textbf{1.} Para b = 1 até B:

\vspace{0.8em}

    \State \hspace{2em} (a) Construa uma amostra bootstrap \( Z^* \) de tamanho \( N \) dos dados de
    \State \hspace{2em} \vspace{0.1em} treinamento.

    \State \hspace{2em} (b) Faça crescer uma árvore de floresta aleatória \( T_b \) para os dados bootstrap,
    \State \hspace{2em} repetindo recursivamente os seguintes passos para cada folha da árvore, até que
    \State \hspace{2em} \vspace{0.5em} o tamanho mínimo do nó \( n_{min} \) seja atingido.
    \State \hspace{4em} \vspace{0.1em} i. Selecione \( m \) variáveis aleatoriamente entre as \( p \) variáveis.
    \State \hspace{4em} \vspace{0.1em} ii. Escolha a melhor variável entre as \( m \).
    \State \hspace{4em} \vspace{0.1em} iii. Divida o nó em dois subnós.

\vspace{0.8em}

\State \hspace{1em} \textbf{2.} Por fim, o conjunto de árvores \( \{T_b\}^{B}_1\) é construído.

\vspace{1em}

\State \hspace{0.7em} No caso da regressão, para fazer uma predição em um novo ponto \( x \), temos a seguinte função:


$$
\hat{f}^{B}_{rf}\left(x\right) = \frac{1}{B}\sum^{B}_{b = 1} T_{b}\left(x\right)
$$

\vspace{1em}

\State \hspace{0.7em} Para a classificação é utilizado o voto majoritário. Assim, seja $\hat{C}_{b}\left(x\right)$ a previsão da classe da árvore de floresta aleatória $b$. Então,

$$
\hat{C}^{B}_{rf}\left(x\right) = \arg \max_c \sum^{B}_{b = 1}I\left(\hat{C}_b\left(x\right) = c\right)
$$

\State onde $c$ representa as classes possíveis.

\end{algorithmic}
\end{algorithm}
```

Fonte: @hastie2009elements [p. 588].

:::

### Boosting Trees

\ \ \ O Boosting, assim como o Bagging mostrado anteriormente, é uma metodologia que pode ser aplicada para melhorar a performance de um modelo ou algoritmo. No entanto, neste trabalho, o Boosting foi aplicado apenas utilizando árvores de decisão, portanto, sua descrição será restrita a esse caso, conhecidas como Boosting Trees.

\vspace{12pt}

\ \ \ No algoritmo de Bagging cada árvore era construída e ajustada utilizando amostras bootstrap. Por fim, era necessário tomar um agregado $\varphi_B$ de todas as $B$ árvores para criar um único estimador. O Boosting Trees funciona de forma similar, no entanto, cada árvore é construída utilizando uma versão modificada dos dados de treinamento original, sem a necessidade de amostras bootstrap, e a informação prévia de outras árvores. Ou seja, são construídas sequenciamente.

\vspace{12pt}

\ \ \ Para o caso da regressão, o Boosting, assim como o Bagging, combina um grande número de árvores de decisão $\hat{f}^1, \dots, \hat{f}^B$. Assim, a primeira árvore é construída utilizando o conjunto de dados originais e os seus resíduos são calculados. Com a primeira árvore construída, a segunda árvore é ajustada para prever esses resíduos e é adicionada ao estimador ajustado para atualizar os seus resíduos. Portanto, para a regressão, os resíduos funcionam como uma informação para construir novas árvores e corrigir os erros das árvores anteriores. Ainda, como para construir cada árvore depende de árvores que já foram construídas, árvores pequenas são suficientes [@james2013introduction].

\vspace{12pt}

\ \ \ O processo de aprendizado na metodologia do Boosting é lenta, o que acaba gerando melhores resultados. Esse processo de aprendizado pode ser controlado por um hiperparâmetro $\lambda$ chamado de shrinkage, permitindo que mais árvores, com formas diferentes, corrijam os erros de árvores passadas. No entanto, um valor muito pequeno para $\lambda$ requer uma quantidade muito maior $B$ de árvores e, diferente do Bagging e Random Forest, o Boosting pode sofrer de sobreajuste se a quantidade de árvores é muito grande. Além disso, a quantidade de divisões $d$ em cada árvore, que controla a complexidade do boosting, pode ser considerado também um hiperparâmetro. Para $d = 1$ é ajustado um modelo aditivo, já que cada termo involve apenas uma variável. @james2013introduction define $d$ como a profundidade de interação que controla a ondem de interação do modelo boosting, já que $d$ divisões podem envolver no máximo $d$ variáveis. Uma versão simplificada do algoritmo pode ser visualizado em @algo-boos.

\vspace{12pt}


::: {#algo-boos}

```pseudocode
#| pdf-line-number: false

\begin{algorithm}
\caption{Método Boosting aplicado a árvores de regressão}
\begin{algorithmic}
\State \hspace{1em} \textbf{1.} Defina $\hat{f}\left(x\right) = 0 \text{ e } r_i = y_i$ para todos os $i$ no conjunto de treinamento

\vspace{0.8em}

\State \hspace{1em} \vspace{0.8em} \textbf{2.} Para $b = 1, 2, \dots, B$, repita:

  \State \hspace{2em} (a) Ajuste uma árvore $\hat{f}^b$ com $d$ divisões para os dados de
  \State \hspace{2em} \vspace{0.1em} treinamento $\left(X, r\right)$.

  \State \hspace{2em} (b) Atualize $\hat{f}$ adicionando uma versão com o hiperparâmetro $\lambda$ de taxa de
  \State \hspace{2em} aprendizado:

$$
\hat{f}\left(x\right) \gets \hat{f}\left(x\right) + \lambda \hat{f}^b\left(x\right)
$$

  \vspace{0.1em}

  \State \hspace{2em} (c) Atualize os resíduos,

$$
r_i \gets r_i - \lambda \hat{f}^b\left(x_{i}\right)
$$

\vspace{1em}

\State \hspace{1em} \textbf{3.} Retorne o modelo de boosting,

$$
\hat{f}\left(x\right) = \sum_{b = 1}^B \lambda \hat{f}^b\left(x\right)
$$


\end{algorithmic}
\end{algorithm}
```

Fonte: @james2013introduction [p. 349].

:::

### Gradient Boosting

\ \ \ O método de Gradient Boosting constrói modelos de regressão aditivos ajustando sequencialmente uma função base aos resíduos, que são os gradientes da função de perda do modelo atual [@friedman2002stochastic]. Estes gradientes representam a direção na qual a função de perda deve ser minimizada. Existem outras implementações de Gradiente Boosting que foram utilizadas nesse trabalho. No entanto, todas elas utilizam o Gradient Boosting com árvores de regressão, mas com algumas modificações para melhorar a eficiência do algoritmo já existente. O algoritmo do gradient boosting aplicado para árvores de regressão, que será explicado, pode ser visualizado no @algo-gradboos.

::: {#algo-gradboos}

```pseudocode
#| pdf-line-number: false

\begin{algorithm}
\caption{Gradient Tree Boosting}
\begin{algorithmic}
\State \hspace{1em} \textbf{1.} Inicialize $f_0\left(x\right) = \arg \min_{\gamma} \sum_{i = 1}^N L\left(y_i, \gamma \right)$

\vspace{0.8em}

\State \hspace{1em} \vspace{0.8em} \textbf{2.} Para $m = 1$ até $M$:

  \State \hspace{2em} (a) Para $i = 1, 2, \dots, N$, calcule

$$
r_{im} = -\left[\frac{\partial L\left(y_i, f\left(x_i \right)\right)}{\partial f\left(x_i\right)}\right]_{f = f_{m - 1}}
$$

  \State \hspace{2em} (b) Ajuste uma árvore de regressão aos alvos $r_{im}$, obtendo regiões terminais
  \State \hspace{2em} $R_{jm}, \ j = 1, 2, \dots, J_{m}$.


  \State \vspace{0.1em}

  \State \hspace{2em} (c) Para $j = 1, 2, \dots, J_m$, calcule

$$
\gamma_{jm} = \arg \min_{\gamma} \sum_{x_i \in R_{jm}} L\left(y_i, f_{m - 1}\left(x_i\right) + \gamma\right)
$$

  \vspace{0.1em}

  \State \hspace{2em} (d) Atualize $f_m\left(x\right) = f_{m - 1}\left(x\right) + \gamma_{jm}$ para $x \in R_{jm}$.

\vspace{1em}

\State \hspace{1em} \textbf{3.} Retorne $\hat{f}\left(x\right) = f_M\left(x\right)$

\end{algorithmic}
\end{algorithm}
```

Fonte: @hastie2009elements
:::

\vspace{12pt}

O Gradient Boosting aplicado para árvores de regressão, tem que cada função base é um caso especial de uma árvore de regressão com $J$ folhas. Dessa forma, cada árvore de regressão tem a forma aditiva

$$
f\left(x;\{b_j, R_j\}^J_{1}\right) = \sum^{J}_{j = 1} b_j I\left(x \in R_j\right)
$$


em que $\{R_j\}^{J}_{1}$ são as regiões disjuntas que, coletivamente, cobrem o espaço de todos os valores conjuntos das variáveis preditoras $x$ e também cada região é representada como as folhas de cada árvore correspondente.

\vspace{12pt}

O Gradient Tree Boosting, que é como é chamado o algoritmo de gradient boosting aplicado a árvores de decisões, utiliza como função base  $J_m$ folhas. A cada iteração $m$, a árvore de regressão particiona o espaço das variáveis independentes em $J_m$ regiões disjuntas $\{R_{jm}\}^{J_m}_1$ e estima uma constante separada para cada região. Assim, como foi visto anteriormente, a previsão de uma árvore de regressão pode ser simplesmente expressa por

$$
f\left(x; \{R_{jm}\}_{1}^{J_m}\right) = \sum^{J_m}_{j=1} \bar{y}_{jm} I\left(x \in R_{jm}\right)
$$

em que $\bar{y}_{jm}$ é a média dos pseudo resíduos $r_{im}$ em cada região $R_{jm}$. Ou seja, cada árvore de regressão é ajustada às componentes negativas dos gradientes, o que indica a direção de diminuição dos resíduos através de uma função perda $L$, diminuindo o erro das árvores passadas a cada nova iteração.

\vspace{12pt}



### Stacking

### Categorical Boosting

### Light Gradient-Boosting

### Extreme Gradient Boosting


\vspace{12pt}

# Metodologia

## Os dados e o procedimento adotado para sua obtenção

--- AINDA SERÁ MODIFICADO ---

\ \ \ O Web scraping, também conhecido como extração de dados da web, é uma técnica utilizada para o processo de coleta de dados estruturados da web de maneira automatizada. É um processo que vem sendo constantemente utilizado por instituições públicas e privadas para a construção de produtos que utilizam algoritmos de aprendizagem de máquinas, observa ofertas e discontos, faz análise de mercado ou monitoração de marcas.

\vspace{12pt}

Neste projeto, para fins de estudo e análise do mercado imobiliário, os dados foram coletados por meio de extração de dados do site do Zap Imóveis. O Zap Imóveis é um site do Grupo OLX que reúne ofertas do mercado imobiliário e que funciona como uma plataforma dinâmica para facilitar a conexão entre quem deseja alugar, comprar ou vender um imóvel; podendo servir também para corretores ou outros profissionais do setor de imóveis. Este projeto foi possível graças as informações que foram coletadas do site do Zap Imóveis em dois diferentes períodos do ano de 2023. O primeiro deles, as informações foram coletadas utilizando variados pacotes para raspagem de dados e proxies rotativas da linguagem de programação R, a fim de evitar ser bloqueado pelos mecanismos de segurança do site. Na segunda etapa, os dados foram coletados empregando a linguagem de programação Python com as bibliotecas Scrapy e Playwrite, que serve para web crawling e web scraping, e o Playwrite que serve para testes em aplicativos da web, mas que neste caso foi utilizado para manejar páginas dinâmicas.

\vspace{12pt}

Desta forma, com a ideia de modelar o valor do imóvel e analisar o mercado imobiliário, foram coletados aqueles variáveis que estavam disponíveis no site do Zap Imóveis e que poderiam de alguma forma ser significativas ao tentar explicar o valor do imóvel durante a sua modelagem. Assim, no total foram coletatas 23 variáveis, das quais 8 são quantitativas e 15 qualitativas nominais, sendo 13 de caráter dicotômico. No entanto, nem todas essas variáveis foram coletadas diretamente do Zap Imóveis, a latitude e longitude foram obtidas pela geocodificação do endereço utilizando o pacote tidygeocoder da linguagem de programação R. Portanto, temos as seguites variáveis:

- Valor do imóvel: esta é a variável dependente, aquela que será modelada e será o principal objeto de estudo deste trabalho;

- Área: área do imóvel em $m^2$;

- Condomínio: valor pago pelo condomínio;

- IPTU: imposto cobrado de quem tem um imóvel urbano;

- Banheiro: quantidade de banheiros presentes na propriedade;

- Vaga de estacionamento: quantidade total de vagas de estacionamento;

- Quarto: quantidade de quartos no imóvel;

- Latitude: posição horizontal medida em frações decimais de graus;

- Longitude: posição vertical que, assim como a latitude, é medida em frações decimais de graus;

- Tipo do imóvel: foram obtidos 7 tipos de imóveis, apartamentos, casas, casas comerciais, casas de condomínio, casas de vila, coberturas, lotes comerciais e de condomínio;

- Endereço: nome do endereço do imóvel;

- Variáveis dicotômicas que indicam se o imóvel tem ou não aquela característica (representado como 1 ou 0, respectivamente): área de serviço, academia, elevador, espaço gourmet, piscina, playground, portaria 24 horas, quadra de esporte, salão de festa, sauna, spa e varanda gourmet.

\vspace{12pt}

No entanto, devido a observações feitas durante o estudo, nem todas essas variáveis foram utilizadas para a modelagem do valor dos imóveis, seja por conter muitos valores valores ausentes ou por não ter se mostrado significante para o que se desejava explicar. Ainda, como a coleta destes dados foram feitas em dois momentos distintos, temos dois bancos de dados, um com 29712 observações e o outro com 14956. Por fim, essas duas bases de dados foram unidas e, para não correr o risco de conter imóveis repetidos, aqueles que tinham o mesmo número de identificação foram removidos.

## Descritiva dos dados

\ \ \ A análise exploratória de dados marca uma das primeiras etapas de qualquer estudo que utiliza a estatística como uma de suas principais ferramentas, pois permite encontrar padrões de comportamento no dados, descobrir relações entre as variáveis estudadas. Dessa forma, a primeira etapa desse estudo, após a coleta e organização dos dados obtidos do Zap Imóveis, foi fazer uma descritiva dos dados. Essa etapa permitiu encontrar padrões nos diferentes tipos de imóveis bem como o seu tipo pode influenciar na características do imóvel, o que, por consequência, pode afetar o seu valor. Assim, para identificar esses diferentes comportamentos, foram criados gráficos e tabelas a fim de caracterizar as relações das variáveis independentes com a dependente.

## Aprendizado Supervisionado e não supervisionado

\ \ \ Na aprendizagem de máquinas, uma das estapas mais importantes é saber qual técnica será utilizada para resolver um problema que se enquadra em diferentes formas de aprendizado. Para isso, existem mais de uma forma em que um algoritmo consegue utilizar os dados e explicar o que está sendo modelado a partir deles. No entanto, a maioria dos problemas de aprendizado de máquinas recais em dois casos mais conhecidos: aprendizado supervisionado e não supervisionado.

### Aprendizado supervisionado

\ \ \ Suponha uma regressão logística. Sabemos que na regressão logistíca temos um modelo com a seguinte forma $Y_i = f\left(X\right) + \epsilon$, em que $Y_i$ assume 0 ou 1 para classificar o que está sendo modelado e representa a variável dependente, $f\left(X\right)$ representa as variáveis independentes que serão utilizadas para a modelagem e $\epsilon$ representa o erro da regressão. Dessa forma, podemos considerar o caso em que a regressão logística tenta classificar pacientes que podem ou não estar com diabetes. Para isso, utilizariamos variáveis significativas para a classificação do estado de cada paciente. Esse exemplo é conhecido como aprendizagem supervisionada. Na aprendizagem supervisionada, busca-se aprender $Y_i$ atráves de um exemplo. Nesse caso, as variáveis dependentes podem ser interpretadas como o exemplo, as informações de relações de pacientes que podem ter ou não diabetes, e o estado do paciente pode ser interpretado como o que se deseja aprender. Este processo é entendido como *aprendizado por exemplo*, @hastie2009elements. O aprendizado supervisionado pode aparecer em casos de regressão linear, regressão logística, ou até mesmo em métodos mais modernos, como GAM, boosting e máquina de vetores de suporte, @james2013introduction.

### Aprendizado não supervisionado

\ \ \ Por outro lado, o aprendizado não supervisionado aparece em situações mais desafiadores, pois não há um exemplo para explicar aquilo que se pretende explicar. Este processo é conhecido como *aprendizado sem exemplo*, @hastie2009elements. Dessa forma, no aprendizado não supervisionado, tem-se uma amostra com N observações $\left(x_1, ..., x_N\right)$ de um vetor aleatório $X$ com densidade conjunta $f\left(x\right)$ em que o objetivo é inferir propriedades da densidade sem ajuda de exemplos para cada observação. Assim, como há uma falta de uma variável resposta $y_i$ para supervisionar a análise, pode-se procurar entender a relação entre as variáveis ou as observações, @james2013introduction. Por exemplo, uma das técnicas mais aplicadas em problemas que envolvem o aprendizado supervisionado é a análise de cluster, em que o objetivo é determinar, com base em $x_1, ..., x_n$, se as observações são caracterizadas em grupos distintos. Esse é um dos métodos que poderiam ser aplicados, por exemplo, na análise de crédito de clientes de um cartão de crédito, tornando possível analisar o seu perfil e classificá-lo em diferentes grupos para recomendar produtos especificos adequados ao seu perfil.

## Reamostragem para avaliação de performance

\ \ \

\ \ \

## Métricas de avaliação

\ \ \

## Tunagem de hiperparâmetros


\ \ \ Na aprendizagem de máquina, uma das etapas fundamentais é a tunagem dos hiperparâmetros dos algoritmos de aprendizagem. Essa etapa consiste em encontrar a melhor combinação de hiperparâmetros e, consequentemente, resultando em uma configuração algoritmo que proporciona melhor performance e capacidade de generalização. No entanto, essa configuração não é trivial.

\vspace{12pt}

\ \ \ Os algoritmos de otimização de hiperparâmetros procuram pelo melhor ajuste de hiperparâmetros $\lambda \in \tilde{\Lambda}$ para um algoritmo de aprendizagem $I_{\lambda}$. O espaço de procura $\tilde{\Lambda} \in \Lambda$ contém todas as possíveis configurações de hiperparâmetros consideradas para otimização. Dessa forma, temos que:

$$
\tilde{\Lambda} = \tilde \Lambda_1 \cup \tilde \Lambda_2 \cup ... \cup \tilde \Lambda_l
$${#eq-space}
em que $l$ são todas as possíveis configurações de hiperparâmetros. Além disso, $\tilde \Lambda_i \ \left(i = 1, 2, ..., l\right)$ representam o subconjunto de limites dos domínios do i-ésimo hiperparâmetro $\Lambda_i$, podendo ser contínuo, discreto ou categórico (BISCHL et al., 2023).

\vspace{12pt}

A busca pela melhor combinação de hiperparâmetros $\lambda$ é feito de forma iterativa, utilizando métodos de reamostragem para dividir o conjunto de dados entre teste e treinamento. Portanto, para validar e encontrar os hiperparâmetos, o algoritmo de aprendizagem é validado através da divisão do conjunto de dados. Assim, tem-se a seguinte estratégia de separação do conjunto de dados:

$$
\mathcal{J} = \left(\left(J_{treino, 1},\ J_{teste, 1}\right), ..., \left(J_{treino, B},\ J_{test, B}\right)\right)
$${#eq-teste}
onde $J_{treino, i}, \ J_{teste, i}$ representam os vetores de índices $\left(i = 1, \, 2, ..., \ B\right)$ para os conjuntos de treino e teste, respectivamente, e $B$ representa o número total de divisões.

\vspace{12pt}

A motivação para fazer a divisão do conjunto de dados entre treino e teste é ajustar o algoritmo em dados reais e avaliar a sua performance em dados ainda não vistos, processo representado pelo banco de treino e teste, respectivamente. Para fazer a avaliação dessa performance é necessário estimar uma métrica de performance em cada divisão. Assim, para um dado algoritmo $I_{\lambda}$ é calculado uma métrica de performance $\rho$ para cada $J_{teste, i}$ após o ajuste do algoritmo no $J_{treino, i}$. Por fim, pode ser calculado uma média amostral da métrica de cada uma das divisões. Dessa forma, o problema de otimizar os hiperparâmetros pode ser definida da seguinte forma:

$$
\lambda^* \in \underset{\lambda \in \tilde \Lambda}{\operatorname{argmin}} \ c\left(\lambda \right)
$$
onde $\lambda^*$ denota a melhor combinação possível de hiperparâmetros, $c\left(\lambda \right)$ representa a generalização do erro, podendo ser representado também por $\widehat{GE}\left(I, \ \mathcal J, \ \rho, \ \lambda\right)$, quando $I, \ \mathcal{J}, \ \rho$ são fixados e $I$ denota um algoritmo de aprendizagem de máquina. O erro de generalização é estimado e otimizado a fim de evitar um ajuste excessivo (overfitting), podendo prejudicar quando o algoritmo fizer estimativas em dados ainda não vistos. Assim, o processo pode ser visualizado pela figura @fig-hpo:


```{mermaid}
%%| label: fig-hpo
%%| fig-cap: Processo de otimização de hiperparâmetros
%%| fig-width: 4.5
flowchart LR
  A["$$\lambda$$"] --> B(Round edge)
  B --> C{Decision}
```

\vspace{12pt}

### Otimização Bayesiana

\ \ \ Existem diversas técnicas para otimização de hiperparâmetros utilizadas em aprendizagem de máquina. Uma das técnicas mais comuns é o GridSearch. @bischl2023hyperparameter definem GridSearch como um processo que divide o intervalo contínuo de valores possíveis de cada hiperparâmetro em um conjunto de valores específicos e avalia exaustivamente o algoritmo para todas as combinações possíveis. No entanto, como todas as combinações possíveis aumentam exponencialmente com a quantidade necessária para avaliação do algoritmo, o GridSearh tem um custo computacional bastante elevado. Assim, existem algoritmos de otimização mais sofisticados que entregam melhores performances, como a otimização bayesiana, que foi utilizada neste trabalho.

\vspace{12pt}

\ \ \ A otimização bayesiana não se refere a um tipo específico de algoritmo de otimização, mas sim a uma filosofia de otimização baseada em inferência bayesiana, a qual contém uma extensa família de algoritmos de otimização [@garnett2023bayesian]. Não obstante, a otimização bayesiana tem obtido benchmarks melhores que outros algoritmos em inúmeros problemas complexos de otimização de hiperparâmetros [@snoek2012practical].

\vspace{12pt}

\ \ \ Diferente de outros algoritmos de otimização de hiperparâmetros, a otimização bayesiana determina as futuras tentativas de avaliação com base em resultados obtidos previamente [@yang2020hyperparameter]. Para a definição dos pontos futuros, é utilizada uma função probabilística $P\left(\rho |  \lambda \right)$ [@bergstra2013making]. Assim, após o ajuste da função probabilística, tem-se como resultado para cada $\lambda$ uma estimativa da performance $\hat c \left(\lambda \right)$ e da predição da incerteza $\hat \sigma \left(\lambda \right)$, além de obter também a distribuição preditiva da função probabilística. Com a distribuição obtida, uma função de aquisição determina o trade-off entre exploitation e exploration^[exploitation pode ser entendido como procurar próximo a boas observações e ]. Dessa forma, os algoritmos de otimização bayesiana são definidos segundo a lei $\lambda \to c\left(\lambda \right)$ e  procuram um equilíbrio entre o processo de exploitation-exploration para detectar as regiões ótimas mais prováveis e não perder melhores configurações em áreas ainda não exploradas.

### Tree-Structured Parzen Estimator

\ \ \ Existem diversas funções probabilísticas para uso na otimização bayesiana, algumas delas é o Processo Gaussiano, Random Forest ou Tree-Structured Parzen Estimator (TPE). Nesse trabalho, foi utilizado o Tree-Structured Parzen Estimator, utilizando a biblioteca Optuna [@optuna_2019] para sua aplicação.

\vspace{12pt}

\ \ \ O TPE define duas funções, $l\left(x\right) \text{ e } g\left(x\right)$, que são usadas para modelar a distribuição das variáveis do domínio [@yang2020hyperparameter]. Utilizando as duas densidades, o TPE procura modelar a probabilidade de se observar um hiperparâmetro $x$ dado uma métrica de performance $\rho$. Dessa forma, tem-se a seguinte definição:


$$
p(x|y) =
\begin{cases}
    l(x) & \text{if } y < y^* \\
    g(x) & \text{if } y \ge y^*
\end{cases}
$${#eq-tpe}
em que $l\left(x\right)$ é definido como a densidade em que a função perda é menor que um limiar $y^*$ e $g\left(x\right)$ representa é a densidade em que a função perda^[definição de função perda] tem valores acima do limiar $y^*$ [@bergstra2011algorithms]. O limite $y^*$ é escolhido através de um hiperparâmetro $\gamma$, onde $\gamma$ representa o percentil dos valores observados de $y$, de modo que $p\left(y < y^*\right) = \gamma$.

\vspace{12pt}

Por padrão, o tree-structured parzen estimator tem como função de aquisição o Expected Improvement $\left(EI\right)$, que pode ser otimizado para o TPE da seguinte forma:

$$
  EI_{y^*}\left(x\right) = \int_{-\infty}^{y^*} \left(y^* - y\right)p\left(y | x\right) dy
$${#eq-exp}

Ainda, para encontrar a probabilidade marginal de $x$, temos a seguinte integral $p\left(x\right) = \int_{\mathbb{R}} p\left(x | y\right)p\left(y\right)dy$. Particionando o domínio de $y$, chega-se em:

$$
p\left(x\right) = \int_{-\infty}^{y^*} p\left(x | y\right)p\left(y\right)dy + \int_{y^*}^{\infty} p\left(x | y\right)p\left(y\right)dy = \gamma l\left(x\right) + \left(1 - \gamma \right) g\left(x\right)
$$

Assim, utilizando o Teorema de Bayes e fazendo as substituições na integral da @eq-exp:

$$
EI_{y^*}\left(x\right) = \int_{-\infty}^{y^*} \left(y^* - y\right) \frac{p\left(x | y\right)p\left(y\right)}{p\left(x\right)}dy = \left(\gamma y^*  - \int_{-\infty}^{y^*} p\left(y\right)dy\right) \left(\gamma + \left(1 - \gamma\right)\frac{g\left(x\right)}{l\left(x\right)}\right) ^{-1}
$$
em que a segunda expressão do produto mostra que para maximizar o Expected Improvement é necessário pontos de $x$ com maior probabilidade em $l\left(x\right)$ e com baixa probabilidade em $g\left(x\right)$. Não obstante, no TPE, maximizar o $EI$ é equivalente a maximizar a razão entre as duas distribuições $r\left(x\right) = \frac{l\left(x\right)}{g\left(x\right)}$ [@cowen2022hebo].


\newpage

# Capítulo 4

## Resultados

\newpage

# Conclusão

# Referências

::: {#refs}
:::
