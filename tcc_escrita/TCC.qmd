---
format: pdf
number-sections: true
indent: true
documentclass: scrreprt
lang: pt-br
bibliography: includes/bib.bib
csl: includes/ufpe-abnt.csl
urlcolor: yellow
linkcolor: yellow
toc: true
title: |
  ![](includes/ufpb.png){width=1in}

  Escrever título (escolher no final)
subtitle: Universidade Federal da Paraíba - CCEN
author: Gabriel de Jesus Pereira
date: today
date-format: long
highlight-style: github
monofont: "Ubuntu Mono"
monofontoptions: Scale = 1
fig-cap-location: top
warning: false
echo: false
include-in-header:
  - text: |
      \usepackage{pdflscape}
      \newcommand{\blandscape}{\begin{landscape}}
      \newcommand{\elandscape}{\end{landscape}}
---

```{r}
library(tidyverse)
library(tidymodels)
set.seed(42)
```

# Resumo


# Capítulo 1

-- Fazer antes da conclusão --

## Introdução

## Objetivos

### Objetivo Geral

### Objetivos Específicos

## Organização do Trabalho

\newpage

# Capítulo 2

-- Fazer depois da metodologia --

## Recursos Computacionais

### Linguagem de Programação R

### Quarto

### Linguagem de Programação Python

### Web Scraping

\newpage

# Metodologia

## Os dados e o procedimento adotado para sua obtenção

\

O Web scraping, também conhecido como extração de dados da web, é uma técnica utilizada para o processo de coleta de dados estruturados da web de maneira automatizada. É um processo que vem sendo constantemente utilizado por instituições públicas e privadas para a construção de produtos que utilizam algoritmos de aprendizagem de máquinas, observa ofertas e discontos, faz análise de mercado ou monitoração de marcas.

Neste projeto, para fins de estudo e análise do mercado imobiliário, os dados foram coletados por meio de extração de dados do site do Zap Imóveis. O Zap Imóveis é um site do Grupo OLX que reúne ofertas do mercado imobiliário e que funciona como uma plataforma dinâmica para facilitar a conexão entre quem deseja alugar, comprar ou vender um imóvel; podendo servir também para corretores ou outros profissionais do setor de imóveis. Este projeto foi possível graças as informações que foram coletadas do site do Zap Imóveis em dois diferentes períodos do ano de 2023. O primeiro deles, as informações foram coletadas utilizando variados pacotes para raspagem de dados e proxies rotativas da linguagem de programação R, a fim de evitar ser bloqueado pelos mecanismos de segurança do site. Na segunda etapa, os dados foram coletados empregando a linguagem de programação Python com as bibliotecas Scrapy e Playwrite, que serve para web crawling e web scraping, e o Playwrite que serve para testes em aplicativos da web, mas que neste caso foi utilizado para manejar páginas dinâmicas.

Desta forma, com a ideia de modelar o valor do imóvel e analisar o mercado imobiliário, foram coletados aqueles variáveis que estavam disponíveis no site do Zap Imóveis e que poderiam de alguma forma ser significativas ao tentar explicar o valor do imóvel durante a sua modelagem. Assim, no total foram coletatas 23 variáveis, das quais 8 são quantitativas e 15 qualitativas nominais, sendo 13 de caráter dicotômico. No entanto, nem todas essas variáveis foram coletadas diretamente do Zap Imóveis, a latitude e longitude foram obtidas pela geocodificação do endereço utilizando o pacote tidygeocoder da linguagem de programação R. Portanto, temos as seguites variáveis:

- Valor do imóvel: esta é a variável dependente, aquela que será modelada e será o principal objeto de estudo deste trabalho;

- Área: área do imóvel em $m^2$;

- Condomínio: valor pago pelo condomínio;

- IPTU: imposto cobrado de quem tem um imóvel urbano;

- Banheiro: quantidade de banheiros presentes na propriedade;

- Vaga de estacionamento: quantidade total de vagas de estacionamento;

- Quarto: quantidade de quartos no imóvel;

- Latitude: posição horizontal medida em frações decimais de graus;

- Longitude: posição vertical que, assim como a latitude, é medida em frações decimais de graus;

- Tipo do imóvel: foram obtidos 7 tipos de imóveis, apartamentos, casas, casas comerciais, casas de condomínio, casas de vila, coberturas, lotes comerciais e de condomínio;

- Endereço: nome do endereço do imóvel;

- Variáveis dicotômicas que indicam se o imóvel tem ou não aquela característica (representado como 1 ou 0, respectivamente): área de serviço, academia, elevador, espaço gourmet, piscina, playground, portaria 24 horas, quadra de esporte, salão de festa, sauna, spa e varanda gourmet.

No entanto, devido a observações feitas durante o estudo, nem todas essas variáveis foram utilizadas para a modelagem do valor dos imóveis, seja por conter muitos valores valores ausentes ou por não ter se mostrado significante para o que se desejava explicar. Ainda, como a coleta destes dados foram feitas em dois momentos distintos, temos dois bancos de dados, um com 29712 observações e o outro com 14956. Por fim, essas duas bases de dados foram unidas e, para não correr o risco de conter imóveis repetidos, aqueles que tinham o mesmo número de identificação foram removidos.

## Descritiva dos dados

\

A análise exploratória de dados marca uma das primeiras etapas de qualquer estudo que utiliza a estatística como uma de suas principais ferramentas, pois permite encontrar padrões de comportamento no dados, descobrir relações entre as variáveis estudadas. Dessa forma, a primeira etapa desse estudo, após a coleta e organização dos dados obtidos do Zap Imóveis, foi fazer uma descritiva dos dados. Essa etapa permitiu encontrar padrões nos diferentes tipos de imóveis bem como o seu tipo pode influenciar na características do imóvel, o que, por consequência, pode afetar o seu valor. Assim, para identificar esses diferentes comportamentos, foram criados gráficos e tabelas a fim de caracterizar as relações das variáveis independentes com a dependente.

## Aprendizado Supervisionado e não supervisionado

\

Na aprendizagem de máquinas, uma das estapas mais importantes é saber qual técnica será utilizada para resolver um problema que se enquadra em diferentes formas de aprendizado. Para isso, existem mais de uma forma em que um algoritmo consegue utilizar os dados e explicar o que está sendo modelado a partir deles. No entanto, a maioria dos problemas de aprendizado de máquinas recais em dois casos mais conhecidos: aprendizado supervisionado e não supervisionado.

### Aprendizado supervisionado

\

Suponha uma regressão logística. Sabemos que na regressão logistíca temos um modelo com a seguinte forma $Y_i = f\left(X\right) + \epsilon$, em que $Y_i$ assume 0 ou 1 para classificar o que está sendo modelado e representa a variável dependente, $f\left(X\right)$ representa as variáveis independentes que serão utilizadas para a modelagem e $\epsilon$ representa o erro da regressão. Dessa forma, podemos considerar o caso em que a regressão logística tenta classificar pacientes que podem ou não estar com diabetes. Para isso, utilizariamos variáveis significativas para a classificação do estado de cada paciente. Esse exemplo é conhecido como aprendizagem supervisionada. Na aprendizagem supervisionada, busca-se aprender $Y_i$ atráves de um exemplo. Nesse caso, as variáveis dependentes podem ser interpretadas como o exemplo, as informações de relações de pacientes que podem ter ou não diabetes, e o estado do paciente pode ser interpretado como o que se deseja aprender. Este processo é entendido como *aprendizado por exemplo*, @hastie2009elements. O aprendizado supervisionado pode aparecer em casos de regressão linear, regressão logística, ou até mesmo em métodos mais modernos, como GAM, boosting e máquina de vetores de suporte, @james2023introduction.

### Aprendizado não supervisionado

\

Por outro lado, o aprendizado não supervisionado aparece em situações mais desafiadores, pois não há um exemplo para explicar aquilo que se pretende explicar. Este processo é conhecido como *aprendizado sem exemplo*, @hastie2009elements. Dessa forma, no aprendizado não supervisionado, tem-se uma amostra com N observações $\left(x_1, ..., x_N\right)$ de um vetor aleatório $X$ com densidade conjunta $f\left(x\right)$ em que o objetivo é inferir propriedades da densidade sem ajuda de exemplos para cada observação. Assim, como há uma falta de uma variável resposta $y_i$ para supervisionar a análise, pode-se procurar entender a relação entre as variáveis ou as observações, @james2023introduction. Por exemplo, uma das técnicas mais aplicadas em problemas que envolvem o aprendizado supervisionado é a análise de cluster, em que o objetivo é determinar, com base em $x_1, ..., x_n$, se as observações são caracterizadas em grupos distintos. Esse é um dos métodos que poderiam ser aplicados, por exemplo, na análise de crédito de clientes de um cartão de crédito, tornando possível analisar o seu perfil e classificá-lo em diferentes grupos para recomendar produtos especificos adequados ao seu perfil.

## Métodos de reamostragem

\

## Tunagem de hiperparâmetros na aprendizagem de máquina

Na aprendizagem de máquina, uma das principais etapas é a tunagem do hiperparâmetros, que se consiste em encontrar a melhor combinação de hiperparâmetros de um modelo. O método de GridSearch é a técnica mais comum para otimização de hiperparâmetros utilizada em aprendizagem de máquina. Essa técnica funciona testando todas as combinações possíveis definidas, utilizando uma métrica de avaliação para selecionar a combinação com os melhores resultados.

\

## Modelos baseados em árvores



\newpage

# Capítulo 4

## Resultados

\newpage

# Capítulo 5

## Conclusão e Discussão

# Referências

::: {#refs}
:::
